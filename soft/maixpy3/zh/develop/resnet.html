<!DOCTYPE html>

<html lang="zh"  class="">


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="keywords" content="">
    
    
    <meta name="description" content="">
    
    <meta name="generator" content="teedoc">
    <meta name="theme" content="teedoc-plugin-theme-default">
    
        
        <meta name="markdown-generator" content="teedoc-plugin-markdown-parser">
        
        <script>
MathJax = {"loader": {"load": ["output/svg"]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}, "svg": {"fontCache": "global"}};
</script>
        
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
        <meta name="html-generator" content="teedoc-plugin-jupyter-notebook-parser">
        
        <meta name="blog-generator" content="teedoc-plugin-blog">
        
        <script src="/static/js/theme_default/pre_main.js"></script>
        
        <link rel="stylesheet" href="/static/css/theme_default/viewer.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/prism.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/theme_default/dark.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/theme_default/light.css" type="text/css"/>
        
        <script src="/static/js/theme_default/jquery.min.js"></script>
        
        <script src="/static/js/theme_default/split.js"></script>
        
        <link rel="stylesheet" href="/static/css/search/style.css" type="text/css"/>
        
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9cb07365544a53067c56c346c838181a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
        
            <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119047820-5"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
  
      gtag('config', 'UA-119047820-5');
    </script>
        
        <link rel="stylesheet" href="/static/css/gitalk/gitalk.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/gitalk/custom_gitalk.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/custom.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/js/thumbs_up/style.css" type="text/css"/>
        
    
    
    <title>V831上部署resnet18分类网络 - Sipeed Wiki</title>
    
    <script type="text/javascript">js_vars = {"teedoc-plugin-ad-hint": {"type": "hint", "label": "NEW", "content": "全新 Maix 系列产品 <a href='https://wiki.sipeed.com/maixcam'>MaixCAM</a> 已上线, 全新 <a href='https://wiki.sipeed.com/maixpy/'>MaixPy</a> 功能更丰富，性能更强大，软件更易用，文档更全面！", "show_times": 2, "show_after_s": 432000, "date": "2022-06-01 14:00", "color": "#a0421d", "link_color": "#e53935", "link_bg_color": "#e6ae5c", "bg_color": "#ffcf89", "color_hover": "white", "bg_color_hover": "#f57c00", "close_color": "#eab971"}, "teedoc-plugin-thumbs-up": {"label_up": "有帮助", "label_down": "待改进", "icon": "/static/images/thumbs_up/up.svg", "icon_clicked": "/static/images/thumbs_up/upped.svg", "url": "https://thumbs-up.sipeed.com", "show_up_count": true, "show_down_count": false, "msg_already_voted": "您已经投过票了", "msg_thanks": "感谢您的反馈", "msg_down_prompt": "感谢反馈，请告诉我们可以改进什么地方?（最少 10 个字）", "msg_down_prompt_error": "消息最少需要 10 个字， 最多 256 个字", "msg_error": "请求服务器出现错误!"}}</script>
    <script type="text/javascript">metadata = {"tags": [], "date": null, "update": [], "ts": 0, "author": "", "brief": "", "cover": ""}</script>
</head>


<body class="type_doc">
    
    <div id="navbar">
        <div id="navbar_menu">
            <a class="site_title" href="/">
                
                    <img class="site_logo" src="/static/image/logo.svg" alt="sipeed wiki logo">
                
                
                    <h2>wiki</h2>
                
        </a>
            <a id="navbar_menu_btn"></a>
        </div>
        <div id="navbar_items">
            <div>
                <ul id="nav_left">
<li class=""><a  href="/">产品</a></li>
<li class="sub_items "><a >开源软件</a><ul><li class=""><a  href="/maixpy/">MaixPy</a></li>
<li class=""><a  href="/soft/maixpy/zh/index.html">MaixPy_v1</a></li>
<li class=""><a  href="/soft/Lichee/zh/index.html">Lichee</a></li>
<li class=""><a  href="/ai/zh/index.html">AI 指南</a></li>
</ul>
</li>
<li class=""><a target="_blank" href="https://maixhub.com">MaixHub</a></li>
<li class=""><a  href="/news/">动态</a></li>
<li class=""><a  href="/faq.html">FAQ 汇总</a></li>
</ul>

            </div>
            <div>
                <ul id="nav_right">
<li class=""><a  href="/store.html"><img src='/static/image/shop.svg' style='height: 1.5em;vertical-align: middle;'></a></li>
<li class=""><a target="_blank" href="https://github.com/sipeed"><img src='/static/image/github.svg' style='height: 1.5em;vertical-align: middle;'></a></li>
</ul>

                <ul class="nav_plugins"><li><a id="google_translate_element"><img class="icon" src="/static/image/google_translate/translate.svg"/>Translate</a></li></ul><ul class="nav_plugins"><li><a id="themes" class="light"></a></li></ul><ul class="nav_plugins"><li><a id="search"><span class="icon"></span><span class="placeholder">搜索</span>
                            <div id="search_hints">
                                <span id="search_input_hint">输入关键词，多关键词空格隔开</span>
                                <span id="search_loading_hint">正在加载，请稍候。。。</span>
                                <span id="search_download_err_hint">下载文件失败，请刷新重试或检查网络</span>
                                <span id="search_other_docs_result_hint">来自其它文档的结果</span>
                                <span id="search_curr_doc_result_hint">当前文档搜索结果</span>
                            </div></a></li></ul>
            </div>
        </div>
    </div>
    
    <div id="wrapper">
        <div id="sidebar_wrapper">
            <div id="sidebar">
                <div id="sidebar_title">
                    
                </div>
                <ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/index.html"><span class="label">MaixPy3 是什么？能做什么？</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/install/install.html"><span class="label">如何获取、安装、使用？</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/tools/MaixPy3_IDE.html"><span class="label">安装或配置 IDE 开发工具</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/tools/0.MaixII-Dock.html"><span class="label">基于 USB 开发 MaixII-Dock</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/tools/maixsense.html"><span class="label">基于 WIFI 开发 MaixSense</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active  with_link"><a href="/news/MaixPy3/v831_usage/v831_usage.html" ><span class="label">M2DOCK (V831)上手视觉指南</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">遇到问题怎么办？</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/origin/helper.html"><span class="label">如何正确反馈问题！</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/question/maixpy3_faq.html"><span class="label">常见问题与解决方法</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">相关的基础知识</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active  with_link"><a href="/news/MaixPy3/difference.html" ><span class="label">MaixPy 和 MaixPy3 的区别</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/origin/video.html"><span class="label">收录一些国内 Python 基础教程</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/origin/hello_world.html"><span class="label">大佬鼠の嵌入式 Python 入门教程 [1]</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/origin/loop_python.html"><span class="label">大佬鼠の嵌入式 Python 入门教程 [2]</span><span class=""></span></a></li>
<li class="not_active  with_link"><a href="https://bing.com/search?q=v831+m2dock" ><span class="label">使用必应搜索 V831 M2DOCK 的内容</span><span class=""></span></a></li>
<li class="not_active  with_link"><a href="https://bbs.sipeed.com/user/909" ><span class="label">咸鱼菌の MaixII-Dock 上手系列教程</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/origin/xiaoxu.html"><span class="label">喏呐の【攻城狮成长记】</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/develop/index.html"><span class="label">开发者更新日志</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/others/framework.html"><span class="label">【项目开发基础】项目架构介绍</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/others/develop.html"><span class="label">【底层开发基础】编译安装测试</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/others/platform.html"><span class="label">【移植适配实例】开发新的平台</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/develop/opmv_cv.html"><span class="label">【图像处理开发】传统视觉算法</span><span class=""></span></a></li>
</ul>
</li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">基础功能模块</span><span class="sub_indicator"></span></a><ul class="show">
<li class="not_active no_link"><a><span class="label">图像处理</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/vision/back-information.html"><span class="label">背景知识</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/vision/maixpy3-example.html"><span class="label">基础用法</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/vision/image_example.html"><span class="label">传统视觉</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">硬件外设</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/GPIO.html"><span class="label">GPIO  (点灯)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/I2C.html"><span class="label">I2C  (pylibi2c)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/PWM.html"><span class="label">PWM  (脉冲宽度调制)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/UART.html"><span class="label">UART  (pyserial)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/SPI.html"><span class="label">SPI  (spidev)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/event.html"><span class="label">EVENT  (evdev)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/ADC.html"><span class="label">ADC*  (模/数转换器)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/hardware/watchdog.html"><span class="label">WATCHDOG*  (看门狗定时器)</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/net.html"><span class="label">网络功能</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">媒体功能</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/Audio/play_mp4.html"><span class="label">视频播放 (pyav)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/Audio/audio.html"><span class="label">录音与播放 (pyaudio)</span><span class=""></span></a></li>
</ul>
</li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">获取 AI 算法</span><span class="sub_indicator"></span></a><ul class="show">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/Edge_detection.html"><span class="label">边缘检测 (sobel)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/resnet.html"><span class="label">物品分类 (resnet)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/yolo.html"><span class="label">物体检测 (yolov2)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/number_recognize.html"><span class="label">数字识别</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/face_recognize.html"><span class="label">人脸识别</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/self_learn.html"><span class="label">自学习分类</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/AI_net/car_registration_plate_recognition.html"><span class="label">车牌识别</span><span class=""></span></a></li>
<li class="not_active  with_link"><a href="https://maixhub.com" ><span class="label">在线训练 AI 模型</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">本地训练 AI 模型</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/train_AI/information.html"><span class="label">深度神经网络基础知识 (必看)</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/train_AI/ready.html"><span class="label">本地训练环境搭建</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/train_AI/v831_sobel.html"><span class="label">边缘检测模型搭建过程</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/train_AI/data.html"><span class="label">如何制作数据集</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/train_AI/train_resnet.html"><span class="label">训练物体分类模型</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/usage/train_AI/train_yolov2.html"><span class="label">训练物体检测模型</span><span class=""></span></a></li>
</ul>
</li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">核心 API 手册</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/soft/maixpy3/zh/api/maix/image.html"><span class="label">image</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/api/maix/display.html"><span class="label">display</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/api/maix/camera.html"><span class="label">camera</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/soft/maixpy3/zh/api/maix/nn.html"><span class="label">nn</span><span class=""></span></a></li>
</ul>
</li>
</ul>

            </div>
        </div>
        <div id="article">
            <div id="menu_wrapper">
                <div id="menu">
                </div>
            </div>
            <div id="content_wrapper">
                <div id="content_body">
                    <div id="article_head">
                        <div id="article_title">
                            
                            <h1>V831上部署resnet18分类网络</h1>
                            
                        </div>
                        <div id="article_tags">
                            <ul>
                            
                            </ul>
                        </div>
                        <div id="article_info">
                        <div id="article_info_left">
                            <span class="article_author">
                                
                            </span>
                            
                                <span class="article_date" title="最后修改日期： 2022-09-22">
                                    2022-09-22
                                </span>
                            
                        </div>
                        <div id="article_info_right">
                            
                            <div id="source_link">
                                <a href="https://github.com/sipeed/sipeed_wiki/blob/main/docs/soft/maixpy3/zh/develop/resnet.md" target="_blank">
                                    <span id='editPage'>编辑本页</span>
                                </a>
                            </div>
                            
                        </div>
                        </div>
                    </div>
                    <div id="article_tools">
                        <span></span>
                        <span id="toc_btn"></span>
                    </div>
                    <div id="update_history">
                        
                    </div>
                    <div id="article_content">
                        
                            <blockquote>
<p>2022年01月11日 以下代码由于 MaixPy3 还在施工中，此处代码仅供参考和示范，功能已在 github 和 社区供其他同学使用和参考。</p>
</blockquote>
<h2 id="%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87">前期准备</h2>
<p>在V831上使用resnet18分类网络，我们需要在linux环境下进行。windows系统可以使用虚拟机，或者是使用WSL，具体的安装教程请自行百度，这里就不过多的进行描述</p>
<h3 id="%E5%AE%89%E8%A3%85pytorch%E7%8E%AF%E5%A2%83">安装pytorch环境</h3>
<p>我们需要在系统中安装pytorch，通过在pytorch官网上可以知道安装pytorch需要执行</p>

<pre class="language-none"><code class="language-none">pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html

</code></pre>
<p>或者是通过conda环境进行安装</p>

<pre class="language-none"><code class="language-none">conda install pytorch torchvision torchaudio cpuonly -c pytorch

</code></pre>
<p>我们还需要安装一个<code>torchsummary</code>库来进行神经网络的可视化</p>

<pre class="language-none"><code class="language-none">pip3 install torchsummary

</code></pre>
<h3 id="%E7%BC%96%E8%AF%91ncnn%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7">编译ncnn转换工具</h3>
<p>通过 <code>git clone https://github.com/Tencent/ncnn.git</code> 将ncnn的仓库拉取到本地，进行编译</p>
<p>安装编译环境的依赖</p>

<pre class="language-bash"><code class="language-bash">sudo apt update
sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev
</code></pre>
<p>编译ncnn需要使用到 Vulkan 后端<br />
要使用 Vulkan 后端，请安装 Vulkan 头文件、一个 vulkan 驱动程序加载器、GLSL 到 SPIR-V 编译器和 vulkaninfo 工具。或者从<a href="https://vulkan.lunarg.com/sdk/home"  target="_blank">https://vulkan.lunarg.com/sdk/home</a>下载并安装完整的 Vulkan SDK（大约 200MB；它包含所有头文件、文档和预构建的加载程序，以及一些额外的工具和所有源代码）</p>

<pre class="language-bash"><code class="language-bash">wget https://sdk.lunarg.com/sdk/download/1.2.182.0/linux/vulkansdk-linux-x86_64-1.2.182.0.tar.gz
tar xvf vulkansdk-linux-x86_64-1.2.182.0.tar.gz
export VULKAN_SDK=$(pwd)/1.2.182.0/x86_64
</code></pre>
<p>拉取ncnn的子仓库</p>

<pre class="language-bash"><code class="language-bash">cd ncnn
git submodule update --init
</code></pre>
<p>开始编译ncnn</p>

<pre class="language-bash"><code class="language-bash">mkdir -p build
cd build
cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_SYSTEM_GLSLANG=ON -DNCNN_BUILD_EXAMPLES=ON ..
make -j$(nproc)
</code></pre>
<p>编译结束之后会在build/tools/onnx/下的到onnx2ncnn可执行文件，这个是就用ncnn的转换工具</p>
<blockquote>
<p>将编译出来的 onnx2ncnn 添加到系统的环境变量中</p>
</blockquote>
<h2 id="%E8%8E%B7%E5%8F%96%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86">获取模型并进行推理</h2>
<blockquote>
<p>以下代码建议在jupyter中运行</p>
</blockquote>
<p>通过pytorch hub来获取resnet18的预训练模型，这里并不细说训练的过程和模型定义</p>
<p>label<a href="https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"  target="_blank">下载</a><br />
使用以下代码进行模型的下载和推理</p>

<pre class="language-python"><code class="language-python">import os
import torch
from torchsummary import summary
torch.hub._validate_not_a_forked_repo=lambda a,b,c: True
## model
model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)
model.eval()
input_shape = (3, 224, 224)
summary(model, input_shape, device=&quot;cpu&quot;)
## test image
filename = &quot;out/dog.jpg&quot;
if not os.path.exists(filename):
    if not os.path.exists(&quot;out&quot;):
        os.makedirs(&quot;out&quot;)
    import urllib
    url, filename = (&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;, filename)
    try: urllib.URLopener().retrieve(url, filename)
    except: urllib.request.urlretrieve(url, filename)
print(&quot;test image:&quot;, filename)
## preparing input data
from PIL import Image
import numpy as np
from torchvision import transforms
input_image = Image.open(filename)
# input_image.show()
preprocess = transforms.Compose([
    transforms.Resize(max(input_shape[1:3])),
    transforms.CenterCrop(input_shape[1:3]),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
input_tensor = preprocess(input_image)
print(&quot;input data max value: {}, min value: {}&quot;.format(torch.max(input_tensor), torch.min(input_tensor)))
input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model
## forward model
# move the input and model to GPU for speed if available
if torch.cuda.is_available():
    input_batch = input_batch.to('cuda')
    model.to('cuda')
with torch.no_grad():
    output = model(input_batch)
## result    
# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes
# print(output[0])
# The output has unnormalized scores. To get probabilities, you can run a softmax on it.
max_1000 = torch.nn.functional.softmax(output[0], dim=0)
max_idx = int(torch.argmax(max_1000))
with open(&quot;imagenet_classes.txt&quot;) as f:
    labels = f.read().split(&quot;\n&quot;)
print(&quot;result: idx:{}, name:{}&quot;.format(max_idx, labels[max_idx]))
</code></pre>
<p>运行后得到结果:</p>

<pre class="language-python"><code class="language-python">Using cache found in /home/neucrack/.cache/torch/hub/pytorch_vision_v0.6.0
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19          [-1, 128, 28, 28]          73,728
      BatchNorm2d-20          [-1, 128, 28, 28]             256
             ReLU-21          [-1, 128, 28, 28]               0
           Conv2d-22          [-1, 128, 28, 28]         147,456
      BatchNorm2d-23          [-1, 128, 28, 28]             256
           Conv2d-24          [-1, 128, 28, 28]           8,192
      BatchNorm2d-25          [-1, 128, 28, 28]             256
             ReLU-26          [-1, 128, 28, 28]               0
       BasicBlock-27          [-1, 128, 28, 28]               0
           Conv2d-28          [-1, 128, 28, 28]         147,456
      BatchNorm2d-29          [-1, 128, 28, 28]             256
             ReLU-30          [-1, 128, 28, 28]               0
           Conv2d-31          [-1, 128, 28, 28]         147,456
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 256, 14, 14]         294,912
      BatchNorm2d-36          [-1, 256, 14, 14]             512
             ReLU-37          [-1, 256, 14, 14]               0
           Conv2d-38          [-1, 256, 14, 14]         589,824
      BatchNorm2d-39          [-1, 256, 14, 14]             512
           Conv2d-40          [-1, 256, 14, 14]          32,768
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
       BasicBlock-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 14, 14]         589,824
      BatchNorm2d-45          [-1, 256, 14, 14]             512
             ReLU-46          [-1, 256, 14, 14]               0
           Conv2d-47          [-1, 256, 14, 14]         589,824
      BatchNorm2d-48          [-1, 256, 14, 14]             512
             ReLU-49          [-1, 256, 14, 14]               0
       BasicBlock-50          [-1, 256, 14, 14]               0
           Conv2d-51            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-52            [-1, 512, 7, 7]           1,024
             ReLU-53            [-1, 512, 7, 7]               0
           Conv2d-54            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
           Conv2d-56            [-1, 512, 7, 7]         131,072
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       BasicBlock-59            [-1, 512, 7, 7]               0
           Conv2d-60            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-61            [-1, 512, 7, 7]           1,024
             ReLU-62            [-1, 512, 7, 7]               0
           Conv2d-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       BasicBlock-66            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
           Linear-68                 [-1, 1000]         513,000
================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 62.79
Params size (MB): 44.59
Estimated Total Size (MB): 107.96
----------------------------------------------------------------
out/dog.jpg
tensor(2.6400) tensor(-2.1008)
idx:258, name:Samoyed, Samoyede

</code></pre>
<p>可以看到模型有 11,689,512的参数， 即 11MiB左右， 这个大小也就几乎是实际在 831 上运行的模型的大小了</p>
<h2 id="%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2">模型转换</h2>
<h3 id="pth%E8%BD%AConnx">pth转onnx</h3>
<p>通过pytorch hub获取到的resnet18 模型是pth格式的，需要转换成onnx格式的模型</p>
<p>转换代码</p>

<pre class="language-python"><code class="language-python">def torch_to_onnx(net, input_shape, out_name=&quot;out/model.onnx&quot;, input_names=[&quot;input0&quot;], output_names=[&quot;output0&quot;], device=&quot;cpu&quot;):
    batch_size = 1
    if len(input_shape) == 3:
        x = torch.randn(batch_size, input_shape[0], input_shape[1], input_shape[2], dtype=torch.float32, requires_grad=True).to(device)
    elif len(input_shape) == 1:
        x = torch.randn(batch_size, input_shape[0], dtype=torch.float32, requires_grad=False).to(device)
    else:
        raise Exception(&quot;not support input shape&quot;)
    print(&quot;input shape:&quot;, x.shape)
    # torch.onnx._export(net, x, &quot;out/conv0.onnx&quot;, export_params=True)
    torch.onnx.export(net, x, out_name, export_params=True, input_names = input_names, output_names=output_names)
onnx_out=&quot;out/resnet_1000.onnx&quot;
ncnn_out_param = &quot;out/resnet_1000.param&quot;
ncnn_out_bin = &quot;out/resnet_1000.bin&quot;
input_img = filename
torch_to_onnx(model, input_shape, onnx_out, device=&quot;cuda:0&quot;)

</code></pre>
<p>在out文件夹中得到onnx格式模型文件</p>
<h3 id="onnx%E8%BD%ACncnn">onnx转ncnn</h3>
<p>然后再利用前面编译出来的onnx2ncnn转换工具进行ncnn格式的转换</p>

<pre class="language-python"><code class="language-python">def onnx_to_ncnn(input_shape, onnx=&quot;out/model.onnx&quot;, ncnn_param=&quot;out/conv0.param&quot;, ncnn_bin = &quot;out/conv0.bin&quot;):
    import os
    # onnx2ncnn tool compiled from ncnn/tools/onnx, and in the buld dir
    cmd = f&quot;onnx2ncnn {onnx} {ncnn_param} {ncnn_bin}&quot;
    os.system(cmd)
    with open(ncnn_param) as f:
        content = f.read().split(&quot;\n&quot;)
        if len(input_shape) == 1:
            content[2] += &quot; 0={}&quot;.format(input_shape[0])
        else:
            content[2] += &quot; 0={} 1={} 2={}&quot;.format(input_shape[2], input_shape[1], input_shape[0])
        content = &quot;\n&quot;.join(content)
    with open(ncnn_param, &quot;w&quot;) as f:
        f.write(content)
onnx_to_ncnn(input_shape, onnx=onnx_out, ncnn_param=ncnn_out_param, ncnn_bin=ncnn_out_bin)
</code></pre>
<blockquote>
<p>这里需要确定 onnx2ncnn 是可以使用的命令，否则会无法使用这个函数进行模型转换</p>
</blockquote>
<h3 id="ncnn%E9%87%8F%E5%8C%96%E5%88%B0int8%E6%A8%A1%E5%9E%8B">ncnn量化到int8模型</h3>
<p>通过 MaixHub 将ncnn模型进行量化到int8模型</p>
<p>在 MaixHub 模型转换 将 ncnn 模型转换为 awnn 支持的 int8 模型 （网页在线转换很方便人为操作，另一个方面因为全志要求不开放 awnn 所以暂时只能这样做）</p>
<p>阅读转换说明，可以获得更多详细的转换说明<br />
<img src="./../asserts/maixhub.jpg" alt="" /></p>
<p>这里有几组参数：</p>
<ul>
<li><p>均值 和 归一化因子： 在 pytorch 中一般是 (输入值 - mean ) / std, awnn对输入的处理是 (输入值 - mean ) * norm, 总之，让你训练的时候的输入到第一层网络的值范围和给awnn量化工具经过(输入值 - mean ) * norm 计算后的值范围一致既可。 比如 这里打印了实际数据的输入范围是[-2.1008, 2.6400]， 是代码中preprocess 对象处理后得到的，即x = (x - mean) / std ==&gt; (0-0.485)/0.229 = -2.1179, 到awnn就是x = (x - mean_2*255) * (1 / std * 255) 即 mean2 = mean * 255, norm = 1/(std * 255), 更多可以看这里。</p>
</li>
<li><p>所以我们这里可以设置 均值为 0.485 * 255 = 123.675， 设置 归一化因子为1/ (0.229 * 255) = 0.017125， 另外两个通道同理，但是目前 awnn 只能支持三个通道值一样。。。所以填123.675, 123.675, 123.675，0.017125, 0.017125, 0.017125 即可，因为这里用了pytorch hub的预训练的参数，就这样吧， 如果自己训练，可以好好设置一下图片输入层尺寸（问不是图片怎么办？貌似 awnn 暂时之考虑到了图片。。）</p>
</li>
<li><p>RGB 格式： 如果训练输入的图片是 RGB 就选</p>
</li>
<li><p>RGB量化图片， 选择一些和输入尺寸相同的图片，可以从测试集中拿一些，不一定要图片非常多，但尽量覆盖全场景（摊手</p>
</li>
</ul>
<blockquote>
<p>自己写的其它模型转换如果失败，多半是啥算子不支持，需要在 使用说明里面看支持的 算子，比如现在的版本view、 flatten、reshape 都不支持所以写模型要相当小心， 后面的版本会支持 flatten reshape 等 CPU 算子</p>
</blockquote>
<p>如果不出意外， 终于得到了量化好的 awnn 能使用的模型， *.param 和 *.bin</p>
<h2 id="%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%9C%A8v831%E4%B8%8A%E6%8E%A8%E7%90%86">使用模型，在v831上推理</h2>
<p>可以使用 python 或者 C 写代码，以下两种方式</p>
<p>python的是需要在终端下运行的，不要使用jupyter，建议使用ssh，这样放文件什么都比较方便</p>
<h3 id="MaixPy3">MaixPy3</h3>
<p>python 请看MaixPy3</p>
<p>不想看文档的话，就是在系统开机使用的基础上， 更新 MaixPy3 就可以了：</p>

<pre class="language-none"><code class="language-none">export TMPDIR=/root &amp;&amp; pip install --upgrade maixpy3

</code></pre>
<p>然后在终端使用 python 运行脚本（可能需要根据你的文件名参数什么的改一下代码）：</p>
<p><a href="https://github.com/sipeed/MaixPy3_scripts/blob/main/basic/v1.0/resnet.py"  target="_blank">https://github.com/sipeed/MaixPy3_scripts/blob/main/basic/v1.0/resnet.py</a></p>
<p>label 在这里： <a href="https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/classes_label.py"  target="_blank">https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/classes_label.py</a></p>
<p>baars.ttf 在这里：<a href="https://github.com/sipeed/MaixPy3_scripts/blob/main/application/base/res/baars.ttf"  target="_blank">https://github.com/sipeed/MaixPy3_scripts/blob/main/application/base/res/baars.ttf</a></p>

<pre class="language-python"><code class="language-python">from maix import camera, nn, display
from home.res.classes_label import labels
class Resnset:
    m = {
        &quot;param&quot;: &quot;/home/model/resnet18_1000_awnn.param&quot;,
        &quot;bin&quot;: &quot;/home/model/resnet18_1000_awnn.bin&quot;
    }
    options = {
        &quot;model_type&quot;:  &quot;awnn&quot;,
        &quot;inputs&quot;: {
            &quot;input0&quot;: (224, 224, 3)
        },
        &quot;outputs&quot;: {
            &quot;output0&quot;: (1, 1, 1000)
        },
        &quot;first_layer_conv_no_pad&quot;: False,
        &quot;mean&quot;: [127.5, 127.5, 127.5],
        &quot;norm&quot;: [0.00784313725490196, 0.00784313725490196, 0.00784313725490196],
    }
    def __init__(self):
        from maix import nn
        self.model = nn.load(self.m, opt=self.options)

    def __del__(self):
        del self.model




while True:
    img = camera.capture().resize(224, 224)
    tmp = img.tobytes()
    out = resnset.model.forward(tmp, quantize=True)
    out2 = nn.F.softmax(out)
    msg = &quot;{:.2f}: {}&quot;.format(out2.max(), labels[out.argmax()])
    img.draw_string(0, 0, str(msg), 0.5, (255, 0, 0), 1)
    display.show(img)
</code></pre>
<blockquote>
<p>如果运行报错了，请更新maixpy3再运行</p>
</blockquote>
<h3 id="C%E8%AF%AD%E8%A8%80-SDK%EF%BC%8C-libmaix">C语言 SDK， libmaix</h3>
<p>访问这里，按照 <a href="https://github.com/sipeed/libmaix"  target="_blank">https://github.com/sipeed/libmaix</a> 的说明克隆仓库，并编译 <a href="https://github.com/sipeed/libmaix/tree/master/examples/nn_resnet"  target="_blank">https://github.com/sipeed/libmaix/tree/master/examples/nn_resnet</a></p>
<p>上传编译成功后dist目录下的所有内容到 v831, 然后执行./start_app.sh即可</p>
<blockquote>
<p>以上内容出至：<a href="https://neucrack.com/p/358"  target="_blank">https://neucrack.com/p/358</a></p>
</blockquote>

                        
                    </div>
                </div>
                <div id="previous_next">
                    <div id="previous">
                        
                    </div>
                    <div id="next">
                        
                    </div>
                </div>
                <div id="comments-container"></div>
            </div>
            <div id="toc_wrapper">
                <div id="toc">
                    <div id="toc_content">
                            
                    </div>
                </div>
            </div>
        </div>
    </div>
    <a id="to_top" href="#"></a>
    <div id="doc_footer">
        <div id="footer">
            <div id="footer_top">
                <ul>
<li><a>相关链接</a><ul><li><a target="_blank" href="https://www.sipeed.com">Sipeed 官网</a></li>
<li><a target="_blank" href="https://maixhub.com/">MaixHub</a></li>
<li><a target="_blank" href="https://sipeed.taobao.com/">Sipeed 淘宝</a></li>
<li><a  href="/sitemap.xml">网站地图</a></li>
<li><a target="_blank" href="https://github.com/teedoc/teedoc">网站使用 teedoc 生成</a></li>
</ul>
</li>
<li><a>源码</a><ul><li><a target="_blank" href="https://github.com/sipeed/sipeed_wiki">Wiki 源码</a></li>
<li><a target="_blank" href="https://github.com/sipeed">开源项目</a></li>
</ul>
</li>
<li><a>关注我们</a><ul><li><a target="_blank" href="https://twitter.com/SipeedIO">twitter</a></li>
<li><a target="_blank" href="https://sipeed.taobao.com/">淘宝</a></li>
<li><a target="_blank" href="https://github.com/sipeed">github</a></li>
<li><a><a>微信公众号</a><img src='/static/image/wechat.png'></a>
</li>
</ul>
</li>
<li><a>联系我们</a><ul><li><a>电话: +86 0755-27808509</a>
</li>
<li><a>商业支持: support@sipeed.com</a>
</li>
<li><a>地址: 深圳市宝安区新湖路4008号蘅芳科技办公大厦A座-2101C</a>
</li>
<li><a  href="/join_us.html">加入我们</a></li>
</ul>
</li>
</ul>

            </div>
            <div id="footer_bottom">
                <ul>
<li><a target="_blank" href="https://www.sipeed.com">©2018-2023 深圳矽速科技有限公司</a></li>
<li><a target="_blank" href="https://beian.miit.gov.cn/#/Integrated/index">粤ICP备19015433号</a></li>
</ul>

            </div>
        </div>
    </div>
    
        <script src="/teedoc-plugin-markdown-parser/mermaid.min.js"></script>
    
        <script>mermaid.initialize({startOnLoad:true});</script>
    
        <script type="text/javascript">
                var transLoaded = false;
                var loading = false;
                var domain = "translate.google.com";
                var domainDefault = domain;
                var storeDomain = localStorage.getItem("googleTransDomain");
                if(storeDomain){
                    domain = storeDomain;
                    console.log("load google translate domain from local storage:" + domain);
                }
                function getUrl(domain){
                    if(domain == "/")
                        return "/static/js/google_translate/element.js?cb=googleTranslateElementInit";
                    else
                        return "https://" + domain + "/translate_a/element.js?cb=googleTranslateElementInit";
                }
                var url = getUrl(domain);
                console.log("google translate domain:" + domain + ", url: " + url);
                function googleTranslateElementInit() {
                    new google.translate.TranslateElement({pageLanguage: "auto", layout: google.translate.TranslateElement.InlineLayout.SIMPLE}, 'google_translate_element');
                }
                function loadJS( url, callback ){
                    var script = document.createElement('script');
                    fn = callback || function(){ };
                    script.type = 'text/javascript';
                    if(script.readyState){
                        script.onreadystatechange = function(){
                            if( script.readyState == 'loaded' || script.readyState == 'complete' ){
                                script.onreadystatechange = null;
                                fn();
                            }
                        };
                    }else{
                        script.onload = function(){
                            fn();
                        };
                    }
                    script.src = url;
                    document.getElementsByTagName('head')[0].appendChild(script);
                }
                function removeHint(){
                    var hint = document.getElementById("loadingTranslate");
                    if(hint){
                        hint.remove();
                    }
                }
                var btn = document.getElementById("google_translate_element");
                btn.onclick = function(){
                    if(transLoaded) return;
                    if(loading){
                        var flag = confirm("loading from " + domain + ", please wait, or change domain?");
                        if(flag){
                            newDomain = prompt("domain, default: " + domainDefault + ", now: " + domain);
                            if(newDomain){
                                domain = newDomain;
                                console.log(domain);
                                url = getUrl(domain);
                                loadJS(url, function(){
                                    localStorage.setItem("googleTransDomain", domain);
                                    removeHint()
                                    transLoaded = true;
                                });
                            }
                        }
                        return;
                    }
                    btn.innerHTML = '<span id="loadingTranslate"><img class="icon" src="/static/image/google_translate/translate.svg"/>Loading ...</span>';
                    loading = true;
                    loadJS(url, function(){
                        localStorage.setItem("googleTransDomain", domain);
                        removeHint()
                        transLoaded = true;
                    });
                }
                </script>
            
    
        <script src="/static/js/plugin_blog/main.js"></script>
    
        <script src="/static/js/theme_default/tocbot.min.js"></script>
    
        <script src="/static/js/theme_default/main.js"></script>
    
        <script src="/static/js/theme_default/viewer.min.js"></script>
    
        <script src="/static/js/prism.js"></script>
    
        <script src="/static/js/search/search_main.js"></script>
    
        <script src="/static/js/gitalk/gitalk.min.js"></script>
    
        <script src="/static/js/gitalk/main.js"></script>
    
        <link rel="stylesheet" href="/static/js/add_hint/style.css" type="text/css"/>
    
        <script src="/static/js/add_hint/main.js"></script>
    
        <script src="/static/js/custom.js"></script>
    
        <script src="/static/js/thumbs_up/main.js"></script>
    
</body>

</html>