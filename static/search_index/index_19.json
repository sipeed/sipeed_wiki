{"/news/Lichee/nano/first_eat.md/first_eat.html":{"title":"Licheepi Nano 使用 TF 卡运行 linux","content":" title: Licheepi Nano 使用 TF 卡运行 linux keywords: Lichee, nano, f1c, linux, 编译, kernel, uboot, buildboot desc: Licheepi nano 全流程 date: 2022 12 06 tags: linux, f1c, compile 原文链接：[嵌入式 linux 入门 4 1 荔枝派 nano 使用 TF 卡运行 linux](https://codinglover.top/2022/03/25/%E5%B5%8C%E5%85%A5%E5%BC%8Flinux%E5%85%A5%E9%97%A84 1 %E8%8D%94%E6%9E%9D%E6%B4%BEnano%E4%BD%BF%E7%94%A8tf%E5%8D%A1%E8%BF%90%E8%A1%8Clinux/) 有改动 <! more > ## \\[简易\\]使用一键脚本构建系统到 TF 卡 1. 去如下位置下载 Lichee Nano 文件夹的所有内容：https://pan.baidu.com/s/1smzuGS9 2. 进入 Lichee Nano/镜像/寻找自己需要的固件，我这里用的 Nano_pub_V4.zip 3. 解压，进入其下的 image 文件找自己需要的镜像，我这里使用 Nano_tf_800480.dd 4. 插上 TF 卡，使用 dd 命令将镜像复制到 TF 卡（windows 用户使用 balenaEtcher 软件烧录） ```bash sudo dd of tf卡路径 if 镜像文件路径 ``` 完成，如果只是为了简单使用，那下面的流程不用看了，用这种方法有个问题，那就是根目录的可用空间只有不到 200M，并不能使用 TF 卡的所有空间，不过对于简单应用也足够了。具体解决方法可以前往 [github](https://github.com/sipeed/Nano Doc Backup/blob/master/build_sys/onekey.md#%E8%84%9A%E6%9C%AC%E7%9A%84%E4%BD%BF%E7%94%A8) 查看。 ## \\[复杂\\]手动构建荔枝派 TF 卡内的系统 本次编译用的宿主机为 ubuntu20.04 ### 安装交叉编译链 \\# 此处为获取 7.2.1 版本，您可获取其他版本或者通过链接直接下载 ```bash wget http://releases.linaro.org/components/toolchain/binaries/7.2 2017.11/arm linux gnueabi/gcc linaro 7.2.1 2017.11 x86_64_arm linux gnueabi.tar.xz tar vxJf gcc linaro 7.2.1 2017.11 x86_64_arm linux gnueabi.tar.xz sudo cp r ./gcc linaro 7.2.1 2017.11 x86_64_arm linux gnueabi /opt/ sudo vi /etc/bash.bashrc # 在文件末尾 添加以下内容 PATH \"$PATH:/opt/gcc linaro 7.2.1 2017.11 x86_64_arm linux gnueabi/bin\" # 添加完毕 # 使路径生效 source /etc/bash.bashrc #查询版本进行测试，如果成功会打印版本信息 arm linux gnueabi gcc v ``` ### 获取并编译 u boot 1. 获取 u boot ```bash sudo apt get install git git clone https://github.com/Lichee Pi/u boot.git cd u boot # 查看分支 git branch a # 切换到 Nano 分支 git checkout nano v2018.01 ``` 2. 编译 u boot ```bash # 此处告知 make 采用 arm linux gnueabi 下的所有交叉编译工具，目标架构为 Arm，设定各项默认配置为 nano 的 spiflash 支持版 make ARCH arm CROSS_COMPILE arm linux gnueabi licheepi_nano_spiflash_defconfig # 若不带 spi flash 的板子，请换成 licheepi_nano_defconfig # 进行可视化配置，我没有配置，直接按默认就行了 make ARCH arm menuconfig # 开始编译 make ARCH arm CROSS_COMPILE arm linux gnueabi j8 ``` 编译完成后在 u boot 目录下找到 u boot sunxi with spl.bin 文件即为可烧录的文件 附一些错误的解决办法（都是本次遇到的） ```bash # 如果在可视化配置时提示 : fatal error: curses.h: No such file or directory，进行如下一步来安装支持环境 sudo apt get install libncurses5 dev libncursesw5 dev # 如果在编译时提示/bin/sh: 1: python: not found，安装 python 即可 sudo apt get install python # 如果编译时提示 unable to execute 'swig': No such file or directory，安装 swig 即可 sudo apt get install swig # 如果编译时提示 fatal error: Python.h: No such file or directory，安装 python dev sudo apt get install python dev ``` ### 烧录 u boot 荔枝派 nano 使用的是全志的 F1C100s，官方提供了烧录工具 sunxi tools，用来对处于 fel 模式下的芯片进行程序烧录。 首先需要获取并编译安装烧录工具: ```bash # 如果提示缺少 libusb.h，要先安装 libusb 库 sudo apt get install libusb 1.0 0 dev # 如果提示缺少 zlib.h，要先安装 libusb 库 sudo apt get install zlib1g dev libssl dev # 获取并编译安装 sunxi tools git clone b f1c100s spiflash https://github.com/Icenowy/sunxi tools.git cd sunxi tools make && sudo make install ``` 拉低板子上 spi1 外设的 cs 引脚之后连接 usb 以进入 fel 模式，此时执行以下流程烧录 u boot： ```bash # 2.烧进 spi flash （开机自启） sudo sunxi fel p spiflash write 0 u boot sunxi with spl.bin 所在路径 ``` 烧录成功后，通过核心板的 U0RX 和 U0TX 串口引脚来连接串口调试期进行 u boot 命令行交互，默认的波特率为 115200。 ### 构建 TF 卡系统分区 **需要在 TF 卡上构建两个分区** 分区 1 用于存放系统启动和内核相关文件，格式化为 FAT，一般只需要分配 32MiB 空间 boot.scr (指引 u boot 加载内核的文件) zImage (系统内核) suniv f1c100s licheepi nano.dtb (设备树文件) 分区 2 用于存放根文件系统，格式化为 ext4 格式，分配所有剩余的空间 **使用 fdisk 工具进行格式化** ```bash sudo fdisk l # 首先查看电脑上已插入的 TF 卡的设备号 sudo umount /dev/sdXx # 若自动挂载了 TF 设备，请先卸载 sudo fdisk /dev/sdX # 进行分区操作 # 若已存分区即按 d 删除各个分区 # 通过 n 新建分区，第一分区暂且申请为 32M(足够大了...)，剩下的空间都给第二分区 # w 保存写入并退出 sudo mkfs.vfat /dev/sdX1 # 将第一分区格式化成 FAT sudo mkfs.ext4 /dev/sdX2 # 将第一分区格式化成 EXT4 ``` 使用 parted 命令查看格式化后的结果 ```bash sudo parted l ``` ![sdcard_partition](./assets/sdcard_partition.jpg) ### 配置 u boot 的启动脚本 提前打开 nano 板子 u boot 的输出命令行对应的串口，在板子上电时按 enter 键进入 u boot 命令行，然后输入**printenv**指令查看环境变量信息，我显示的信息如下，#号后是我添加的对关键信息的说明： ```bash arch arm # 板子的架构 baudrate 115200 # 命令行串口波特率 board sunxi board_name sunxi #略去中间大段信息 boot_scripts boot.scr.uimg boot.scr # 启动时寻找名为boot.scr.uimg或boot.scr的启动脚本 boot_targets fel mmc0 usb0 pxe dhcp # 启动介质的优先级优先从排在前面的介质引导系统 bootcmd run distro_bootcmd # 启动时要执行的指令？唔。。。不太明白 #略去后面信息 ``` 根据 boot_scripts 变量我们知道我们要编写一个名为 boot.scr 的启动脚本，然后将这个脚本放到 TF 卡的第一个分区（FAT 分区），u boot 启动时就会去找这个脚本执行了。 还记得我们编译 u boot 时获取的 u boot 源码吗，在其下的 tools 目录中有一个 mkimage 工具可以用于生成 boot.scr，为了生成 boot.scr，首先需要编写 boot.cmd 脚本用来指导 mkimage 进行生成，脚本内容如下： ```bash setenv bootargs console tty0 console ttyS0,115200 panic 5 rootwait root /dev/mmcblk0p2 rw load mmc 0:1 0x80C00000 suniv f1c100s licheepi nano.dtb load mmc 0:1 0x80008000 zImage bootz 0x80008000 0x80C00000 ``` 第一行 setenv 命令，设定了变量 bootargs(启动参数)为：通过 tty0 和 ttyS0 串口输出启动信息；启动失败延迟 5 秒重启，根文件在 TF 卡的第二分区，可读写； 第二行指定了从 TF 中将设备树的 dtb 文件加载到 0x80C00000 的位置(地址参考自官方 SDK) 第三行指定了将压缩后的内核 zImage 加载到 0x80008000 的位置 第四行为从加载地址启动内核的命令 然后就可以生成 boot.scr 文件了，进入 mkimage 所在目录，然后执行如下指令： ```bash mkimage C none A arm T script d ``` 结果如下： ![set_boot_configurations](./assets/set_boot_configurations.png) 将生成的 boot.scr 拷贝到 TF 卡的 FAT 分区中即可。 ### 编译 Linux 内核 1. 下载 Linux 源码 完整的下载命令为： ```bash git clone https://github.com/Icenowy/linux.git ``` git 拉取有时速度很慢，建议做如下配置： ```bash sudo vim /etc/hosts # 添加下面两行 192.30.253.112 github.com 151.101.73.194 github.global.ssl.fastly.net # 添加完成 # 可自行通过dns检测网站检测github.global.ssl.fastly.net，更换为更快的ip地址 ``` 完整拉取 linux 极大，建议只拉取单层分支，减少等待时间： ```bash git clone depth 1 b f1c100s 480272lcd test https://github.com/Icenowy/linux.git ``` 这里只拉取了单层分支 2. 配置源码 ```bash wget dl.sipeed.com/LICHEE/Nano/SDK/config # 下载配置文件 mv config /linux源码目录/.config # 移动到linux源码主目录并重命名为.config # 也可以使用以下指令进行进一步的配置 make ARCH arm menuconfig ``` 3. 编译源码 进入 linux 源码主目录后，进行如下操作 ```bash #配置架构，然后使用可视化配置工具对源码进行配置 make ARCH arm menuconfig # 这里可以直接退出配置界面，我们用默认配置就行了 #配置编译用的工具链前缀 make ARCH arm CROSS_COMPILE arm linux gnueabi j4 #请自行修改编译线程数 ``` 4. 编译过程中碰到的问题记录 1. 编译过程中提示是否需要使能某些配置 这是因为配置文件中没有对应的配置项，根据情况选择，我一律选择了 n，不需要它们。 2. 提示 fatal error: openssl/bio.h: No such file or directory ```bash sudo apt install libssl dev # 缺少这个库 ``` 编译要挺长的时间，这取决于机器性能。编译成功后，显示如下信息： ![compile_kernel](./assets/compile_kernel.png) 这时到 linux 源码目录下的 arch/arm/boot/目录中可以找到内核镜像 zImage，将其拷贝到 TF 卡的 FAT 第一分区。 ### 配置设备树 [设备树添加节点](https://wiki.sipeed.com/soft/Lichee/zh/Nano Doc Backup/build_sys/devicetree.html)这一章节有详细介绍，有需要的可以自行查看。由于本次只使用核心板，所以不用配置 dts 文件，直接编译生成 dtb 就行了。 荔枝派 Nano 对应的 dts 文件为 Linux 源码主目录下的 arch/arm/boot/dts/suniv f1c100s licheepi nano.dts 进入 Linux 源码的主目录，之后执行以下指令编译 dtb 文件： ```bash make ARCH arm CROSS_COMPILE arm linux gnueabi dtbs j4 ``` 编译成功后，在 Linux 源码的主目录的 arch/arm/boot/dts/下可以找到 suniv f1c100s licheepi nano.dtb 文件（这个文件的文件名和前面生成 boot.scr 时在 boot.cmd 中设置的文件名一致），将其复制到 TF 卡的 FAT 第一分区。 ### 构建根文件系统 使用 buildroot 构建根文件系统，流程如下： 1. 下载安装 ```bash # 获取所需的头文件 sudo apt install linux headers $(uname r) #uname r用于获取内核版本号 # 下载、解压、进入目录（这个国外链接下载有点慢） wget https://buildroot.org/downloads/buildroot 2017.08.tar.gz tar xvf buildroot 2017.08.tar.gz cd buildroot 2017.08/ ``` 2. 配置 buildroot 工具 ```bash # 进入配置界面 make menuconfig 以下选项为基础配置： Target options Target Architecture (ARM (little endian)) Target Variant arm926t Toolchain C library (musl) # 使用musl减小最终体积 System configuration Use syslinks to /usr .... # 启用/bin, /sbin, /lib的链接 Enable root login # 启用root登录 Run a getty after boot # 启用登录密码输入窗口 (licheepi) Root password #　默认账户为root 密码为licheepi 另可自行添加或删除指定的软件包 ``` 3. 编译 ```bash make ``` 由于编译过程中需要下载软件包以及不支持多线程编译，编译需要很长时间（晚上丢那编译，一觉醒来就好了），编译完成后的文件为 buildroot 目录下的 output/images/rootfs.tar tips： 若编译时，buildroot 下载软件包速度太慢，请下载 dl.zip ，将其中的软件包解压至 buildroot 的 dl 下目录（官方文档的解决方法）； 或者也可以考虑使用 vi 打开 buildroot 的.config 文件，将其中的对应配置切换为以下内容以切换到国内镜像站进行下载（个人推荐此方法）： ``` BR2_BACKUP_SITE \"http://sources.buildroot.net\" BR2_KERNEL_MIRROR \"https://mirror.bjtu.edu.cn/kernel/\" BR2_GNU_MIRROR \"http://mirrors.nju.edu.cn/gnu/\" BR2_LUAROCKS_MIRROR \"https://luarocks.cn\" BR2_CPAN_MIRROR \"http://mirrors.nju.edu.cn/CPAN/\" ``` 4. 编译过程中的问题解决记录 1. error \"Please port gnulib freadahead.c to your platform!类似的错误 ```bash # 进入buildroot下的如下目录 cd output/build/host m4 1.4.18/ # 执行如下指令（查了半天，没搞懂是干嘛的） sed i 's/IO_ftrylockfile/IO_EOF_SEEN/' lib/*.c # 在lib/stdio impl.h文件最后新增一行#define _IO_IN_BACKUP 0x100 echo \"#define _IO_IN_BACKUP 0x100\" >> lib/stdio impl.h # 之后返回buildroot主目录执行make继续编译 # stackoverflow上一位老哥说了出现这个问题的原因，不知道是不是对的 # This was an interoperability problem between GNU m4 1.4.18 and # newer glibc header files. # It is fixed in GNU m4 1.4.19, available from # https://ftp.gnu.org/gnu/m4/ and the GNU mirrors. ``` 编译完成后，文件为 buildroot 下的 output/images/rootfs.tar，将其复制到 TF 卡的 ext4 第二分区并解压。 ### 验证 将 TF 卡插入荔枝派 nano，使用 USB 转 TTL 模块连接荔枝派的 U0TX 和 U0RX 这对串口，应该就正常上电进入登录界面了。 ![boot_licheepi_nano](./assets/boot_licheepi_nano.jpg) 使用用户名 root，密码 licheepi 进行登录即可。 使用 fdisk 指令，根文件系统已经可以识别 TF 卡中的所有空闲空间 ![licheepi_fdisk](./assets/licheepi_fdisk.jpg)"},"/news/Lichee/RV/D1_RTL8723DS_Drivers/D1_RTL8723DS_Drivers.html":{"title":"D1 LicheeRV Dock 移植RTL8723DS驱动","content":" title: D1 LicheeRV Dock 移植RTL8723DS驱动 keywords: D1, RTL8723DS, 驱动 desc: RTL8723DS驱动移植 date: 2022 04 02 tags: linux, D1 这里讲解怎样自己添加驱动 <! more > [原文链接](https://bbs.aw ol.com/topic/994/d1 licheerv dock %E7%A7%BB%E6%A4%8Drtl8723ds%E9%A9%B1%E5%8A%A8) 手动焊接RTL8723DS之后，现在开始移植驱动程序。 先获取源码：https://github.com/lwfinger/rtl8723ds 下载完成后，把驱动文件复制到 tina d1 open\\lichee\\linux 5.4\\drivers\\net\\wireless\\rtl8723ds 里，没有rtl8723ds文件夹记得新建一个。 修改tina d1 open\\lichee\\linux 5.4\\drivers\\net\\wireless\\Makefile，加一行 obj $(CONFIG_RTL8723DS) + rtl8723ds/ ![](./assets/rtl8723ds.png) 修改tina d1 open\\lichee\\linux 5.4\\drivers\\net\\wireless\\Kconfig，加一行 source \"drivers/net/wireless/rtl8723ds/Kconfig\" ![](./assets/Kconfig.png) 修改tina d1 open\\lichee\\linux 5.4\\drivers\\net\\wireless\\rtl8723ds\\os_dep\\linux\\os_intfs.c； 加一行 MODULE_IMPORT_NS(VFS_internal_I_am_really_a_filesystem_and_am_NOT_a_driver); ![](./assets/os_intfs.png) 修改tina d1 open\\lichee\\linux 5.4\\drivers\\net\\wireless\\rtl8723ds\\os_dep\\linux\\rtw_cfgvendor.c 在每一行.policy VENDOR_CMD_RAW_DATA, 下面加上 .maxattr 1, ![](./assets/rtw_cfgvendor.png) 修改tina d1 open\\target\\allwinner\\d1 lichee_rv_dock\\modules.mk，增加以下内容： ![](./assets/modules.png) （其中的d1 lichee_rv_dock 是我的板级配置，请选择自己的板级配置比如d1 nezha，如下图） ![](./assets/borad_config.png) 进入内核配置，勾选Realtek 8723D SDIO or SPI WiFi为Module（ < M > 不是 < * > ） ```menuconfig make kernel_menuconfig Device Drivers > Network device support > Wireless LAN > <M> Realtek 8723D SDIO or SPI WiFi ``` 进入Tina配置，勾选相关驱动 ```bash make menuconfig Firmware > <*> r8723ds firmware.............................. RealTek RTL8723DS firmware Kernel modules > Wireless Drivers > <*> kmod net rtl8723ds........................... RTL8723DS support (staging) ``` 保存，编译，打包 ```bash make j8 pack ``` 烧录后就能看到 ![](./assets/apperance.jpg)"},"/news/Lichee/RV/D1-ncnn/D1_ncnn_new.html":{"title":"又在全志d1开发板上玩ncnn","content":" title: 又在全志d1开发板上玩ncnn keywords: D1, RV, Lichee, ncnn, desc: 又在全志d1开发板上玩ncnn date: 2022 03 28 tags: RV, ncnn <! more > 转载自知乎用户 [nihui](https://www.zhihu.com/people/nihui 2) [原文链接](https://zhuanlan.zhihu.com/p/441176926)，原文写于 2021 07 03 又在全志d1开发板上玩ncnn **可在不修改本文章内容和banner图前提下，转载本文** ## 0x0 工具链变得更好了 距上次[在全志d1开发板上玩ncnn](./D1_ncnn.html)，已经过去了5个月 在此期间，ncnn收到perfxlab和腾讯犀牛鸟开源人才的学生有关riscv vector的优化 但更重要的是，平头哥收到了社区的反馈，提供了新版工具链 支持了 risc v vector intrinsic v1.0 修复了 release 模式编译 ncnn 时的非法指令问题 https://occ.t head.cn/community/download?id 3987221940543754240 旧版本工具链的 gcc 比较笨，经常做些负优化，于是试试全新的工具链 ## 0x1 配置新的 cmake toolchain ```bash 旧 march rv64gcvxtheadc mabi lp64d mtune c906 DRVV_SPEC_0_7 D__riscv_zfh 1 static 新 march rv64gcv0p7_zfh_xtheadc mabi lp64d mtune c906 static ``` arch 参数要用 v0p7，不能用默认的 v，否则会生成非法指令 删除 DRVV_SPEC_0_7，开启 ncnn 的 rvv 1.0 intrinsic 代码 删除 D__riscv_zfh 1，arch 参数的 zfh 中已经指代 放在 ncnn/toolchains/c906 v222.toolchain.cmake ## 0x2 工具链修复 因为 rvv 0.7 缺少某些指令支持，遇到一些 rvv 1.0 的代码会生成 unknown op ```bash fneg frec7 frsqrt7 ``` 因此要修改下工具链头文件 打开 Xuantie 900 gcc linux 5.10.4 glibc x86_64 V2.2.2/lib/gcc/riscv64 unknown linux gnu/10.2.0/include/riscv_vector.h 找到以下三行 ```h _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rec7) _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rsqrt7) _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, neg) ``` 注释掉 ```h // _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rec7) // _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, rsqrt7) // _RVV_FLOAT_ITERATOR_ARG (_RVV_FLOAT_UNARY_OP, neg) ``` 找到文件末尾的三个 #endif，添加以下兼容代码，保存 ```h #endif #define vfneg_v_f32m1(x, vl) vfsgnjn_vv_f32m1(x, x, vl) #define vfneg_v_f32m2(x, vl) vfsgnjn_vv_f32m2(x, x, vl) #define vfneg_v_f32m4(x, vl) vfsgnjn_vv_f32m4(x, x, vl) #define vfneg_v_f32m8(x, vl) vfsgnjn_vv_f32m8(x, x, vl) #define vfneg_v_f16m1(x, vl) vfsgnjn_vv_f16m1(x, x, vl) #define vfneg_v_f16m2(x, vl) vfsgnjn_vv_f16m2(x, x, vl) #define vfneg_v_f16m4(x, vl) vfsgnjn_vv_f16m4(x, x, vl) #define vfneg_v_f16m8(x, vl) vfsgnjn_vv_f16m8(x, x, vl) #define vfrec7_v_f32m1(x, vl) vfrdiv_vf_f32m1(x, 1.f, vl) #define vfrec7_v_f32m2(x, vl) vfrdiv_vf_f32m2(x, 1.f, vl) #define vfrec7_v_f32m4(x, vl) vfrdiv_vf_f32m4(x, 1.f, vl) #define vfrec7_v_f32m8(x, vl) vfrdiv_vf_f32m8(x, 1.f, vl) #define vfrec7_v_f16m1(x, vl) vfrdiv_vf_f16m1(x, 1.f, vl) #define vfrec7_v_f16m2(x, vl) vfrdiv_vf_f16m2(x, 1.f, vl) #define vfrec7_v_f16m4(x, vl) vfrdiv_vf_f16m4(x, 1.f, vl) #define vfrec7_v_f16m8(x, vl) vfrdiv_vf_f16m8(x, 1.f, vl) #define vfrsqrt7_v_f32m1(x, vl) vfrdiv_vf_f32m1(vfsqrt_v_f32m1(x, vl), 1.f, vl) #define vfrsqrt7_v_f32m2(x, vl) vfrdiv_vf_f32m2(vfsqrt_v_f32m2(x, vl), 1.f, vl) #define vfrsqrt7_v_f32m4(x, vl) vfrdiv_vf_f32m4(vfsqrt_v_f32m4(x, vl), 1.f, vl) #define vfrsqrt7_v_f32m8(x, vl) vfrdiv_vf_f32m8(vfsqrt_v_f32m8(x, vl), 1.f, vl) #define vfrsqrt7_v_f16m1(x, vl) vfrdiv_vf_f16m1(vfsqrt_v_f16m1(x, vl), 1.f, vl) #define vfrsqrt7_v_f16m2(x, vl) vfrdiv_vf_f16m2(vfsqrt_v_f16m2(x, vl), 1.f, vl) #define vfrsqrt7_v_f16m4(x, vl) vfrdiv_vf_f16m4(vfsqrt_v_f16m4(x, vl), 1.f, vl) #define vfrsqrt7_v_f16m8(x, vl) vfrdiv_vf_f16m8(vfsqrt_v_f16m8(x, vl), 1.f, vl) #endif #endif ``` ## 下载和编译ncnn 这次可以用 release 编译啦！ ```bash git clone https://github.com/Tencent/ncnn.git cd ncnn mkdir build c906 cd build c906 cmake DCMAKE_TOOLCHAIN_FILE ../toolchains/c906 v222.toolchain.cmake DCMAKE_BUILD_TYPE release DNCNN_OPENMP OFF DNCNN_THREADS OFF DNCNN_RUNTIME_CPU OFF DNCNN_RVV ON DNCNN_SIMPLEOCV ON DNCNN_BUILD_EXAMPLES ON .. make j32 ``` ## 新旧工具链的性能测试对比 ![](./assets/ncnn_new/ncnn_new_001.jpg) ![](./assets/ncnn_new/ncnn_new_002.jpg) ## 0x5 欢迎关注 ncnn github，加qq群交流！ https://github.com/Tencent/ncnn qq群在 ncnn github 首页 readme 中～"},"/news/Lichee/RV/D1-ncnn/D1_ncnn.html":{"title":"在全志d1开发板上玩ncnn","content":" title: 在全志d1开发板上玩ncnn keywords: D1, RV, Lichee, ncnn, desc: 在全志d1开发板上玩ncnn date: 2022 03 28 tags: RV, ncnn <! more > 转载自知乎用户 [nihui](https://www.zhihu.com/people/nihui 2) [原文链接](https://zhuanlan.zhihu.com/p/386312071)，原文写于 2021 07 03 在全志d1开发板上玩ncnn **可在不修改本文章内容和banner图前提下，转载本文** ``` 这是我最后一次优化 risc v 这 1.4w 行代码是我最后的倔强 你们不可能再看见我为这个 d1 写一行代码，不可能 这 96 个 cpp 文件，我要用到 2030 年 ``` **首先感谢全志科技公司送了我d1开发板，以及sipeed、rvboards在系统底层技术工作和支持，才有了ncnn AI推理库在risc v架构上更好的优化 qwqwqwq** ## 0x0 ncnn risc v 优化情况 [ncnn](https://github.com/Tencent/ncnn) 是腾讯开源的神经网络推理框架 支持深度学习模型 caffe/mxnet/keras/pytorch(onnx)/darknet/tensorflow(mlir) 跨平台：Windows/Linux/MacOS/Android/iOS/WebAssembly/... 兼容多种 CPU 架构：x86/arm/mips/risc v/... 支持 GPU 加速：NVIDIA/AMD/Intel/Apple/ARM Mali/Adreno/... 支持各种常见的模型结构，比如 mobilenet/shufflenet/resnet/LSTM/SSD/yolo... 很强，qq群请移驾 ncnn github 首页README _因为据全（某）志（人）说，全志的用户基础都挺一般，可能不知道 ncnn 是什么东西，所以便罗嗦一番..._ 从上次发了开箱自拍jpg，到现在一个月了，ncnn risc v vector 优化情况还算不错，大部分重要的优化都做了，剩下一些会留给社区学生pr，和慢慢变聪明的编译器 ncnn risc v 目前使用 rvv 1.0 intrinisc 编写优化代码，并支持任意 vlen 的配置，面向未来顺便兼容了 d1开发板 rvv 0.7.1 某些 intrinisc 转换可能有效率问题 有遇到过 0.7.1 intrinisc 行为怪异只能写 C 代码绕过 gcc 还比较笨，每行 intrinisc 都会加一条无用的 setvli 指令 因为没法同时兼容 rvv 1.0 和 rvv 0.7.1，便没有写汇编 一些算子，如 hardswish/hardsigmoid/binaryop/eltwise/slice/... 待优化（欢迎pr！！！qaq） 下面这张表只是最近一周多的情况。如果跟最开始比，柱状图就太高了... ![](./assets/ncnn/001.jpg) ![](./assets/ncnn/002.jpg) ## 0x1 准备交叉编译工具链 去平头哥芯片开放社区下载 工具链 900 系列 https://occ.t head.cn/community/download?id 3913221581316624384 比如 riscv64 linux x86_64 20210512.tar.gz，下载后解压缩，设置环境变量 ```bash tar xf riscv64 linux x86_64 20210512.tar.gz export RISCV_ROOT_PATH /home/nihui/osd/riscv64 linux x86_64 20210512 ``` ## 0x2 下载和编译ncnn 为 d1 架构交叉编译 ncnn **因为编译器 bug，release 编译会导致运行时非法指令错误，必须使用 relwithdebinfo 编译哦** ncnn 已支持直接用 simpleocv 替代 opencv 编译出 examples **不需要配opencv啦！** **不需要配opencv啦！** **不需要配opencv啦！（重要，说了三遍）** ```bash git clone https://github.com/Tencent/ncnn.git cd ncnn mkdir build c906 cd build c906 cmake DCMAKE_TOOLCHAIN_FILE ../toolchains/c906.toolchain.cmake DCMAKE_BUILD_TYPE relwithdebinfo DNCNN_OPENMP OFF DNCNN_THREADS OFF DNCNN_RUNTIME_CPU OFF DNCNN_RVV ON DNCNN_SIMPLEOCV ON DNCNN_BUILD_EXAMPLES ON .. make j32 ``` ## 0x3 测试benchncnn **d1 默认的 TinaLinux 执行 ncnn 程序时会发生非法指令错误，必须使用 Debian 系统哦** vgg16 这类大型模型在内存不足时会发生 segmentation fault，是 d1开发板硬件条件不够，不管即可 将 `ncnn/build c906/benchmark/benchncnn` 和 `ncnn/benchmark/*.param` 拷贝到 d1开发板上 ```bash ./benchncnn 4 1 0 1 0 ``` ## 0x4 测试example 将 `ncnn/build c906/examples/nanodet` 和测试图片拷贝到 d1开发板上 从这里下载 nanodet 模型文件并拷贝到 d1开发板上 https://github.com/nihui/ncnn assets/tree/master/models ```bash ./nanodet test.jpg ``` 输出检测结果信息，并保存在 image.png ``` 0 0.82324 at 200.04 44.89 198.96 x 253.33 0 0.78271 at 32.98 63.45 178.15 x 232.92 56 0.45923 at 1.46 71.92 90.14 x 117.85 imshow save image to image.png waitKey stub ``` 把image.png下载到本地查看，结果已经画在图片上了！d1开发板AI目标检测成功 w ![](./assets/ncnn/003.jpg) ## 0x5 mips大概也会安排啦，欢迎关注 ncnn github，加qq群交流！ https://github.com/Tencent/ncnn qq群在 ncnn github 首页 readme 中～"},"/news/Lichee/RV/run_nonos_program/nonos_run.html":{"title":"在D1上使用裸机程序","content":" title: 在D1上使用裸机程序 keywords: RV, D1, 裸机 date: 2022 04 29 tags: MaixPy,MaixPy3 近日一国内小哥实现了一种在D1上运行裸机程序的方法。让我们一起来看一下吧 <! more > Github仓库地址在这里：https://github.com/Ouyancheng/FlatHeadBro 相关使用方法在仓库的 readme 写的很详细了。 大概就是用先编译出一个 启动固件，烧录到SD卡启动板子后可以看到串口有相关的信息打印出来。 接着只需要使用 python 将想要运行的程序通过串口传送到开发板上面即可。"},"/news/maixhub/new_maixhub.html":{"title":"新版 MaixHub 正式上线啦！","content":" title: 新版 MaixHub 正式上线啦！ keywords: 在线训练, 模型平台, 单片机运行模型, 云端训练, 模型库, model zoo date: 2022 09 04 tags: MaixHub, 模型训练 cover: ./images/deploy.gif 先看看效果， 一个检测小鸭子（可同时检测多个相同或者不同目标），另外一个是表情分类模型： ![deploy](./images/deploy.gif) ![face_emotion](./images/face_emotion.gif) <! more > > 原文： https://neucrack.com/p/444 , 持续更新 > 视频： [基于K210的情绪识别与可视化](https://www.bilibili.com/video/BV1Xe4y1D7ne?spm_id_from 333.337.search card.all.click&vd_source 6c974e13f53439d17d6a092a499df304) ## 新版 [MaixHub](https://maixhub.com) 简介 [MaixHub](https://maixhub.com) 推出了新版！支持了更多设备，包括 K210, V831, NCNN, TFjs, TinyMaix(所有单片机上运行)！更新了一大堆功能： * 多种上传数据集方式： ![上传数据集](./images/1.jpg) * 本地文件上传 * 设备直接拍照后一键上传 ![采集](./images/采集.jpg) * 导入本地标注 * 支持在线标注，简单快速好用，以及支持视频自动标注哦 ![在线标注](./images/在线标注.jpg) * 多种训练参数自定义支持 ![参数](./images/参数.jpg) * 多种平台（硬件平台） * 手机、电脑 ![浏览器](./images/浏览器.jpg) * 带硬件NPU加速的高性价比板子，比如[Maix II Dock](https://wiki.sipeed.com/hardware/zh/maixII/M2/resources.html) ![m1m2](./images/m1m2.jpg) * 通用单片机，更是推出了超轻量的单片上运行的模型推理库[TinyMaix](https://github.com/sipeed/TinyMaix)，可以移植到任意单片机，甚至能在 2KiB RAM的arduino上跑 ![mcu](./images/mcu.jpg) * 训练过程、日志、图标展示，以及验证结果展示，方便分析和优化模型 ![MaixHub](./images/maixhub.jpg) * 一键部署到设备 ![部署](./images/部署.jpg) * 一键分享到模型库（模型平台/model zoo），同时模型库也支持手动上传分享更厉害好玩的模型哦 ![模型库](./images/模型库.jpg) ## 训练一个模型试试 注意 MaixHub 在不停更新，可能有些地方在未来会有些许变化，原理变化不大，举一反三即可 * 创建训练项目，选择检测任务，检测任务能框出物体的位置，后面需要我们标注数据，分类任务则不需要标注框，用来区分多种物体 ![创建训练项目](./images/创建训练项目.jpg) ![创建项目](./images/创建项目.jpg) * 创建数据集 ![数据集](./images/数据集.jpg) * 采集数据，可以从本地上传，也可以用手机在线拍照采集，也可以用设备拍照采集（比如 Maix II DocK） ![采集数据](./images/采集数据.jpg) ![采集](./images/采集.jpg) * 标注数据，就是将要检测的物体框起来，并且给一个标签，比如这里只有一个duck；一张图里面可以有多个框，也可以只有一个框，最后训练出来的模型都能识别同一个画面的多个物体，数据量尽量多一点，覆盖的场景全面一点，这样实际到板子上跑起来准确率更高，最好使用什么板子跑就用什么板子采集数据，准确率会高些 ![collect](./images/collect.gif) 这里有训练集，验证集，测试集的概念，训练集就是拿来参与训练的数据，验证集不参与训练，但是每隔一段训练时间后会将模型在验证集上面跑一次，得到 `val_acc`也就是验证集精确度，即这个模型在这个从来没参与过训练的数据上正确率如何，一般用这个指标来评判模型的好坏；测试集则是完全没在训练过程中参与的数据，比如部署到板子上后实际识别的物体就算是测试集。所以为了让实际在板子上跑的时候准确度高，尽量将验证集的数据和实际应用的场景（测试集）相近，这样训练时在验证集上的准确率（val_acc）才能更精确地反应在测试集上的效果。 > 比如你实际识别的是哈士奇狗狗，训练集中放了各种狗狗图，验证集却放了中华田园犬，就算 val_acc 为 1，即全部识别正确，实际拿去识别哈士奇狗狗的时候可能完全无法识别 * 创建训练任务，一个项目里面可以多次创建任务，调整不同的参数。 注意要根据自己的设备选择对应的平台，比如 K210 选择 nncase， 普通没有 NPU 加速的单片机选择 TinyMaix，手机或者浏览器跑则选择 tfjs。分辨率使用默认的 224x224 效果最好，因为迁移训练就是基于一个已经训练过的模型微调训练模型，这个模型默认都是 224x224 下训练的，所以理论上效果最好。 ![参数](./images/参数.jpg) 另外，选择模型主干网络，网络越大效果越好（精确度越高），但是占用的内存就越大，以及运行消耗的时间就越久，也就是对算力的要求越大，根据你的数据集复杂度以及设备性能选择合适的主干网络（backbone）。 还有更多参数，可以看页面对应的文档说明即可，也可以到首页的交流群交流。 * 启动训练，训练任务多的时候可能需要排队，耐心等待就好了，如果加急可以联系官方或者管理员钞能力解决哈哈哈。 训练过程可以看到 `val_acc`， 即损失和精确度曲线，会慢慢上升，代表在验证集训练完成后可以看到 ![训练结果](./images/训练结果.jpg) 如前面所说，这里最重要的是 `val_acc`，即在验证集上的准确度，越接近 `1`越好（实际上这里 val_acc 是 MAP，MAP相关含义可自行搜索）。以及展示了部分识别正确的和识别错误（或者未识别到）的样例。 * 一键部署 根据不同设备支持的方式可能不同，可能是直接下载文件（具体使用方法看对应说明），也有（比如 Maix II Dock）支持一键部署，在设备上选择模型部署，扫描部署页面的二维码即可自动部署，然后就可以进行识别了。 需要注意的是一键部署需要设备已经联接互联网，设备选择联网功能，到 [maixhub.com/wifi](https://maixhub.com/wifi) 生成填写 WiFi 信息然后设备扫码连接 WiFi， 注意不是局域网，需要能访问互联网。 ![deploy](./images/deploy.gif) * 分享模型到模型库 训练的模型可以一键分享到模型库，如果你训练的模型实际在板子上运行的识别效果不错，欢迎点击左边导航栏分享模型分享到模型库，可以多写点图文介绍，推荐在 B 站上传一个视频后嵌入到模型描述里面~ 更多功能持续在更新~ 持续关注哦~ 也欢迎来上传分享你自己的模型！ ## 训练优化建议 * 尽量多采集实际使用场景的图片，覆盖更多使用场景有利于提高最终识别率。 * 图片数量尽量不要太小，虽然平台限制最小数量为 20 张图才可以训练， 但要打到比较好的效果，显然一个分类 200 张都不算多，不要一直在 30 张训练图片上纠结为什么训练效果不好。。。 * 默认分辨率但是 224x224， 是因为预训练模型是在 224x224 下训练的，当然也有其它分辨率的，比如 128x128，具体发现不支持的分辨率预训练模型，在训练日志中会打印警告信息。 * 为了让验证集的精确度的可信度更高（也就是在实际开发板上跑的精确度更接近训练时在验证集上的精确度），验证集的数据和实际应用的场景数据一致。比如训练集是在网上找了很多图片，那这些图片可能和实际开发板的摄像头拍出来的图有差距，可以往验证集上传一些实际设备拍的图来验证训练的模型效果。 这样我们就能在训练的时候根据验证集精确度（val_acc）来判断模型训练效果如何了，如果发现验证集精确度很低，那么就可以考虑增加训练集复杂度和数量，或者训练集用设备拍摄来训练。 * 对于检测训练项目，如果检测训练的物体很准，但是容易误识别到其它物体，可以在数据里面拍点其它的物体当背景；或者拍摄一些没有目标的图片，不添加任何标注也可以，然后在训练的时候勾选“允许负样本”来使能没有标注的图片。 * 检测任务可以同时检测到多个目标，如果你觉得识别类别不准，也有另外一种方式，先只检测模型检测到物体（一个类别），然后裁切出图片中的目标物体上传到分类任务，用分类任务来分辨类别。不过这样就要跑两个模型，需要写代码裁切图片（在板子跑就好了），以及需要考虑内存是否足够"},"/news/others/Python_call_so.html":{"title":"Python3调用c/cpp的方法","content":" title: Python3调用c/cpp的方法 keywords: python, c, cpp, desc: python调用so date: 2022 03 31 tags: python, c, cpp <! more > 原文链接：https://blog.csdn.net/springlustre/article/details/101177282 作者：[springlustre](https://blog.csdn.net/springlustre?type blog) 有改动，仅供参考 python中使用 ctypes 模块可以在python中直接调用C/C++。 首先要将C/C++编译成动态库（.so)，然后python中调用即可。 特别注意在调用C++函数需要在函数声明时，加入前缀 extern \"C\" ，这是因为C++支持函数重载功能，在编译时会改变函数名。在函数声明时，前缀extern \"C\"可以确保按C的方式进行编译。 值得注意的是，一定要有函数输入输出类型的声明，int型不用转换，float和double类型需要进行转换； ctypes中的变量类型与C中对应如下： ctypes数据类型 C数据类型 c_char char c_short short c_int int c_long long c_float float c_double double c_void_p void c_uint8 unsigned char 使用方法： 编写c++代码 ```cpp #include <iostream> #include <string> #include <cstdlib> #include <vector> #include <stdio.h> class Test{ private: double _calculate(int a, double b); public: double calculate(int a, double b, char c[], int * d, double * e, char ** f); }; double Test::_calculate(int a, double b){ double res a+b; std::cout<<\"res: \"<<res<<std::endl; return res; } double Test::calculate(int a, double b, char c[], int * d, double * e, char ** f){ std::cout<<\"a: \"<<a<<std::endl; std::cout<<\"b: \"<<b<<std::endl; std::cout<<\"c: \"<<c<<std::endl; std::cout<<\"d: \"<<d[0]<<d[1]<<std::endl; std::cout<<\"e: \"<<e[0]<<e[1]<<std::endl; std::cout<<\"f: \"<<f[0]<<f[1]<<std::endl; return this >_calculate(a, b); } // 封装C接口 extern \"C\"{ // 创建对象 Test* test_new(){ return new Test; } double my_calculate(Test* t, int a, double b, char c[], int * d, double * e, char ** f){ return t >calculate(a, b,c,d,e,f); } } ``` 将上面的代码编译成so文件 > g++ shared Wl, soname,test o test.so fPIC test.cpp 使用python调用so文件 ```python # * coding: utf 8 * import ctypes # 指定动态链接库 lib ctypes.cdll.LoadLibrary('./test.so') #需要指定返回值的类型，默认是int lib.my_calculate.restype ctypes.c_double class Test(object): def __init__(self): # 动态链接对象 self.obj lib.test_new() def calculate(self, a, b,c,d,e,f): res lib.my_calculate(self.obj, a, b,c,d,e,f) return res #将python类型转换成c类型，支持int, float,string的变量和数组的转换 def convert_type(input): ctypes_map {int:ctypes.c_int, float:ctypes.c_double, str:ctypes.c_char_p } input_type type(input) if input_type is list: length len(input) if length 0: print(\"convert type failed...input is \"+input) return null else: arr (ctypes_map[type(input[0])] * length)() for i in range(length): arr[i] bytes(input[i],encoding \"utf 8\") if (type(input[0]) is str) else input[i] return arr else: if input_type in ctypes_map: return ctypes_map[input_type](bytes(input,encoding \"utf 8\") if type(input) is str else input) else: print(\"convert type failed...input is \"+input) return null if __name__ '__main__': t Test() A1\t 123; A2\t 0.789; A3\t \"C789\"; A4\t [456,789]; A5\t [0.123,0.456]; A6\t [\"A123\", \"B456\"]; print(t.calculate(convert_type(A1), convert_type(A2), convert_type(A3),convert_type(A4),convert_type(A5),convert_type(A6))) ```"},"/news/others/20k_lite_start/20k_lite_start.html":{"title":"Primer 20K Lite 初见","content":" title: Primer 20K Lite 初见 keywords: Primer 20K, Lite, FPGA desc: Primer 20K 上手 tags: FPGA, Primer 20K cover: ./assets/cover.png update: date: 2022 08 22 version: v0.1 author: wonder content: 初稿 date: 2022 09 23 version: v0.2 author: wonder content: 更新常见问题 date: 2022 10 18 version: v0.3 author: wonder content: 修改部分表达语句 拿到 Primer 20K Lite 后上手点个灯 <! more > ## 前言 本篇文档引导新用户熟悉 IDE 流程并且完成点灯操作。 默认固件工程可以在 [github](https://github.com/sipeed/TangPrimer 20K example/tree/main/Lite bottom%20test%20project/test_board) 找到 默认固件功能如下： 所有引出到排针的 IO 电平逻辑定期翻转，spi lcd 连接器与 sd 卡槽连接器的可编程引脚也定期翻转 DDR 测试；可以通过核心板上下载接口里面的串口引脚在电脑上位机上看到 DDR 测试结果 因为固件里面有 DDR 测试，所以核心板上电后会发烫；介意这个发热的话可以把默认的固件给擦除了。 ## 安装 IDE 参考 [安装IDE](https://wiki.sipeed.com/hardware/zh/tang/common doc/get_started/install the ide.html) 来完成我们需要准备的软件环境。 对于 Linux 用户，如果打开 Programmer 烧录软件困难的话，可以使用 [openfpgaLoader](https://wiki.sipeed.com/hardware/zh/tang/common doc/get_started/flash_in_linux.html) 这软件来烧录 GW2A 18，相关用法在 [OpenFpgaloader](https://wiki.sipeed.com/hardware/zh/tang/common doc/get_started/flash_in_linux.html) 一文中有说明。 ## 新建工程 文件 > 新建 > FPGA Design > Project <div> <img src \"./assets/new_project.png\" width 58% alt \"new_project\"> <img src \"./assets/fpga_project.png\" width 35% alt \"fpga_project\"> </div> 设置工程名称，要求只用英文和下划线命名，存放路径中不要有中文字符或者空格等。 ![project_path](./assets/project_path.png) 然后在下面的芯片型号中选择 GW2A LV18PG256C8/I7，使用上面的筛选能够更快地选择到正确的型号。注意 Device 那一栏为 GW2A 18C ![device_choose](./assets/device_choose.png) 然后点击确定后就可以进行最终项目预览了。确认无误后就完成工程创建了。 ## 编写代码 ### 新建文件 高云半导体 IDE 提供了三种新建文件的方法。在此我们直接使用快捷键 `Ctrl + N` 来新建文件，其他两种不在此讲述。 在弹出的窗口中选择 `Verilog File`，会 VHDL 的也可以选择下面的 `VHDL File`，这篇文章只用 Verilog 来做点灯示例。 <img src \"./assets/new_verilog_file.png\" width 50% alt \"new_verilog_file\"> 点击 OK 之后会提示让我们输入文件名称，此处以 `led` 为文件名做示范。 <img src \"./assets/file_name.png\" width 75% alt \"file_name\"> 到这里我们就完成文件的创建了，可以直接编写代码了。 ![created_file](./assets/created_file.png) ### Verilog 简单说明 Verilog 是一种硬件描述语言，用来对数字电路进行抽象化描述。 Verilog 的基本设计单元是“模块”(module)。 一个模块是由两部分组成的：一部分描述接口，另一部分描述内部逻辑功能，即定义输入是如何影响输出的。 一个模块长成这样： ```v module module_name #(parameter) (port) ; function endmodule ``` 模块整体结构由 module 和 endmodule 组成，module 后面跟着的是模块的名称(module_name)，可传递变量参数(parameter)，端口及其方向的申明(port)，紧接着就是内部逻辑功能描述(function) ,最后用 endmodule 来表示这一个模块，描述完毕。 内部逻辑功能通常由 assign 和 always 块完成；其中 assign 语句描述逻辑功能，always 块常用于描述时序功能。 ### 代码思路 写代码前我们需要先想清楚代码目的：每隔 0.5S 灯闪一次。 对此所画的需求框图如下： ![block_method](./assets/block_method.png) 然后对于 0.5S 我们需要一个计数器来计时，LED 灯闪就是 IO 翻转 ![count_block](./assets/time_count.png) 把上面的思维框图具体到实际使用的话，就变成下面的样式了: ![clock_time_count](./assets/clock_time_count.png) 其中 Clock 为时钟源，用来给计时器提供准确的时间。 ### 代码描述 根据上文 Verilog 简单说明和所描述的框图，可以知道所要编写 Verilog 模块有 Clock 和 IO电平 两个端口； ```v module led( input Clock, output IO_voltage ); endmodule ``` 对于内部的计时模块，Primer 20K 核心板上的晶振为 27MHZ，因此我们每秒钟会有 27000000 个时钟上升沿，想要 0.5S 计数的话那么只需要计数 13500000 次上升沿就好。计数是从 0 开始的，数 13500000 的话就是从 0 数到 13499999。计数完后我们设置一个标志位，来通知 LED 的 IO 翻转一下电平。整体计数代码如下： ```v //parameter Clock_frequency 27_000_000; // 时钟频率为27Mhz parameter count_value 13_499_999; // 计时 0.5S 所需要的计数次数 reg [23:0] count_value_reg ; // 计数器 reg count_value_flag; // IO 电平翻转标志 always @(posedge Clock) begin if ( count_value_reg < count_value ) begin //没有计数到 0.5S count_value_reg < count_value_reg + 1'b1; // 继续计数 count_value_flag < 1'b0 ; // 不产生翻转标志 end else begin //计数到 0.5S 了 count_value_reg < 23'b0; // 清零计数器，为重新计数最准备 count_value_flag < 1'b1 ; // 产生翻转标志 end end ``` 对于 LED IO 电平翻转代码如下： ```v reg IO_voltage_reg 1'b0; // 声明 IO 电平状态用于达到计时时间后的翻转，并赋予一个低电平初始态 always @(posedge Clock) begin if ( count_value_flag ) // 电平翻转标志有效 IO_voltage_reg < ~IO_voltage_reg; // IO 电平翻转 else // 电平翻转标志无效 IO_voltage_reg < IO_voltage_reg; // IO 电平不变 end ``` 将上面的代码整合后就变成了下面的内容: ```v module led( input Clock, output IO_voltage ); /**********计时部分**********/ //parameter Clock_frequency 27_000_000; // 时钟频率为27Mhz parameter count_value 13_499_999; // 计时 0.5S 所需要的计数次数 reg [23:0] count_value_reg ; // 计数器 reg count_value_flag; // IO 电平翻转标志 always @(posedge Clock) begin if ( count_value_reg < count_value ) begin //没有计数到 0.5S count_value_reg < count_value_reg + 1'b1; // 继续计数 count_value_flag < 1'b0 ; // 不产生翻转标志 end else begin //计数到 0.5S 了 count_value_reg < 23'b0; // 清零计数器，为重新计数最准备 count_value_flag < 1'b1 ; // 产生翻转标志 end end /**********电平翻转部分**********/ reg IO_voltage_reg 1'b0; // 声明 IO 电平状态用于达到计时时间后的翻转，并赋予一个低电平初始态 always @(posedge Clock) begin if ( count_value_flag ) // 电平翻转标志有效 IO_voltage_reg < ~IO_voltage_reg; // IO 电平翻转 else // 电平翻转标志无效 IO_voltage_reg < IO_voltage_reg; // IO 电平不变 end /**********补充一行代码**********/ assign IO_voltage IO_voltage_reg; endmodule ``` 上面代码最后面补充了一行代码，是因为 IO_voltage 声明在了 port 位置，默认为 wire 型，想要将它与 reg 变量 IO_voltage_reg 连接起来，需要用到 assign 语句。 ## 综合，约束，布局布线 ### 综合 代码保存后，可以双击 IDE 内部的 Process > Synthesize 来进行代码综合，将 verilog 代码内容转换为综合网表。 ![synthesize](./assets/synthesize.png) 关于网表有兴趣的可以自己去查阅相关资料，此处不再额外说明。 ### 约束 综合完之后我们需要进行管脚约束，才能将所编写的模块端口与 FPGA 引脚相对应，并且实现模块的功能。 点击上图 Synthesize 上面的 FloorPlanner 来进行管脚约束。 ![floorplanner](./assets/floorplanner.png) 由于是首次创建，所以会弹出下面的对话框，点击 OK 后就弹出了图形化约束交互界面。 ![create_constrain_file](./assets/create_constrain_file.png) ![floorplanner_intreface](./assets/floorplanner_interface.png) 关于约束的方法可以查看 [SUG935 1.3_Gowin设计物理约束用户指南.pdf](http://cdn.gowinsemi.com.cn/SUG935 1.3_Gowin%E8%AE%BE%E8%AE%A1%E7%89%A9%E7%90%86%E7%BA%A6%E6%9D%9F%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97.pdf) 此处因个人喜所以仅使用下图中 IO Constranins 方法来约束引脚： ![floor_planner_ioconstrain](./assets/floor_planner_ioconstrain.png) 根据[核心板原理图](https://dl.sipeed.com/shareURL/TANG/Primer_20K/02_Schematic)，我们可以知道晶振所输入的引脚为 H11。 <img src \"./assets/crystal_port.png\" alt \"crystal_port\" width 45%> 然后结合底板上的 IO 丝印，决定用底板上的 L14 引脚进行点灯。 ![l14_port](./assets/l14_port.png) 因此对于在 FloorPlanner 交互窗口下面的 IO Constranins 中将 PORT（端口）与 Location（引脚） 分别填入下面的值： ![io_constrain_value](./assets/io_constrain_value.png) 输入完毕后快捷键 Ctrl + S 来保存一下引脚约束，然后接可以关闭 FloorPlanner 的交互图形界面了。 接着发现在工程项目里面多出来刚刚创建的 cst 文件了，里面的内容也比较好理解。 ![cst_content](./assets/cst_content.png) ### 布局布线 完成约束后就要开始运行布局布线了，目的是为了把综合所生成的网表与我们自己定义的约束来通过 IDE 算出最优解然后将资源合理地分配在 FPGA 芯片上。 双击下图红框处的 Place&Route 就开始运行了。 ![place_route](./assets/place_route.png)。 紧接着没有报错，全部通过。就可以开始进行烧录了。 ## 烧录固件 建议使用高云教育版的 Programmer 软件，可以在高云官网下载到 [点我跳转](http://www.gowinsemi.com.cn/faq.aspx) ，下载下图所示的 Programmer 软件即可。 ![educational_edition_programmer](./assets/educational_edition_programmer.png) <! 如果使用的是 bl702 下载器，那么要求使用 [此处](https://dl.sipeed.com/shareURL/TANG/programmer) 链接内的 Programmer 软件来进行烧录，来避免 Programmer 软件识别不到芯片等一系列问题。 下载后解压替换掉 Gowin 对应安装目录的 Programmer 文件夹即可。 > <! 不会替换的话可以在下载解压后的 Programmer 程序中手动添加需要下载的 .fs 文件来进行烧录。 > ### 接线说明 由于需要将核心板与下载器进行连线，这里说明一下所连接的对应端口。 核心板的引脚可以在核心板背面看到。 <table> <tr> <td>核心板</td> <td>5V0</td> <td>TMS</td> <td>TDO</td> <td>TCK</td> <td>TDI</td> <td>RX</td> <td>TX</td> <td>GND</td> </tr> <tr> <td>调试器</td> <td>5V0</td> <td>TMS</td> <td>TDO</td> <td>TCK</td> <td>TDI</td> <td>TX</td> <td>RX</td> <td>GND</td> </tr> </table> ![cable_connect](./assets/cable_connect.png) ### 扫描设备 双击下图中的下载程序(Program Device) 来运行 Programmer 软件 ![open_programmer](./assets/open_programmer.png) <! 正确运行我们所提供下载的 Programmer 软件的话软件上面所显示的软件名称为 `Programmer 2` ，点击下图红框处来扫描设备，且在设备选择中选择 GW2A 18C 。 > 然后在打开的页面中点击一下 scan_device 来扫描到我们的设备。 ![scan_device](./assets/scan_device.png) 点击 OK 后就可以进行烧录操作了。 烧录相关的文档可以参考 [SUG502 1.3_Gowin_Programmer用户指南.pdf](http://cdn.gowinsemi.com.cn/SUG502 1.3_Gowin_Programmer%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97.pdf) ### 下载到 SRAM 一般来说这个模式是以用来快速验证所生成的固件是否满足自己目的的。 因为其烧录快的特性所以使用的较多，然是当然断电会丢失数据，所以如果想上电运行程序的话是不能选这个的。 点击 Operation 下面的功能框来打开设备设置界面，接着在 Operation 框中选择 SRAM Program 选项来设置为下载到 SRAM ，最后点击下面的那三个点点框来选择我们所生成的 .fs 下载固件。通常来说下载固件生成与工程文件目录下的 impl > pnr 目录下。 ![sram_mode](./assets/sram_mode.png) 接着来点击红框处开始进行烧录 ![sram_download](./assets/sram_download.png) 有问题的话可以前往 [常见问题](https://wiki.sipeed.com/hardware/zh/tang/common doc/questions.html) 自行排查。 到这里就下载完成了。 ### 下载到 Flash 上面说过下载到 SRAM 是为了快速验证，但是不能上电运行程序。 所以想要上电运行的话我们需要设置下载到 Flash。 和上面下载到 SRAM 的步骤几乎类似，先点开 Operation 下面的功能框来打开设备设置界面，接着在 Operation 框中选择 External Flash Mode 选项来设置为下载到外部 Flash ，最后点击下面的那三个点点框来选择我们所生成的 .fs 下载固件，通常来说下载固件生成与工程文件目录下的 impl > pnr 目录下。最后在下面的外部 Flash 选项中选择设备为 Generic Flash 。 ![flash_mode](./assets/flash_mode.png) 接着来点击红框处开始进行烧录 ![flash_download](./assets/flash_download.png) 然后我们的程序重新上电也能照样运行了。 有问题的话可以前往 [常见问题](https://wiki.sipeed.com/hardware/zh/tang/common doc/questions.html) 自行排查。 ### 代码效果 使用 Sipeed 的 PMOD 后，如下图所示有一个灯在闪。 ![result](./assets/result.gif) ## 常见问题 前往 [常见问题](./../../../docs/hardware/zh/tang/common doc/questions.html) 查看一般的解决方法"},"/news/others/threshold/threshold.html":{"title":"在线图传调试 LAB 阈值","content":" title: 在线图传调试 LAB 阈值 keywords: LAB, 阈值, threshold, desc: Threshold 简介 date: 2022 07 12 tags: 图传 ,在线调试 , 阈值 cover: ./assets/threshold.png 网上发现一篇不错的文章。这里转载一下，有较大改动 [原文链接](https://bbs.elecfans.com/jishu_2290503_1_1.html) <! more > ## 前言 根据 官方MaixPy3 和 M2 Dock 的相关说明和官方文档与样例，在大家的帮助下，学习了基础的魔方色块的寻找功能。再此分享给大家。 ## 基础科普 ### 图传 图传的概念，在无人机中非常常见。 简单来讲，就是把摄像头拍摄的实时视频，又快又好的传递到终端设备上呈现——既要速度，不能卡，卡了没意思；也要质量，清晰度不能低，低了没得玩。而传输速度快，质量高，会占用较多的设备资源，以及需要较大的带宽。所以设计一个上好的图传方案和系统，是很多该行业厂家的重大追求目标之一。 ### LAB Lab是一种用数字化的方法来描述人的视觉感应的颜色系统。它是一种设备无关的、基于生理特征的颜色系统。在机器视觉中，Lab的概念会经常提及。 可以用一张图，来详细描述Lab颜色空间： ![lab](./assets/lab.png) 上示图片，是从人的视觉感应角度来看的。 首先是L：表示亮度，从纯黑到纯白，取值为 [0 > 100] 然后是a：表示从蓝色到红色的范围，取值为 [ 128 > 127] 最后是b：表示从蓝色到黄色的范围，取值为 [ 128 > 127] 通常，Lab会以范围的形式来表示，也就是Lab阈值，因为因为现场环境的不同，我们看到的颜色，不可能是完完全全的理论纯色，所以给出一定的容错范围； 例如：[(0, 100, 21, 127, 128, 9)]，分别表示：L min、L max、a min、a max、b min、b max，机器视觉就根据这个范围，来进行颜色判断。 ## M2Dock 启用图传 ### 相关代码 了解相关概念后，可以开始使用 M2 Dock 图传功能了。 下面就是相关启用图传代码了。其实在[官方文档](https://wiki.sipeed.com/soft/maixpy3/zh/usage/net.html#MJPG %E5%9B%BE%E4%BC%A0 %E6%80%8E%E4%B9%88%E7%94%A8%EF%BC%9F)都写过 ```python from maix import camera, mjpg, utils, display queue mjpg.Queue(maxsize 8) mjpg.MjpgServerThread(\"0.0.0.0\", 18811, mjpg.BytesImageHandlerFactory(q queue)).start() while True: img camera.capture() jpg utils.rgb2jpg(img.convert(\"RGB\").tobytes(), img.width, img.height) queue.put(mjpg.BytesImage(jpg)) display.show(img) ``` 上面的代码有三种运行方式： 1. 在 jupyter 的网页编辑界面，运行上述代码 2. 可以用 adb shell 或者 ssh 连接到 M2 Dock 后，运行 python ，再输入代码运行 3. 用 adb shell 或者 ssh 连接到 M2 Dock 后，用vim编辑 tuchuan.py 并保存后，再执行 python ./tuchuan.py 来运行代码 当然对于小白来说，方式1最方便，方式2最麻烦。但是方式3运行效率最好 正确运行上述代码后，接可以开启图传功能了。 ### 实际使用 要访问M2 Dock提供的图传功能，可以有几种方式，根据不同情况可以选择不同方式： #### 使用 OTG 连接运行代码 使用 jyputer 或 adb shell 都可以算作是使用 otg 连接板子 这种情况在成功弹出U盘（即正常连接）后可以在浏览器访问 [http://127.0.0.1:18811](http://127.0.0.1:188811) 来打开图传页面。 ![local](./assets/local.png) 原理可查看[这里](https://wiki.sipeed.com/soft/maixpy3/zh/tools/MaixPy3_IDE.html#IDE %E8%BF%9E%E6%8E%A5%E5%8E%9F%E7%90%86) #### 非 OTG 运行代码 使用串口或者ssh或者设置成开机运行的代码的话，均可认为是非 OTG 运行代码，这个时候我们要通过IP来访问板子图传网址了，即访问 http://设备ip地址:18811 来查看图传实例 ![wireless](./assets/threshold.png) ## Lab 阈值实例 前面说过，机器视觉中会利用到 Lab，同样的，MaixPy3 也提供了很简单的方法来应用 Lab 阈值。 这里有一个能直接使用的在线工具: [https://wiki.sipeed.com/threshold](https://wiki.sipeed.com/threshold)（加载有点慢） 提供了一个简单的示例，可以自己通过调整下面滑块位置或者输入阈值数值来查看不同的效果 ![threshold](./assets/threshold.png) 也可以自己手动上传图片然后查看不同阈值所产生的效果，当然这里主要介绍无线调整阈值功能。 > 因为浏览器安全方面的权限，我们需要把 [https://wiki.sipeed.com/threshold](https://wiki.sipeed.com/threshold) 先保存到本地才能进行局域网图传。 使用键盘上面的 `Ctrl + S` 两个按键来将该网页保存到本地，然后在浏览器打开保存到本地的网页就等于在本地运行 [https://wiki.sipeed.com/threshold](https://wiki.sipeed.com/threshold) 了，接着就可以开始后续的操作来实现局域网图传了。 成功运行上面[图传代码](#m2dock 启用图传)且能够在浏览器地址栏中输入板子相应的 IP 地址和图传端口号来访问图传画面后，就可以在本地阈值网页中输入正确的图传 IP 后来直接调整阈值了。下图中右上角有一个图传地址的输入栏，在那里输入正确查看 m2dock 图传的 IP 后就能够实时查看摄像头录制画面且能够实时调整阈值了。 ![threshold_1](./assets/wireless_1.png) 熟练的话可以知道能够调整a值来获取橙色色块阈值，做到下面的效果： ![threshold_2](./assets/wireless_2.png) 上图中可以看到除了红色和橙色之外的颜色都被过滤掉了，其他颜色都成了黑色区域。 可以再调整一下L，来使得比较黑的红色也被排除掉 ![threshold_3](./assets/wireless_3.png) 换到其他魔方面调整阈值来说橙色模块更准确点： ![threshold_4](./assets/wireless_4.png) 尽量在多个颜色里面来选出自己需要的颜色，因此像下面这种同一面颜色的不好选出差别 ![threshold_5](./assets/wireless_5.png) 所以把魔方打乱后识别效果合适很多。 通过上述说明，可以逐步得到模仿六种颜色的阈值了。 ## 实战演示 这里使用一个金字塔魔方来进行展示： <img src \"./assets/cube_1.png\" width 50% alt cube_1><img src \"./assets/cube_2.png\" width 50% alt cube_2> 使用支架来将 m2dock 摄像头对准魔方 ![snap](./assets/snap.png) 在电脑上进行阈值的调整 ![change](./assets/change.png) 最终得到下面的四组值： ```python [(0, 100, 128, 23, 128, 127)], #绿色 [(10, 100, 30, 127, 37, 127)], #红色 [(40, 100, 25, 42, 7, 127)], #黄色 [(0, 100, 128, 127, 128, 46)], #蓝色 ``` 根据官方例程修改后得到下面代码： ```python from maix import image, display, camera color [ [(0, 100, 128, 23, 128, 127)], #绿色 [(10, 100, 30, 127, 37, 127)], #红色 [(40, 100, 25, 42, 7, 127)], #黄色 [(0, 100, 128, 127, 128, 46)], #蓝色 ] # 0.5.0 以后蓝色的 lab 阈值，0.4.9 之前为 [(13, 11, 91, 54, 48, 28)] font_color [ # 边框和文字颜色，暂时都用白色 (255,255,255), # 绿色 (255,255,255), # 红色 (255,255,255), # 黄色 (255,255,255) # 白色 ] name_color ('green', 'red', 'yellow', 'blue') while True: img camera.capture() for n in range(0,4): blobs img.find_blobs(color[n]) #在图片中查找lab阈值内的颜色色块 if blobs: for i in blobs: if i[\"w\"]>15 and i[\"h\"]>15: img.draw_rectangle(i[\"x\"], i[\"y\"], i[\"x\"] + i[\"w\"], i[\"y\"] + i[\"h\"], color font_color[n], thickness 1) #将找到的颜色区域画出来 img.draw_string(i[\"x\"], i[\"y\"], name_color[n], scale 0.8, color font_color[0], thickness 1) #在红色背景图上写下hello worl display.show(img) ``` 运行上述代码后，识别的效果如下： <img src \"./assets/result_1.png\" width 50% alt result_1><img src \"./assets/result_2.png\" width 50% alt result_2> 可以看到已经成功识别出魔方颜色块，且效果还不错。 具体效果视频可以前往 [原链接](https://bbs.elecfans.com/jishu_2290503_1_1.html) 查看"},"/news/others/python_use.html":{"title":"Python 变量作用域","content":" title: Python 变量作用域 keywords: Python, 作用域, desc: Python作用域说明 date: 2022 07 13 tags: Python 这里说明一下 Python 变量作用域，帮助大家更好地使用 Python； [原文链接](https://www.cnblogs.com/Jolly hu/p/12228320.html) <! more > ## 作用域简介 **作用域指的是变量的有效范围**。变量并不是在任何位置都可以访问的，访问权限取决于这个变量是在哪里赋值的，也就是在哪个作用域内的。 通常而言，在编程语言中，变量的作用域从代码结构形式来看，有块级、函数、类、模块、包等由小到大的级别。但是在 Python 中，没有块级作用域，也就是类似 if语句块、for语句块、with上下文管理器 等等是不存在作用域概念的，他们等同于普通的语句 ```python if True: # if语句块没有作用域 x 1 print(x) # 1 def func(): # 函数有作用域 a 8 print(a) # Traceback (most recent call last): # File \"<pyshell#3>\", line 1, in <module> # a # NameError: name 'a' is not defined ``` 上面的代码可以试着运行一下，然后发现在 if 语句内定义的变量 x，可以被外部访问，而在函数 func() 中定义的变量 a，则无法在外部访问。 通常，函数内部的变量无法被函数外部访问，但内部可以访问；类内部的变量无法被外部访问，但类的内部可以。通俗来讲，就是内部代码可以访问外部变量，而外部代码通常无法访问内部变量。 变量的作用域决定了程序的哪一部分可以访问哪个特定的变量名称。 Python 的作用域一共有4层，分别是： L （Local） 局部作用域 E （Enclosing） 闭包函数外的函数中 G （Global） 全局作用域 B （Built in） 内建作用域 ```python global_var 0 # 全局作用域 def outer(): out_var 1 # 闭包函数外的函数中 def inner(): inner_var 2 # 局部作用域 ``` 前面说的都是变量可以找得到的情况，那如果出现本身作用域没有定义的变量，那该如何寻找呢？ Python 以 L –> E –> G –>B 的规则查找变量，即：在局部找不到，便会去局部外的局部找（例如闭包），再找不到就会去全局找，最后去内建中找。 如果这样还找不到，那就提示变量不存在的错误。例如下面的代码，函数 func 内部并没有定义变量 a，可是 print 函数需要打印 a，那怎么办？ 向外部寻找！按照 L –> E –> G –>B 的规则，层层查询，这个例子很快就从外层查找到了 a，并且知道它被赋值为 1，于是就打印了 1。 ```python a 1 def func(): print(a) ``` ## 全局变量和局部变量 定义在函数内部的变量拥有一个局部作用域，被叫做局部变量，定义在函数外的拥有全局作用域的变量，被称为全局变量。（类、模块等同理） 所谓的局部变量是相对的。局部变量也有可能是更小范围内的变量的外部变量。 局部变量只能在其被声明的函数内部访问，而全局变量可以在整个程序范围内访问。调用函数时，所有在函数内声明的变量名称都将被加入到作用域中。 ```python a 1 # 全局变量 def func(): b 2 # 局部变量 print(a) # 可访问全局变量a,无法访问它内部的c def inner(): c 3 # 更局部的变量 print(a) # 可以访问全局变量a print(b) # b对于inner函数来说，就是外部变量 print(c) ``` ## global 和 nonlocal 关键字 我们先看下面的例子： ```python total 0 # total是一个全局变量 def plus( arg1, arg2 ): total arg1 + arg2 # total在这里是局部变量. print(\"函数内局部变量total \", total) print(\"函数内的total的内存地址是: \", id(total)) return total plus(10, 20) print(\"函数外部全局变量total \", total) print(\"函数外的total的内存地址是: \", id(total)) ``` 很明显，函数 plus 内部通过 total arg1 + arg2 语句，新建了一个局部变量 total，它和外面的全局变量 total 是两码事。而如果我们想要在函数内部修改外面的全局变量 total 呢？使用 global 关键字！ > global：指定当前变量使用外部的全局变量 ```python global：指定当前变量使用外部的全局变量 total 0 # total是一个全局变量 def plus( arg1, arg2 ): global total # 使用global关键字申明此处的total引用外部的total total arg1 + arg2 print(\"函数内局部变量total \", total) print(\"函数内的total的内存地址是: \", id(total)) return total plus(10, 20) print(\"函数外部全局变量total \", total) print(\"函数外的total的内存地址是: ``` 所运行结果： ```python 函数内局部变量total 30 函数内的total的内存地址是: 503494624 函数外部全局变量total 30 函数外的total的内存地址是: 503494624 ``` 我们再来看下面的例子： ```python a 1 print(\"函数outer调用之前全局变量a的内存地址： \", id(a)) def outer(): a 2 print(\"函数outer调用之时闭包外部的变量a的内存地址： \", id(a)) def inner(): a 3 print(\"函数inner调用之后闭包内部变量a的内存地址： \", id(a)) inner() print(\"函数inner调用之后，闭包外部的变量a的内存地址： \", id(a)) outer() print(\"函数outer执行完毕，全局变量a的内存地址： \", id(a)) ``` 如果你将前面的知识点都理解通透了，那么这里应该没什么问题，三个 a 各是各的 a，各自有不同的内存地址，是三个不同的变量。 打印结果也很好的证明了这点： ```python 函数outer调用之前全局变量a的内存地址： 493204544 函数outer调用之时闭包外部的变量a的内存地址： 493204576 函数inner调用之后闭包内部变量a的内存地址： 493204608 函数inner调用之后，闭包外部的变量a的内存地址： 493204576 函数outer执行完毕，全局变量a的内存地址： 493204544 ``` 那么，如果，inner 内部想使用 outer 里面的那个 a，而不是全局变量的那个 a，怎么办？用 global 关键字？先试试看吧： ```python a 1 print(\"函数outer调用之前全局变量a的内存地址： \", id(a)) def outer(): a 2 print(\"函数outer调用之时闭包外部的变量a的内存地址： \", id(a)) def inner(): global a # 注意这行 a 3 print(\"函数inner调用之后闭包内部变量a的内存地址： \", id(a)) inner() print(\"函数inner调用之后，闭包外部的变量a的内存地址： \", id(a)) outer() print(\"函数outer执行完毕，全局变量a的内存地址： \", id(a)) ``` 运行结果如下，很明显，global使用的是全局变量a。 ```python 函数outer调用之前全局变量a的内存地址： 494384192 函数outer调用之时闭包外部的变量a的内存地址： 494384224 函数inner调用之后闭包内部变量a的内存地址： 494384256 函数inner调用之后，闭包外部的变量a的内存地址： 494384224 函数outer执行完毕，全局变量a的内存地址： 494384256 ``` 那怎么办呢？使用 nonlocal 关键字！它可以修改嵌套作用域（enclosing 作用域，外层非全局作用域）中的变量。将 global a 改成 nonlocal a 后运行，代码这里我就不重复贴了， 运行后查看结果，可以看到我们真的引用了 outer 函数的 a 变量。 ```python 函数outer调用之前全局变量a的内存地址： 497726528 函数outer调用之时闭包外部的变量a的内存地址： 497726560 函数inner调用之后闭包内部变量a的内存地址： 497726592 函数inner调用之后，闭包外部的变量a的内存地址： 497726592 函数outer执行完毕，全局变量a的内存地址： 497726528 ``` ## 面试真题 不要上机测试，请说出下面代码的运行结果： ```python a 10 def test(): a + 1 print(a) test() ``` 很多同学会说，这太简单了！函数内部没有定义 a，那么就去外部找，找到 a 10，于是加 1，打印 11！ 我会告诉你，这段代码有语法错误吗？a + 1 相当于 a a + 1，按照赋值运算符的规则是先计算右边的 a+1。但是，Python 的规则是，如果在函数内部要修改一个变量，那么这个变量需要是内部变量，除非你用 global 声明了它是外部变量。很明显，我们没有在函数内部定义变量 a，所以会弹出局部变量在未定义之前就引用的错误。 ## 更多的例子 再来看一些例子（要注意其中的闭包，也就是函数内部封装了函数）： ```python name 'jack' def outer(): name 'tom' def inner(): name 'mary' print(name) inner() outer() ``` 上面的题目很简单，因为inner函数本身有name变量，所以打印结果是mary。那么下面这个呢？ ```python name 'jack' def f1(): print(name) def f2(): name 'eric' f1() f2() ``` 这题有点迷惑性，想了半天，应该是‘eric’吧，因为 f2 函数调用的时候，在内部又调用了 f1 函数，f1 自己没有 name 变量，那么就往外找，发现 f2 定义了个 name，于是就打印这个 name。错了！！！结果是‘jack’！ **Python函数的作用域取决于其函数代码块在整体代码中的位置，而不是调用时机的位置**。调用 f1 的时候，会去 f1 函数的定义体查找，对于 f1 函数，它的外部是 name 'jack'，而不是 name 'eric'。 再看下面的例子，f2 函数返回了 f1 函数： ```python name 'jack' def f2(): name 'eric' return f1 def f1(): print(name) ret f2() ret() ``` 仔细回想前面的例子，其实这里有异曲同工之妙，所以结果还是‘jack’。"},"/news/others/busybox_related/busybox_related.html":{"title":"Ubuntu 下 busybox 的妙用","content":" title: Ubuntu 下 busybox 的妙用 keywords: Ubuntu, busybox, 小技巧, mount, nfs date: 2022 07 08 tags: busybox, Linux Linux 下有不少好用的工具，BusyBox 就是其中的一个 <! more > ## Busybox 简介 作为一个开源 (GPL) 项目，Busybox 一个没令人失望。在 Linux 这么多年且这么多次的版本更新中，一些类似于 `devmem` 之类的命令被更改掉了，然后挂载 nfs 系统的命令 `mount nfs` 也不一定直接适用与新版本系统了，然而这些都可以通过 Busybox 来解决。 ## 安装 Busybox 对于普通的 Linux 发行版可以直接使用命令行来安装。比如 Ubuntu 系统直接使用 `sudo apt install Busybox` 命令就能完成安装了，其他的版本可以自行寻找或编译对应的 Busybox。 ## 相关使用 安装完 Busybox 后，可以直接执行 `busybox` 来查看是否有信息打印出来，比如执行完`busybox`指令后的部分信息打印如下： ```bash BusyBox v1.30.1 (Ubuntu 1:1.30.1 4ubuntu6.4) multi call binary. BusyBox is copyrighted by many authors between 1998 2015. Licensed under GPLv2. See source distribution for detailed copyright notices. Usage: busybox [function [arguments]...] or: busybox list[ full] or: busybox show SCRIPT or: busybox install [ s] [DIR] or: function [arguments]... ``` 对于一些程序，出于安全或者性能因素，在新版本中修改了部分内容。想执行旧版软件里的相关功能的话，可以通过 busybox 来解决。 下面举两个例子 ### devmem 与 devmem2 对于 `devmem` 命令，在新版的都被 `devmem2` 所替代了，但是可以通过 busybox 来调用运行 `devmem` 命令。 ```bash home:~$ devmem2 Usage: devmem2 { address } [ type [ data ] ] address : memory address to act upon type : access operation type : [b]yte, [h]alfword, [w]ord data : data to be written ``` ```bash home:~$ busybox devmem BusyBox v1.30.1 (Ubuntu 1:1.30.1 4ubuntu6.4) multi call binary. Usage: devmem ADDRESS [WIDTH [VALUE]] Read/write from physical address ADDRESS Address to act upon WIDTH Width (8/16/...) VALUE Data to be written ``` ### mount nfs 对于较新版本的 `mount` 命令，在挂载 nfs 文件系统的时候会出错。 ```bash mount: /mnt/nfs: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.<type> helper program. ``` 这个时候使用 `busybox mount` 来替代 `mount` 来挂载 nfs 文件系统就不会再报错了。 大概原因是因为系统默认为安装 nfs 的相关工具，这个时候使用 busybox 里面的 mount 可以节约大量的时间。"},"/news/others/tinymaix_cnx/tinymaix_cnx.html":{"title":"TinyMaix ：超轻量级推理框架","content":" title: TinyMaix ：超轻量级推理框架 keywords: TinyMaix, Sipeed, 框架, 机器学习 date: 2022 08 24 tags: TinyMaix, 推理框架 <! more > ## 介绍 TinyMaix 是面向单片机的超轻量级的神经网络推理库，即 TinyML 推理库，可以让你在任意单片机上运行轻量级深度学习模型。 **关键特性** 核心代码少于 **400行**(`tm_layers.c`+`tm_model.c`+`arch_cpu.h`), 代码段(.text)少于**3KB** 低内存消耗，甚至 **Arduino ATmega328** (32KB Flash, 2KB Ram) 都能基于 TinyMaix 跑 mnist(手写数字识别) 支持 **INT8/FP32/FP16** 模型，实验性地支持 **FP8** 模型，支持 keras h5 或 tflite 模型转换 支持多种芯片架构的专用指令优化: **ARM SIMD/NEON/MVEI，RV32P, RV64V** 友好的用户接口，只需要 load/run 模型~ 支持全静态的内存配置(无需 malloc ) 即将支持 [MaixHub](https://maixhub.com) **在线模型训练** **在Arduino ATmega328上运行 mnist demo 实例** ``` mnist demo 0000000000000000000000000000 0000000000000000000000000000 0000000000000000000000000000 000000000077AFF9500000000000 000000000AFFFFFFD10000000000 00000000AFFFD8BFF70000000000 00000003FFD2000CF80000000000 00000004FD10007FF40000000000 00000000110000DFF40000000000 00000000000007FFC00000000000 0000000000004FFE300000000000 0000000000008FF9000000000000 00000000000BFF90000000000000 00000000001EFE20000000000000 0000000000CFF800000000000000 0000000004FFB000000000000000 000000001CFF8000000000000000 000000008FFA0000000000000000 00000000FFF10000000000000000 00000000FFF21111000112999900 00000000FFFFFFFFA8AFFFFFFF70 00000000AFFFFFFFFFFFFFFA7730 0000000007777AFFF97720000000 0000000000000000000000000000 0000000000000000000000000000 0000000000000000000000000000 0000000000000000000000000000 0000000000000000000000000000 use 49912us 0: 0 1: 0 2: 89 3: 0 4: 1 5: 6 6: 1 7: 0 8: 0 9: 0 ### Predict output is: Number 2, prob 89 ``` ## TODO 1. 将 `tm_layers.c` 优化到 `tm_layers_O1.c`, 目标提升速度到 `1.4~2.0X` 2. 针对 64/128/256/512KB 内存限制，找到合适的骨干网络 3. 增加例程：Detector,KWS,HAR,Gesture,OCR,... 4. ... 如果想参与进 TinyMaix 的开发，或者想与 TinyML 爱好者交流， 请加入 telegram 交流群：https://t.me/tinymaix ## TinyMaix 设计思路 TinyMaix 是专为低资源的单片机所设计的 AI 神经网络推理框架，通常被称为 **TinyML** 现在已经有很多 TinyML 推理库，比如 TFLite micro, microTVM, NNoM, 那为什么又捏了 TinyMaix 这个轮子呢? TinyMaix 是两个周末业余时间完成的项目，所以它足够简单，可以再30分钟内走读完代码，可以帮助TinyML新手理解它是怎么运行的。 TinyMaix 希望成为一个足够简单的 TinyML 推理库，所以它放弃了很多特性，并且没有使用很多现成的 NN 加速库，比如 CMSIS NN 在这个设计思路下，TinyMaix 只需要5个文件即可编译~ 我们希望 TinyMaix 可以帮助任何单片机运行 AI 神经网络模型, 并且每个人都能移植 TinyMaix 到自己的硬件平台上~ > 注意：虽然 TinyMaix 支持多架构加速，但是它仍然需要更多工作来平衡速度和尺寸 ### 设计特性 [x] 最高支持到 mobilenet v1, RepVGG 的骨干网络 因为它们对单片机来说是最常用的，最高效的结构 [x] 基础的 Conv2d, dwConv2d, FC, Relu/Relu6/Softmax, GAP, Reshape [ ] MaxPool, AvgPool (现在使用 stride 代替) [x] FP32 浮点模型, INT8 量化模型, **FP16**半精度模型 [x] 转换 keras h5 或 tflite 到 tmdl 简单模型使用keras/tf训练已经足够 复用了tflite现成的量化功能 [x] 模型统计功能 可选以减少代码尺寸 ### 可考虑添加的特性 [ ] INT16 量化模型 优点: 更精确 对于 SIMD/RV32P 指令加速更友好 缺点: 占用了 2 倍的 FLASH/RAM [ ] Concat 算子 优点: 支持 mobilenet v2, 模型精度更高 缺点: 占用了 2 倍的 RAM concat 张量占用了更多时间，使得模型运算变慢 需要更多转换脚本工作转换分支模型到扁平结构 [ ] Winograd 卷积优化 优点: 可能加速卷积计算 缺点: 增加了 RAM 空间和带宽消耗 增大了代码段(.text)尺寸 需要很多变换，弱单片机可能会消耗更多时间 ### 不考虑添加的特性 [ ] BF16 模型 多数单片机不支持 BF16 计算 精度不会比 INT16 高太多 占用了 2 倍的 FLASH/RAM [ ] AVX/vulkan 加速 TinyMaix 是为单片机设计的，所以不考虑电脑/手机的支持 [ ] 其他多样化的算子 TinyMaix 仅为单片机提供基础模型算子支持，如果你需要更特殊的算子，可以选择 TFlite micro/TVM/NCNN... ## 例程体验 ### mnist MNIST 是手写数字识别任务，简单到以至于可以在 ATmega328 这样的 8 位单片机上运行。 在电脑上测试： ``` cd examples/mnist mkdir build cd build cmake .. make ./mnist ``` ### mbnet mbnet (mobilenet v1) 是适用于移动手机设备的简单图像分类模型，不过对单片机来说也稍微困难了些。 例程里的模型是 mobilenet v1 0.25，输入 128x128x3 的RGB图像，输出 1000 分类的预测 它需要至少 128KB SRAM 和 512KB Flash, STM32F411 是典型可以运行该模型的最低配置。 在 PC 上测试运行 mobilenet 1000分类图片例程 ``` cd examples/mbnet mkdir build cd build cmake .. make ./mbnet ``` ## 如何使用 (API) ### 加载模型 ``` tm_err_t tm_load (tm_mdl_t* mdl, const uint8_t* bin, uint8_t*buf, tm_cb_t cb, tm_mat_t* in); ``` mdl: 模型句柄; bin: 模型bin内容; buf: 中间结果的主缓存；如果NULL，则内部自动malloc申请；否则使用提供的缓存地址 cb: 网络层回调函数; in: 返回输入张量，包含输入缓存地址 //可以忽略之，如果你使用自己的静态输入缓存 ### 移除模型 ``` void tm_unload(tm_mdl_t* mdl); ``` ### 输入数据预处理 ``` tm_err_t tm_preprocess(tm_mdl_t* mdl, tm_pp_t pp_type, tm_mat_t* in, tm_mat_t* out); ``` TMPP_FP2INT //用户自己的浮点缓存转换到int8缓存 TMPP_UINT2INT //典型uint8原地转换到int8数据；int16则需要额外缓存 TMPP_UINT2FP01 //uint8转换到0~1的浮点数 u8/255.0 TMPP_UINT2FPN11//uint8转换到 1~1的浮点数 ### 运行模型 ``` tm_err_t tm_run (tm_mdl_t* mdl, tm_mat_t* in, tm_mat_t* out); ``` ## 如何移植 TinyMaix的核心文件只有这5个：`tm_model.c`, `tm_layers.c`, `tinymaix.h`, `tm_port.h`, `arch_xxx.h` 如果你使用没有任何指令加速的普通单片机，选择 `arch_cpu.h`, 否则选择对应架构的头文件 然后你需要编辑 `tm_port.h`，填写你需要的配置，所有配置宏后面都有注释说明 注意 `TM_MAX_CSIZE`,`TM_MAX_KSIZE`,`TM_MAX_KCSIZE` 会占用静态缓存。 最后你只需要把他们放进你的工程里编译~ ## 怎样训练/转换模型 在 examples/mnist 下有训练脚本可以学习如何训练基础的mnist模型 > 注意：你需要先安装TensorFlow (> 2.7) 环境. 完成训练并保存h5模型后，你可以使用以下脚本转换原始模型到 tmdl 或者 c 头文件。 1. h5_to_tflite.py 转换 h5 模型到浮点或者 int8 量化的 tflite 模型 python3 h5_to_tflite.py h5/mnist.h5 tflite/mnist_f.tflite 0 python3 h5_to_tflite.py h5/mnist.h5 tflite/mnist_q.tflite 1 quant_img_mnist/ 0to1 2. tflite2tmdl.py 转换 tflite 文件到 tmdl 或者 c 头文件 python3 tflite2tmdl.py tflite/mnist_q.tflite tmdl/mnist_q.tmdl int8 1 28,28,1 10 ``` pack model head mdl_type 0 out_deq 1 input_cnt 1 output_cnt 1 layer_cnt 6 buf_size 1464 sub_size 0 in_dims [3, 28, 28, 1] out_dims [1, 1, 1, 10] pack layers CONV_2D [3, 28, 28, 1] [3, 13, 13, 4] in_oft:0, size:784; out_oft:784, size:680 padding valid layer_size 152 CONV_2D [3, 13, 13, 4] [3, 6, 6, 8] in_oft:784, size:680; out_oft:0, size:288 padding valid layer_size 432 CONV_2D [3, 6, 6, 8] [3, 2, 2, 16] in_oft:0, size:288; out_oft:1400, size:64 padding valid layer_size 1360 MEAN [3, 2, 2, 16] [1, 1, 1, 16] in_oft:1400, size:64; out_oft:0, size:16 layer_size 48 FULLY_CONNECTED [1, 1, 1, 16] [1, 1, 1, 10] in_oft:0, size:16; out_oft:1448, size:16 layer_size 304 SOFTMAX [1, 1, 1, 10] [1, 1, 1, 10] OUTPUT! in_oft:1448, size:16; out_oft:0, size:56 layer_size 48 pack done! model size 2.4KB (2408 B) FLASH buffer size 1.4KB (1464 B) RAM single layer mode subbuff size 1.4KB (64+1360 1424 B) RAM Saved to tmdl/mnist_q.tmdl, tmdl/mnist_q.h ``` 现在你有了 tmdl 或者 C 头文件，把它放到你的工程里编译吧~ ## 使用 Maixhub 在线训练模型 TODO ## 怎样添加新平台的加速代码 TinyMaix 使用基础的点积函数加速卷积运算 你需要在 src 里添加 arch_xxx_yyy.h, 并添上你自己平台的点积加速函数： ``` TM_INLINE void tm_dot_prod(mtype_t* sptr, mtype_t* kptr,uint32_t size, sumtype_t* result); ``` ## 贡献/联系 如果你需要向TinyMaix贡献代码，请先阅读“TinyMaix设计思路”一节，我们只需要“设计内的特性”和“可考虑添加的特性”。 如果你想要提交你的移植测试结果，请提交到 benchmark.md. 我们非常欢迎你移植 TinyMaix 到自己的芯片/板子上，这会证明使用 TinyMaix 运行深度学习模型是非常容易的事情~ 如果你对 TinyMaix 的使用和移植有问题，可以在此仓库提交 Issues。 如果你有商业或私有项目咨询，你可以发邮件到 support@sipeed.com 或 zepan@sipeed.com (泽畔)."},"/news/others/v831_resnet18/v831_resnet18.html":{"title":"在V831上（awnn）跑 pytorch resnet18 模型","content":" title: 在V831上（awnn）跑 pytorch resnet18 模型 keywords: V831,awnn,resnet18 date: 2022 06 13 tags: V831,awnn,resnet18 在V831上（awnn）跑 pytorch resnet18 模型，和模型转换方法 <! more > 版权声明：本文为 neucrack 的原创文章，遵循 CC 4.0 BY SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://neucrack.com/p/358 原文时间：2021.04.10， 搬运有改动 可以参考一下 ## 直接使用 Pytorch hub 与模型训练 此处省略模型定义和训练过程，仅使用 pytorch hub 的 resnet18 预训练模型进行简单介绍 https://pytorch.org/hub/pytorch_vision_resnet/ ## 在 PC 端测试模型推理 根据上面链接的使用说明，使用下面代码可以运行模型 其中，label 下载：https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt ```python import os import torch from torchsummary import summary ## model model torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained True) model.eval() input_shape (3, 224, 224) summary(model, input_shape, device \"cpu\") ## test image filename \"out/dog.jpg\" if not os.path.exists(filename): if not os.path.exists(\"out\"): os.makedirs(\"out\") import urllib url, filename (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", filename) try: urllib.URLopener().retrieve(url, filename) except: urllib.request.urlretrieve(url, filename) print(\"test image:\", filename) ## preparing input data from PIL import Image import numpy as np from torchvision import transforms input_image Image.open(filename) # input_image.show() preprocess transforms.Compose([ transforms.Resize(max(input_shape[1:3])), transforms.CenterCrop(input_shape[1:3]), transforms.ToTensor(), transforms.Normalize(mean [0.485, 0.456, 0.406], std [0.229, 0.224, 0.225]), ]) input_tensor preprocess(input_image) print(\"input data max value: {}, min value: {}\".format(torch.max(input_tensor), torch.min(input_tensor))) input_batch input_tensor.unsqueeze(0) # create a mini batch as expected by the model ## forward model # move the input and model to GPU for speed if available if torch.cuda.is_available(): input_batch input_batch.to('cuda') model.to('cuda') with torch.no_grad(): output model(input_batch) ## result # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes # print(output[0]) # The output has unnormalized scores. To get probabilities, you can run a softmax on it. max_1000 torch.nn.functional.softmax(output[0], dim 0) max_idx int(torch.argmax(max_1000)) with open(\"imagenet_classes.txt\") as f: labels f.read().split(\"\\n\") print(\"result: idx:{}, name:{}\".format(max_idx, labels[max_idx])) ``` 运行结果如下： ```python Using cache found in /home/neucrack/.cache/torch/hub/pytorch_vision_v0.6.0 Layer (type) Output Shape Param # Conv2d 1 [ 1, 64, 112, 112] 9,408 BatchNorm2d 2 [ 1, 64, 112, 112] 128 ReLU 3 [ 1, 64, 112, 112] 0 MaxPool2d 4 [ 1, 64, 56, 56] 0 Conv2d 5 [ 1, 64, 56, 56] 36,864 BatchNorm2d 6 [ 1, 64, 56, 56] 128 ReLU 7 [ 1, 64, 56, 56] 0 Conv2d 8 [ 1, 64, 56, 56] 36,864 BatchNorm2d 9 [ 1, 64, 56, 56] 128 ReLU 10 [ 1, 64, 56, 56] 0 BasicBlock 11 [ 1, 64, 56, 56] 0 Conv2d 12 [ 1, 64, 56, 56] 36,864 BatchNorm2d 13 [ 1, 64, 56, 56] 128 ReLU 14 [ 1, 64, 56, 56] 0 Conv2d 15 [ 1, 64, 56, 56] 36,864 BatchNorm2d 16 [ 1, 64, 56, 56] 128 ReLU 17 [ 1, 64, 56, 56] 0 BasicBlock 18 [ 1, 64, 56, 56] 0 Conv2d 19 [ 1, 128, 28, 28] 73,728 BatchNorm2d 20 [ 1, 128, 28, 28] 256 ReLU 21 [ 1, 128, 28, 28] 0 Conv2d 22 [ 1, 128, 28, 28] 147,456 BatchNorm2d 23 [ 1, 128, 28, 28] 256 Conv2d 24 [ 1, 128, 28, 28] 8,192 BatchNorm2d 25 [ 1, 128, 28, 28] 256 ReLU 26 [ 1, 128, 28, 28] 0 BasicBlock 27 [ 1, 128, 28, 28] 0 Conv2d 28 [ 1, 128, 28, 28] 147,456 BatchNorm2d 29 [ 1, 128, 28, 28] 256 ReLU 30 [ 1, 128, 28, 28] 0 Conv2d 31 [ 1, 128, 28, 28] 147,456 BatchNorm2d 32 [ 1, 128, 28, 28] 256 ReLU 33 [ 1, 128, 28, 28] 0 BasicBlock 34 [ 1, 128, 28, 28] 0 Conv2d 35 [ 1, 256, 14, 14] 294,912 BatchNorm2d 36 [ 1, 256, 14, 14] 512 ReLU 37 [ 1, 256, 14, 14] 0 Conv2d 38 [ 1, 256, 14, 14] 589,824 BatchNorm2d 39 [ 1, 256, 14, 14] 512 Conv2d 40 [ 1, 256, 14, 14] 32,768 BatchNorm2d 41 [ 1, 256, 14, 14] 512 ReLU 42 [ 1, 256, 14, 14] 0 BasicBlock 43 [ 1, 256, 14, 14] 0 Conv2d 44 [ 1, 256, 14, 14] 589,824 BatchNorm2d 45 [ 1, 256, 14, 14] 512 ReLU 46 [ 1, 256, 14, 14] 0 Conv2d 47 [ 1, 256, 14, 14] 589,824 BatchNorm2d 48 [ 1, 256, 14, 14] 512 ReLU 49 [ 1, 256, 14, 14] 0 BasicBlock 50 [ 1, 256, 14, 14] 0 Conv2d 51 [ 1, 512, 7, 7] 1,179,648 BatchNorm2d 52 [ 1, 512, 7, 7] 1,024 ReLU 53 [ 1, 512, 7, 7] 0 Conv2d 54 [ 1, 512, 7, 7] 2,359,296 BatchNorm2d 55 [ 1, 512, 7, 7] 1,024 Conv2d 56 [ 1, 512, 7, 7] 131,072 BatchNorm2d 57 [ 1, 512, 7, 7] 1,024 ReLU 58 [ 1, 512, 7, 7] 0 BasicBlock 59 [ 1, 512, 7, 7] 0 Conv2d 60 [ 1, 512, 7, 7] 2,359,296 BatchNorm2d 61 [ 1, 512, 7, 7] 1,024 ReLU 62 [ 1, 512, 7, 7] 0 Conv2d 63 [ 1, 512, 7, 7] 2,359,296 BatchNorm2d 64 [ 1, 512, 7, 7] 1,024 ReLU 65 [ 1, 512, 7, 7] 0 BasicBlock 66 [ 1, 512, 7, 7] 0 AdaptiveAvgPool2d 67 [ 1, 512, 1, 1] 0 Linear 68 [ 1, 1000] 513,000 Total params: 11,689,512 Trainable params: 11,689,512 Non trainable params: 0 Input size (MB): 0.57 Forward/backward pass size (MB): 62.79 Params size (MB): 44.59 Estimated Total Size (MB): 107.96 out/dog.jpg tensor(2.6400) tensor( 2.1008) idx:258, name:Samoyed, Samoyede ``` 可以看到模型有 11,689,512 个参数，差不多 11MiB 左右，这个大小也几乎是实际在 831 上运行的模型大小了 ## 将模型转换为 V831 能使用的模型文件 转换过程如下： 使用 Pytorch 将模型导出为 onnx 模型， 得到 onnx 文件 ```python def torch_to_onnx(net, input_shape, out_name \"out/model.onnx\", input_names [\"input0\"], output_names [\"output0\"], device \"cpu\"): batch_size 1 if len(input_shape) 3: x torch.randn(batch_size, input_shape[0], input_shape[1], input_shape[2], dtype torch.float32, requires_grad True).to(device) elif len(input_shape) 1: x torch.randn(batch_size, input_shape[0], dtype torch.float32, requires_grad False).to(device) else: raise Exception(\"not support input shape\") print(\"input shape:\", x.shape) # torch.onnx._export(net, x, \"out/conv0.onnx\", export_params True) torch.onnx.export(net, x, out_name, export_params True, input_names input_names, output_names output_names) onnx_out \"out/resnet_1000.onnx\" ncnn_out_param \"out/resnet_1000.param\" ncnn_out_bin \"out/resnet_1000.bin\" input_img filename torch_to_onnx(model, input_shape, onnx_out, device \"cuda:0\") ``` 如果你不是使用 pytorch 转换的, 而是使用了现成的 ncnn 模型, 不知道输出层的名字, 可以在 https://netron.app/ 打开模型查看输出层的名字 使用 onnx2ncnn 工具将 onnx 转成 ncnn 模型，得到一个 .param 文件和一个 .bin 文件 按照 ncnn 项目的编译说明编译，在 build/tools/onnx 目录下得到 onnx2ncnn 可执行文件 ```python def onnx_to_ncnn(input_shape, onnx \"out/model.onnx\", ncnn_param \"out/conv0.param\", ncnn_bin \"out/conv0.bin\"): import os # onnx2ncnn tool compiled from ncnn/tools/onnx, and in the buld dir cmd f\"onnx2ncnn {onnx} {ncnn_param} {ncnn_bin}\" os.system(cmd) with open(ncnn_param) as f: content f.read().split(\"\\n\") if len(input_shape) 1: content[2] + \" 0 {}\".format(input_shape[0]) else: content[2] + \" 0 {} 1 {} 2 {}\".format(input_shape[2], input_shape[1], input_shape[0]) content \"\\n\".join(content) with open(ncnn_param, \"w\") as f: f.write(content) onnx_to_ncnn(input_shape, onnx onnx_out, ncnn_param ncnn_out_param, ncnn_bin ncnn_out_bin) ``` ## 使用全志提供的awnn工具将ncnn模型进行量化到int8模型 在 maix.sipeed.com 模型转换 将 ncnn 模型转换为 awnn 支持的 int8 模型 （网页在线转换很方便人为操作，另一个方面因为全志要求不开放 awnn 所以暂时只能这样做） 阅读转换说明，可以获得更多详细的转换说明 ![](./assets/convert.png) 这里有几组参数： 均值 和 归一化因子： 在 pytorch 中一般是 `(输入值 mean ) / std`, awnn 对输入的处理是 `(输入值 mean ) * norm`, 总之，让你训练的时候的输入到第一层网络的值范围和给 awnn 量化工具经过 `(输入值 mean ) * norm` 计算后的值范围一致既可。 比如这里打印了实际数据的输入范围是 [ 2.1008, 2.6400]， 是代码中 preprocess 对象处理后得到的，即 `x (x mean) / std > (0 0.485)/0.229 2.1179`, 到 awnn 就是 `x (x mean_2*255) * (1 / std * 255)` 即 `mean2 mean * 255`, `norm 1/(std * 255)`, 更多可以看[这里](https://github.com/Tencent/ncnn/wiki/FAQ ncnn produce wrong result#pre process)。 所以我们这里可以设置 均值为 `0.485 * 255 123.675`， 设置 归一化因子为 `1/ (0.229 * 255) 0.017125`， 另外两个通道同理。但是目前 awnn 只能支持三个通道值一样。。。所以填 `123.675, 123.675, 123.675，0.017125, 0.017125, 0.017125` 即可，因为这里用了 pytorch hub 的预训练的参数，就这样吧， 如果自己训练，可以好好设置一下 图片分辨率（问不是图片怎么办？貌似 awnn 暂时之考虑到了图片。。） RGB 格式： 如果训练输入的图片是 RGB 就选 RGB 量化图片， 选择一些和输入尺寸相同的图片，可以从测试集中拿一些，不一定要图片非常多，但尽量覆盖全场景（摊手 自己写的其它模型转换如果失败，多半是啥算子不支持，上图框出的地方查看所支持的算子，比如现在的版本view、 flatten、reshape 都不支持所以写模型要相当小心，后面的版本会支持 flatten reshape 等 CPU 算子 如果不出意外， 终于得到了量化好的 awnn 能使用的模型， *.param 和 *.bin ## 使用模型，在v831上推理 可以使用 python 或者 C 写代码，以下两种方式 ### MaixPy3 python 请看 [MaixPy3](https://wiki.sipeed.com/soft/maixpy3/zh/) 不想看文档的话，就是在系统开机使用的基础上， 更新 MaixPy3 就可以了： ```bash pip install upgrade maixpy3 ``` 然后在终端使用 python 运行脚本（可能需要根据你的文件名参数什么的改一下代码）： https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/load_forward_camera.py label 在这里： https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/classes_label.py ```python from maix import nn from PIL import Image, ImageDraw from maix import camera, display test_jpg \"/root/test_input/input.jpg\" model { \"param\": \"/root/models/resnet_awnn.param\", \"bin\": \"/root/models/resnet_awnn.bin\" } camera.config(size (224, 224)) options { \"model_type\": \"awnn\", \"inputs\": { \"input0\": (224, 224, 3) }, \"outputs\": { \"output0\": (1, 1, 1000) }, \"first_layer_conv_no_pad\": False, \"mean\": [127.5, 127.5, 127.5], \"norm\": [0.00784313725490196, 0.00784313725490196, 0.00784313725490196], } print(\" load model:\", model) m nn.load(model, opt options) print(\" load ok\") print(\" read image\") img Image.open(test_jpg) print(\" read image ok\") print(\" forward model with image as input\") out m.forward(img, quantize True) print(\" read image ok\") print(\" out:\", out.shape) out nn.F.softmax(out) print(out.max(), out.argmax()) from classes_label import labels while 1: img camera.capture() if not img: time.sleep(0.02) continue out m.forward(img, quantize True) out nn.F.softmax(out) msg \"{:.2f}: {}\".format(out.max(), labels[out.argmax()]) print(msg) draw ImageDraw.Draw(img) draw.text((0, 0), msg, fill (255, 0, 0)) display.show(img) ``` ### C 语言 SDK,libmiax 按照 https://github.com/sipeed/libmaix 的说明克隆仓库，并编译 https://github.com/sipeed/libmaix/tree/master/examples/nn_resnet 上传编译成功后dist目录下的所有内容到 v831, 然后执行./start_app.sh即可"},"/news/others/831_ssh/831_ssh.html":{"title":"使用 SSH 来连接 M2Dock","content":" title: 使用 SSH 来连接 M2Dock keywords: MaixII, SSH date: 2022 07 19 tags: MaixII, ssh, adb Linux 系统可以使用 ssh 远程被操作，但是对于 M2Dock 还有另一种用法 <! more > 内容较多，对新手很有帮助 ## SSH 简介 SSH 为 Secure Shell 的缩写，是建立在应用层基础上的安全协议，可以有效防止远程管理过程中的信息泄露问题。 因为其易用且安全，所以被广泛使用。 ## 软件准备 ### MobaXterm 这里使用 [MobaXterm](https://mobaxterm.mobatek.net/) 来作为主要软件进行示例。 因为它免费且易用，所以就用它了。 当然这里主要是使用它的 SSH 功能，其他诸多强大功能各位可以自行尝试 #### 下载 MobaXterm 点击这个链接 [https://mobaxterm.mobatek.net/download home edition.html](https://mobaxterm.mobatek.net/download home edition.html) 可以跳转到下载界面。 这里我们选择 [Portable edition](https://download.mobatek.net/2212022060563542/MobaXterm_Portable_v22.1.zip) （携带版（下载后解压就可以用）） <details> <summary><font color #4F84FF>点开查看下载页面截图</font></summary> <img src \"./assets/mobaxterm_protable_edition.png\" alt \"Portable edition\"> </details> 下载解压后文件夹里是这样的: <details> <summary><font color #4F84FF>点开查看解压后文件夹</font></summary> <img src \"./assets/mobaxterm_snapshot.png\" alt \"mobaxterm_snapshot\"> </details> 里面只有一个可执行的 mobaxterm 本体文件与一个插件文件 ### ADB M2Dock 带有 adb 功能。 可以进行端口转发然后通过 USB 数据线与电脑进行 SSH 连接，比使用无线 SSH 连接更加稳定。 如果曾经自行配置过 adb 那可以直接看[操作步骤](#操作步骤) ### 下载 adb #### Linux 安装 adb Ubuntu 用户可以直接使用包管理器来安装。 在命令行终端执行 `sudo apt get install android tools adb` 来安装 adb。 且安装后能直接通过命令行调用 adb 程序。 #### Windows 配置 adb Windows 用户可以在 [这里](https://developer.android.google.cn/studio/releases/platform tools?hl zh cn) 下载 adb。 ![下载adb](./assets/download_adb.png) 然后自行选择合适的地方解压文件，并把其文件路径复制一下： 比如我这里是直接把可执行文件(adb.exe)所在的路径全都复制了，因此**我**此次所用路径为 `Y:\\platform tools_r33.0.2 windows\\platform tools` (仅举例用) ![copy_path](./assets/copy_path.png) 但是为了能够随时在命令行终端里使用 adb 命令我们需要把它添加到系统路径： Windows10 和 Windows11 用户可以直接在任务栏的搜索里面输入 `path` 来打开系统属性 其他版本可以通过点开下面的箭头来查看系统属性的方法：<details> <summary><font color #4F84FF>点开查看打开系统属性方法</font></summary> 右键此电脑然后选择最下面的属性选项 （鼠标右键 ① 处，然后鼠标左键点击弹出菜单的最下面的 ② 处的属性） <img src \"./assets/right_click.png\" alt \"open system properties\"> </details> 然后在弹出的系统属性窗口中依次点击 ① 和 ② 处来打开环境变量 ![system properties](./assets/system_properties.png) 在弹出的窗口中上面的一栏中双击名为 Path 的变量来对其进行编辑 ![path](./assets/path.png) 双击空白处相当于添加一个条目，这里我们把之前复制的 adb 路径存入其中， 比如对于我之前复制的路径为 `Y:\\platform tools_r33.0.2 windows\\platform tools`，因此在下面所所添加的内容就是 `Y:\\platform tools_r33.0.2 windows\\platform tools`，具体内容应当根据每个人的情况而定(不会有人和我一样的) ![adb_path](./assets/add_path.png) 接着单击所有已打开窗口的 OK 来保存配置。 > 如果进行了错误的操作那就点击取消然后从头再来，系统环境是很危险的配置，不要随意删除 然后就可以在命令行终端中执行一次 adb 来检查一下是否正确配置了 需要保存环境变量配置和系统属性后在进行这一步 环境变量配置和系统属性保存需要新打开一个命令行终端来执行 adb 指令 ![adb_command](./assets/adb.png) 下面那一大堆就是相关的说明。但是在这里我们不太需要用，只要有对应的输出就行。 ## 操作步骤 1. 将 M2Dock 通过 otg接口与电脑相连且已弹出 U盘 2. 在命令行中执行 `adb forward tcp:22 tcp:22` 来进行端口映射 ![adb_forward](./assets/adb_forward.png) 3. 运行 MobaXterm ，可按照下面的 gif 或者图文进行创建 ssh 会话操作 <details> <summary><font color #4F84FF>点开查看创建 ssh 会话的 gif 操作</font></summary> <img src \"./assets/create_ssh.gif\" alt \"create_ssh\"> </details> <details> <summary><font color #4F84FF>点开查看创建 ssh 会话的图文版操作</font></summary> 单机左上角的 session 来创建会话 <img src \"./assets/click_session.png\" alt \"click_session\"> 在弹出的窗口中选择 SSH <img src \"./assets/click_ssh.png\" alt \"click_ssh\"> 因为前面执行过 adb forward 指令，因此在 Remote host 输入 127.0.0.1 <img src \"./assets/remote_host.png\" alt \"remote_host\"> 点击下方 OK 就完成了 SSH 会话的创建，接着会要求我们输入用户名和密码，均为 root，自行输入即可 输入密码的时候是没有输入显示的，但是错误就会提示。因此个人多试几次就行 <img src \"./assets/login.png\" alt \"login\"> 紧接着就成功登陆进来了 <img src \"./assets/succeed_login.png\" alt \"succeed_login\"> 点一下左下角的 Remote monitoring ，就能监视设备运行状态了 <img src \"./assets/monitor.png\" alt \"monitor\"> </details> 在成功使用 SSH 在 MobaXterm 软件中连上 M2Dock 后，可以看到在会话栏中看到设备里的文件。默认所查看的文件路径为当前用户的根目录。 <img src \"./assets/monitor.png\" alt \"monitor\"> 我们可以手动拖入或者拖出文件或者文件夹来进行电脑与板子互传文件的操作 当然也可以双击文件然后对其进行文本编辑: ![Edit_file](./assets/edit_file.gif) ## 其他 ### 开启自动保存 需要注意的是点击保存后还要选择一下确认保存到文件才行 比如出现下图的情况的话点击一次 Autosave 就可以让它以后不再弹出 ![autosave](./assets/autosave.png) ### 关闭 MaixPy3 IDE 使用 USB 数据线使电脑与板子进行 SSH 通信时，最好关闭电脑端的 MaixPy3 IDE，这样可以避免一些麻烦 ### 使用无线连接 将板子联网之后可以通过命令行来得到其 IP。 然后可以在新建 SSH 会话的时候把板子的 IP 填入到 Remote host 中。 就可以通过无线网来使电脑与板子使用 SSH 进行通信 ![ifconfig](./assets/ifconfig.png) 板子没能成功连接到无线网就不会被分配 IP ### adb forward adb forward 的功能是建立一个端口转发，比如 `adb forward tcp:11111 tcp:22222` 的是将 PC 端的11111 端口收到的数据，转发给到 adb 设备的 22222 端口。 SSH 默认的端口为 22 ，因此使用 `adb forward tcp:22 tcp:22` 是将电脑端的 22 端口转发到 adb 设备的 22 端口。 例如使用 `adb forward tcp:1145 tcp:22` 命令的话，需要把配置 IP 处的端口修改一下: ![port](./assets/port.png)"},"/news/others/v831_opencv/v831_opencv.html":{"title":"给 M2Dock 安装 Opencv","content":" title: 给 M2Dock 安装 Opencv keywords: M2Dock, Opencv, Python, V831 date: 2023 03 20 tags: Opencv, M2Dock, V831 M2Dock 既然能够运行 Python, 那么我们也可以给它安装 Opencv。 <! more > ## 前言 由于 V831 性能有限，且交叉编译什么的对于大多数人来说太烦琐了，因此这里提供一个 github 上的一位的大神 [irfan798](https://github.com/irfan798) 所 release 的一个适用于 M2Dock 的 Opencv 库。 仓库地址: [v83x_opencv 4.5.5.62_numpy 1.19.2](https://github.com/irfan798/maix3_opencv_python/releases/tag/cv 4.5.5.62_numpy 1.19.2) 相关的使用方法在 release 页面已经写了，但是不会操作话可以继续往下面看。 ## 下载、安装、运行 M2Dock 版本为最新镜像。 ### 下载 opencv 安装文件 ![download_open](./assets/download_opencv.png) 点击上图中红框处的文件即可下载由 [irfan798](https://github.com/irfan798) 所发布的适用于 M2Dock 的 Opencv Python 安装包。 把下载下来的名为 `opencv_python_headless 4.5.5.62 cp38 cp38 linux_armv7l.whl` 文件复制到由 M2Dock 在电脑上所显示的 U 盘中。 > 下载站备份站： [点我](https://dl.sipeed.com/shareURL/others/m2dock_opencv) ### 安装 opencv 软件包 在 adb 命令行终端中依次执行下面的命令来在 M2Dock 上安装刚刚所下载的 Opencv Python 安装包： 安装的时候显示内存不足的话，可以在 M2Dock 上执行 `rm rf home/model/` 删除内置模型文件来腾出空间安装 Opencv. 下面的安装操作都在 M2Dock 的命令终端执行。 ```shell sync #刷新所有文件 pip install /root/opencv_python_headless 4.5.5.62 cp38 cp38 linux_armv7l.whl upgrade #安装刚刚下载的 Opencv Python 安装包 ``` ### 查看运行结果 成功安装完之后我们可以在 M2Dock 上运行 Opencv 了。如下所示: ```python import os # 当前系统为 v831 m2dock maixpy3 0.5.4 20230310.zip 系统镜像 # https://api.dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/release print(os.system(\"pip list > /tmp/tmp.log\")) with open(\"/tmp/tmp.log\") as f: print(f.read()) ``` 结果如下： ![m2dock_opencv_command_result](./assets/m2dock_opencv_command_result.png) 从上面可以看到有 `opencv` 和 `numpy`。在自己的执行结果中没有看到 `Numpy` 的话, 可以重新烧录最新的 m2dock 镜像来得到。 ## 体验 opencv ```python from maix import camera, display, image import cv2 print(cv2) img image.new(size (120, 120), mode \"RGB\", color (255, 255, 255)) img.draw_line(0, 0, 120, 120) img.draw_rectangle(40, 80, 120, 120, color (255, 0, 0), thickness 16) # img.draw_circle(120, 120, 20, color (0, 255, 0)) img.draw_string(40, 40, \"dalaoshu\", 2, color (0, 0, 255)) import cv2 import numpy as np cv_img cv2.imdecode(np.frombuffer(img.tobytes('jpg'), np.uint8), cv2.IMREAD_COLOR) cv_img cv_img[ : , : , (2,1,0)] tmp image.load(cv_img.tobytes(), cv_img.shape) while True: img camera.capture() #从摄像头中获取一张图像 img.draw_image(tmp) display.show(img) #将图像显示出来 ``` 可以看到结果如下： ![m2dock_opencv_command_result](./assets/m2dock_opencv_result_download.jpg) ## 常见问题 如果 `pip list` 没看到 `Numpy`, 可以通过更新到最新的 m2dock 镜像来解决。 安装的时候显示内存不足的话，可以删除一下内置模型文件 `rm rf home/model/` 建议使用 Maixpy3 来进行编程使用，这个 opencv 不支持使用 `show` 图像，且不能操作板子上的摄像头，只支持 usb 摄像头。"},"/news/others/color_introduction/color_introduction.html":{"title":"常见的图像颜色空间解释","content":" title: 常见的图像颜色空间解释 keywords: Color, 色彩空间,RGB,HSV,YUV,LAB,CMYK desc: 色彩空间科普 date: 2022 06 11 tags: Color, 色彩空间 cover: ./assets/cover.png 常用颜色表示方法： RGB HSV YUV LAB CMYK <! more > 版权声明：本文为 neucrack 的原创文章，遵循 CC 4.0 BY SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://neucrack.com/p/294 ## RGB 红绿蓝 三色，也是大家熟悉光学三原色 RGB 使用加色模式，也就是默认是黑色，三原色相加获得白色， 比如下图`蓝色+绿色 青色(cyan)`，得到`蓝色 青色 绿色`也就是`蓝色 青色+绿色`的互补色， 绿色的互补色就是图中的`M(品红色）magenta`（同理蓝色的互补色是Y黄色）（互补色就是两者相加为白色），所以`蓝色 青色+品红色` ![](./assets/color_add.png) ![](./assets/coordinate_box.png) 上图可以看到灰度图在正方体对角线上，即三个通道（轴）的值相等时，值越大越白 ![](./assets/color.png) 一般两种表示方法： ### RGB888(24bit) RGB三个通道，每个通道分别用8bit长度表示，比如(255, 255, 255), 每个通道取值范围为[0, 255]，或者0xFFFFFF三个字节表示 ### RGB565(16bit) RGB三个通道分别用5bit 6bit 5bit表示，比如(31, 63, 31)，但一般不这样表示，使用两个字节表示，比如0xFFFF, 一般在编写程序时在内存中多使用以下两种布局方式： 第一种： ![](./assets/bgr_color.png) 第二种： ![](./assets/grgb_color.png) 这两种方式的不同主要是因为 RGB565 共占用 2 个字节， 两个字节的顺序不同造成的，把第二张图从中间分隔成两份，右边移到左边，就变成了第一种的排列方式了 C语言结构体如下： ```c #define COLOR_16_SWAP 1 typedef union { struct { #if COLOR_16_SWAP 0 uint16_t blue : 5; uint16_t green : 6; uint16_t red : 5; #else uint16_t green_h : 3; uint16_t red : 5; uint16_t blue : 5; uint16_t green_l : 3; #endif } ch; uint16_t full; } color16_t; ``` 比如`(1,2,3)` `(R, G, B)`： 使用第一种方式二进制值为 `B00001 000010 00011 ` 即 `B0000 1000 0100 0011`, 十六进制表示为 `0x0843`（注意这里表示方法从左到右是从高位到低位，上面的图从左到右是低位到高位）； 使用第二种方式二进制值为 `B010 00011 00001 000 `即 `B0100 0011 0000 1000`, 十六进制表示为 `0x4308`； ## HSV 相关解释： Hue（色调、色相） Saturation（饱和度、色彩纯净度） Value（明度） ![](./assets/hsv.png) ## HLS HLS 中的 L 分量为亮度，亮度为100，表示白色，亮度为0，表示黑色；HSV 中的 V 分量为明度，明度为100，表示光谱色，明度为0，表示黑色。 提取白色物体时，使用 HLS 更方便，因为 HSV 中的Hue里没有白色，白色需要由S和V共同决定（S 0, V 100）。而在 HLS 中，白色仅由亮度L一个分量决定。所以检测白色时使用 HSL 颜色空间更准确。 ![](./assets/hls.png) ## YUV Y'UV、YUV、YCbCr、YPbPr 几个概念其实是一回事儿。Y’UV、YUV 主要是用在彩色电视中，用于模拟信号表示。YCbCr 是用在数字视频、图像的压缩和传输，如 MPEG、JPEG。今天大家所讲的 YUV 其实就是指 YCbCr。Y 表示亮度（luma），CbCr 表示色度（chroma）。 另外Y’UV在取值上可以使正或者负数，但是Y’CbCr一般是 `16–235` 或者 `0–255` Y’UV 设计的初衷是为了使彩色电视能够兼容黑白电视。对于黑白电视信号，只需要 Y 通道， 在彩色电视则显示 YUV 信息 ![](./assets/yuv.png) ![](./assets/y'uv.png) ### 打包格式和采样 YUV 格式通常有两大类:打包(packed)格式和平面(planar)格式， 前者是每个像素为基本单位，一个一个像素的数据连续排列在内存中， 后者则是YUV 分成3个数组（内存块）存放， 另外还有Y和UV分开存放的（比如 YUV420SP（ Semi Planar， U和V交叉放，即YYYYYYYY…UVUV…） 和 YUV420P（先放U再放V，即YYYYYYYY…UUVV）） 人眼的视觉特点是对亮度更铭感，对位置、色彩相对来说不铭感。在视频编码系统中为了降低带宽，可以保存更多的亮度信息(luma)，保存较少的色差信息(chroma)。这叫做 chrominance subsamping, 色度二次采样。原则：在数字图像中，(1) 每一个图形像素都要包含 luma（亮度）值；（2）几个图形像素共用一个 Cb + Cr 值，一般是 2、4、8 个像素。 一般分为以下几种 YUV444：就是每个 Y 值对应一个 U 和 一个 V 值 YUV422: 就是图像的横轴（width方向） 4 个 Y 值公用 2 个 U 和V，纵轴（height方向）4 个 Y 对应了 4 个 U 和 4 个 V YUV420: 就是在 YUV422 的基础上， 纵轴的 U 和 V 数量也减半，每 2 个提供给 4 个 Y 配对使用 YUV411: 同理，就是 4 个 Y， 对应横轴和纵轴的 1 个 U 和 V ![](./assets/yuv_pack.png) `SP`(Semi Planar) 和 `P` 的说法， 区别就是在内存中的存放顺序不同, 比如 YUV420SP: ![](assets/yuv420sp.jpg) YUV420P: ![](assets/yuv420p.jpg) 另外，还有 NV12 和 NV21 的区别， 就是在 UV 的存放上顺序不同 NV12: IOS只有这一种模式。存储顺序是先存Y，再UV交替存储。YYYYUVUVUV NV21: 安卓的模式。存储顺序是先存Y，再存U，再VU交替存储。YYYYVUVUVU YUV与RGB之间的转换 略 参考代码： https://github.com/latelee/yuv2rgb ## LAB Lab颜色空间中的L分量用于表示像素的亮度，取值范围是[0,100],表示从纯黑到纯白；a表示从红色到绿色的范围，取值范围是[127, 128]；b表示从黄色到蓝色的范围，取值范围是[127, 128] ![](./assets/LAB.png) ## CMY & CMYK ![](./assets/cmyk_1.jpg) 一般用在印刷， 因为人眼看到的物体的颜色是反射光，而不是自发光，一束白光照到物体上，默认反射所有，即白色，人眼实际看到的颜色是用光的颜色减去材料吸收后的颜色,这时涂上黑色的颜料，即吸收了所有白光，所以人眼看到的是黑色。 利用色料的三原色混色原理，加上黑色油墨，共计四种颜色混合叠加，形成所谓“全彩印刷”。四种标准颜色是：`C：Cyan 青色`，又称为‘天蓝色’或是‘湛蓝’`M：Magenta 品红色`，又称为‘洋红色’；`Y：Yellow 黄色`；`K：blacK 黑色`，虽然有文献解释说这里的K应该是Key Color（定位套版色），但其实是和制版时所用的定位套版观念混淆而有此一说。此处缩写使用最后一个字母K而非开头的B，是为了避免与Blue混淆。CMYK模式是减色模式，相对应的RGB模式是加色模式。 印刷三原色如何得到黑色， 理论配色如下： > C(100) +M（100） +Y（100） 黑色（100，100，100） 可见黑色就是青色、品与黄色之和，但是这三种颜色混成的黑色不够纯，所以印刷学就引进了K(Black)黑色，因为B已经被Blue占用，所以黑色就只好用引文字母黑色的最后一个字母K, 哪么真正印刷的黑色配色如下: > C(100) +M（100） +Y（100） + K(100) 黑色 （100，100，100，100） 或者 > C(0) +M(0) + Y(0) + K(100) 黑色(0，0，0，100） 减色模式：前面说的由于物体是吸收了部分光，才呈现出特有的颜色，比如品红的物体，是吸收了它的互补色绿色（看前面的RGB对互补色的描述），也就是白色光减去了绿色才得到的颜色，所以称之为减色模式"},"/news/others/linux_adb/linux_adb.html":{"title":"Linux 连接不上 adb 设备","content":" title: Linux 连接不上 adb 设备 keywords: Linux, adb date: 2022 07 21 tags: Linux, adb 这里写一下 Linux 系统下连接 M2Dock 后可能出现的 adb 问题 ```bash user@ubuntu:~$ adb shell error: insufficient permissions for device ``` <! more > 在 linux 系统下连接 M2Dock 之后，使用 `adb shell` 后出现 `error: insufficient permissions for device` 。 ```bash user@ubuntu:~$ adb shell error: insufficient permissions for device ``` 这时我们应该使用命令 `lsusb` 来查看一下是否成功连接到系统了 ```bash lee@ubuntu:~$ lsusb Bus 001 Device 002: ID 18d1:0002 Google Inc. Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub ``` 比如上面的 `Google Inc` 就代表 adb 设备。 执行 `lsusb` 没有 `Google Inc` 显示的话，就先检查一下 M2Dock 是否正常启动了（手摸屏幕试试温度是最快的方法），确定正常启动后可以更换数据线或者使用别的 USB 口等方式来尝试成功连接到电脑。 根据上面显示出来的 `Bus 001 Device 002: ID 18d1:0002 Google Inc.` 信息，我们需要在 `/etc/udev/rules.d/` 新建一个名为 `51 android.rules` 的文件，其内容应该为 `SUBSYSTEM \"usb\", ATTRS{idVendor} \"18d1\", ATTRS{idProduct} \"0002\",MODE \"0666\"` ，其中 `ATTRS{idVendor}` 和 `ATTRS{idProduct}` 的值应该根据前面 `lsusb` 命令中的而修改，这里自己注意一下；最后更改文件权限： > 小白一键式命令 ```bash sudo echo \"SUBSYSTEM \"usb\", ATTRS{idVendor} \"18d1\", ATTRS{idProduct} \"0002\",MODE \"0666\"\" sudo tee /etc/udev/rules.d/51 android.rules sudo chmod a+x /etc/udev/rules.d/51 android.rules sudo udevadm control reload rules sudo service udev restart sudo udevadm trigger adb kill server adb start server ``` 上面的代码中，第一行写入了 `SUBSYSTEM \"usb\", ATTRS{idVendor} \"18d1\", ATTRS{idProduct} \"0002\",MODE \"0666\"` 内容到 `/etc/udev/rules.d/51 android.rules` 文件。 第二行更改了对应的文件权限，最后重启了一下 adb 服务将权限激活。 接着重新插拔 USB，在使用 `adb shell` 就发现可以正常操作 M2Dock 了。 有什么问题的话可以在下方留言来一起探讨"},"/news/others/maixII_connect_udisk.html":{"title":"MaixII 通过 USB OTG 口连接U盘","content":" title: MaixII 通过 USB OTG 口连接U盘 keywords: MaixII, U盘 date: 2022 06 14 tags: MaixII, U盘 MaixII的USB口是用来做device连接电脑跑adb的。 但是有没有方法可以在不跑adb的时候（总不能天天跑adb吧，再说adb也可以网络跑啊）连接一些USB设备玩玩呢。 > 2023年02月以后的 0.5.4 镜像支持 UVC 摄像头 TTY 串口 等设备了。 <! more > 原文链接：https://bbs.sipeed.com/thread/844 有改动 ## 摸索过程 MaixII dock 有两个接口，我们要更改 otg 口因此我们使用 UART口 连接电脑来更改板子设置 ### 看看在那里定义了 在 /etc/init.d/ 文件夹里面可以看到有如下的文件 ```bash root@sipeed:# ls /etc/init.d S00mpp S10udev S40network S52ntpd log rc.preboot S01audio S11dev S41netparam adbd network rcK S01logging S12usb S50telnet cron rc.final rcS S02app S20urandom S51dropbear fontconfig rc.modules sysntpd ``` 注意到里面有一个 `S12usb` 使用 `cat /etc/init.d/S12usb` 查看里面内容后发现有一句 ```bash otg_role `cat /sys/devices/platform/soc/usbc0/otg_role` ``` 抱着好奇的心态在设备上跑了这句脚本，结果如下所示： ```bash root@sipeed:~# cat /sys/devices/platform/soc/usbc0/otg_role usb_device ``` ### 切换为 USB host 再好奇下看这个 /sys/devices/platform/soc/usbc0 目录中都有啥，结果如下： ```bash root@sipeed:~# ls /sys/devices/platform/soc/usbc0 driver hw_scan_debug of_node subsystem usb_device usb_null driver_override modalias otg_role uevent usb_host ``` 重点是里面的：`usb_device` `usb_host` `usb_null` 那直接把 `usb_host` echo 到 `/sys/devices/platform/soc/usbc0/otg_role` 中看看啥效果： ```bash echo \"usb_host\" > /sys/devices/platform/soc/usbc0/otg_role ``` 然后我们使用 `lsusb` 看看都有啥 ```bash root@sipeed:~# lsusb Bus 001 Device 001: ID 1d6b:0002 Bus 002 Device 001: ID 1d6b:0001 ``` 哈，USB控制器出来了。 ### 连接USB设备 想着设备内识别SD卡，那U盘应该也差不多。插个U盘试下。 ```bash root@sipeed:~# lsusb Bus 001 Device 001: ID 1d6b:0002 Bus 001 Device 002: ID aaaa:8816 Bus 002 Device 001: ID 1d6b:0001 ``` 多出来一个设备，在 /dev 目录下看了下果然多出来一个sda： ```bash root@sipeed:/# ls /dev/sda sda sda1 sda2 ``` 挂载 U盘 试试： 出现 `Read only file system` 的话，重烧是最快的解决方法。 ```bash root@sipeed:~# mkdir p /home/usbdisk root@sipeed:~# mount /dev/sda2 /home/usbdisk/ root@sipeed:~# df Filesystem 1K blocks Used Available Use% Mounted on /dev/root 256512 88352 162920 35% / tmpfs 29864 12 29852 0% /tmp none 29796 0 29796 0% /dev /dev/mmcblk0p3 2013 1 2013 0% /mnt/cfg /dev/mmcblk0p6 2939292 59664 2863244 2% /mnt/UDISK /dev/sda4 7926272 405644 7520628 5% /home/usbdisk ``` 挂载成功。 然后，试了下无线网卡、USB串口啥的，基本都没识别出来，估计是驱动没有编译进去吧。"},"/news/others/usb_rndis/usb_rndis.html":{"title":"Ghost 系列 USB 网卡（RNDIS) 使用教程","content":" title: Ghost 系列 USB 网卡（RNDIS) 使用教程 keywords: USB, RNDIS, DRIVE date: 2022 10 20 tags: USB, RNDIS, DRIVE 本文为转载网上文章，与任何产品的使用无关，本文仅方便用户快速了解 USB RNDIS 驱动安装的详细过程，故转载了这篇文章：[原文链接](https://www.foream.com/wiki/docs/mindoc/mindoc 1b2er0dm4pos9) ## 简述 本文档主要描述 GHOST 4K 相机如何工作在 USB 网卡模式（符合 RNDIS 规范）如何 PC 端通过 USB 连接相机后与相机 TCP/IP 通讯，并通过 RTSP 或 RTMP 视频通讯协议获取到相机的视频流方法。本方法使用了 RNDIS `（Remote Network Driver Interface Specification）` 远程网络驱动接口规范， 就是在USB设备上跑 TCP/IP，让相机看上去像一块 PC 的网卡。 RNDIS 是 Windows7 的一部分， 但遗憾的是如果默认安装（插上符合 RNDIS 的设备时）一般均会安装失败，本文档会描述如何重新安装 RNDIS 驱动。 ## 如何 enable GHOST 4K 相机为USB网卡模式 1. 相机固件版本号： v2.0 以上 2. 在相机 SD 卡的根目录下创建文件名为 `fmcam.conf` 的文本文件 .. details:: 查看注意事项 请注意有些系统配置会自动加上 `.txt` 的扩展名变为 `fmcam.conf.txt` 请删除 `.txt`,确保文件名只为 `fmcam.conf`。 文件内容如下: usb_net 1 usb_net_host 192.168.5.1 usb_net_ip 192.168.5.2 3. 相机进入 USB 网卡模式后，相机 WIFI 指示灯会亮绿灯。 ## 如何在 Windows7 上安装 RNDIS 驱动 1. 相机使用如上 `mcam.conf` 脚本文件开机后，插入 USB 并连接到 PC 端，Windows7 会弹出正在安装设备驱动程序软件消息。 ![rndis one](./assets/rndis one.jpg) >**注意**： 请确保相机先开机，识别到有效的 `fmcam.conf` 脚本文件才会进 USB 网卡模式，如果是关机插入 USB 连接电脑，会进入到 MSC U 盘模式。 2. Windows 会自动搜索并安装 RNDIS 驱动，不过片刻之后您会发现安装失败。 ![rndis two](./assets/rndis two.jpg) 3. 右键点击桌面**计算机**图标，选择**管理**——**设备管理**，可以看到 `RNDIS/Ethernet Gadget` 设备，并且处于驱动未安装状态。 ![pc](./assets/pc.jpg) 4. 右键点击 `RNDIS/Ethernet Gadget` 设备，选择**更新驱动程序软件**，在如何搜索设备软件提示窗口中，选择**浏览计算机查找驱动程序软件（R）**。选择从设备列表中选择**网络适配器**。 ![gadget r](./assets/gadget. r.jpg) 5. 选择**从计算机的设备驱动程序列表中选择(L)**。 ![garget l](./assets/gadget l.jpg) 6. 在硬件设备列表中往下拉，找到**网络适配器**,选中并**下一步**。 ![rndis four](./assets/rndis four.jpg) 7. 在网络适配器窗口的制造商列表中选择**微软公司（Microsoft Corporation）**,右侧列表中选择远端 `RNDIS` 兼容设备（Remote NDIS Compatible Device） ![microsoft](./assets/microsoft.jpg) 8. 弹出如下警告窗口，请选 `YES` ![rndis five](./assets/rndis five.jpg) 9. 点击**是**并等待安装结束，`RNDIS` 设备将会安装成功 ![rndis six](./assets/rndis six.jpg) 10. 在**控制面板**中选择**网络和Internet**下的**查看网络状态和任务**： ![rndis seven](./assets/rndis seven.jpg) 11. 选择**更改适配器设置** ![rndis eight](./assets/rndis eight.jpg) 12. 可以看到网络连接中多了一个本地连接`（RNDIS/Ethernet Gedget）` ![rndis nine](./assets/rndis nine.jpg) 13. 设置新增的 `USB` 网卡的 `IP` 地址（要求与相机配置文件 `fmcam.conf` 指定的 `usb_net_host` 的值一致） 右击**本地连接（RNDIS/Ethernet Gadget)** ![rndis ten](./assets/rndis ten.jpg) 选中 **Internet 协议版本 4(TCP/IPv4)**，点击**属性**按键，指定 `PC` 网卡的 `IP` 地址为: `192.168.5.1`. ![ipv4](./assets/ipv4.jpg) 14. 判断 `PC` 与相机是否可以 `ping` 通，检测方法如下：从电脑开始里找到运行，然后在运行对话框中输入 `CMD` 命令，之后按回车键，进入 `CMD` 命令操作界面，如下图： ![cmd](./assets/cmd.jpg) 输入命令符按回车键（或点确认键）后即可进入 `CMD` 命令操作框，然后我们再输入 `ping` 命令，输入: `ping 192.168.5.2` ， 其中 `192.168.5.2` 是相机脚本文件，`fmcam.conf` 中用户设定的相机 `IP`。 ![ping](./assets/ping.jpg) 如果能 `ping` 通，说明相机与 `PC` 端建立 `TCP/IP` 连接成功。 ## PC 端如何获取相机的视频流 ### 设置视频流的分辨率及码率 在相机 `SD`卡中的配置文件 `fmcam.conf` 增加两个选项 `stream_resolution` 和 `stream_bitrate` 如： ```bash usb_net 1 usb_net_host 192.168.5.1 usb_net_ip 192.168.5.2 stream_resolution 4KUHD stream_bitrate 25000000 ``` `stream_resolution` 用于设置相机视频流的分辨率，可以为 `4KUHD/1080P/720P/WVGA` , 均为 `30fps` 分别代表如下分辨率： ```bash 4KUHD： 3840*2160 1080P： 1920*1080 720P： 1280*720 WVGA： 848*420 ``` `stream_bitrate` 用于设置相机视频流的码率，其中 1000000 代表 1Mbps, 25000000 代表 25Mbps, 800000 代表 800kbps. ### 获取 RTSP 视频流 `PC` 端安装 `VLC 播放器`，在菜单**媒体/打开网络串流**中输入 `rtsp://192.168.5.2/live`，可获得 `RTSP` 协议的视频流，其中 `192.168.5.2` 为相机的 `IP` 地址。 ![rtsp](./assets/rtsp.jpg) ### 如何 PC 端通过 USB 网卡模式获取多台 GHOST 4K 的视频流 1. 配置相机为 `USB` 网卡模式，并配置为不同的网段： CAM1 的脚本文件 `fmcam.conf` 如下： ```bash usb_net 1 usb_net_host 192.168.5.1 usb_net_ip 192.168.5.2 stream_resolution 4KUHD stream_bitrate 25000000 ``` CAM2 的脚本文件如下： ```bash usb_net 1 usb_net_host 192.168.6.1 usb_net_ip 192.168.6.2 stream_resolution 4KUHD stream_bitrate 25000000 ``` CAM3 的脚本文件如下： ```bash usb_net 1 usb_net_host 192.168.7.1 usb_net_ip 192.168.7.2 stream_resolution 4KUHD stream_bitrate 25000000 ``` CAM4 的脚本文件如下： ```bash usb_net 1 usb_net_host 192.168.8.1 usb_net_ip 192.168.8.2 stream_resolution 4KUHD stream_bitrate 25000000 ``` 2. 当这 4 台相机通过 `USB` 连接 `PC` 端后， 会分别提示安装 `RNDIS/Ethernet Gedget` 驱动，按上述方法安装驱动成功后，在网络连接中会多 4 个 `RNDIS/Ethernet Getget` 网卡，分别设置对应相机的 `USB` 网卡地址为如： CAM1 USB 网卡 IP 地址：`192.168.5.1` CAM2 USB 网卡 IP 地址：`192.168.6.1` CAM3 USB 网卡 IP 地址：`192.168.7.1` CAM4 USB 网卡 IP 地址：`192.168.8.1` 3. 获取多台设备的视频流, 这 4 台设备的 `RTSP` 视频流地址分别为： CAM1 USB 网卡 IP 地址：`rtsp://192.168.5.2/live` CAM2 USB 网卡 IP 地址：`rtsp://192.168.6.2/live` CAM3 USB 网卡 IP 地址：`rtsp://192.168.7.2/live` CAM4 USB 网卡 IP 地址：`rtsp://192.168.8.2/live`"},"/news/MaixPy3/maixpy3_easyuse/maixpy3_easyuse.html":{"title":"MaixPy3 源码怎么样","content":" title: MaixPy3 源码怎么样 keywords: V831, Maixpy3 date: 2022 04 29 tags: MaixPy3,QQ 这里只使用一张图来说明一下相关的结论 <! more > ![](./assets/pic.jpg)"},"/news/MaixPy3/camera_resize/camera_resize.html":{"title":"MaixPy3 Image.resize 的效果","content":" title: MaixPy3 Image.resize 的效果 keywords: MaixPy3, desc: 这里展示一下 MaixPy3 Image.resize 的效果 date: 2022 07 01 tags: MaixPy3, resize, teedoc 点击下载对应的 ipynb 文件后导入到 jupyter 照样能阅读 [源文件](https://dl.sipeed.com/fileList/others/wiki_news/maixpy3_resize/camera_resize.ipynb) <! more > ## 先写一些 jupyter 用法 每一个框框都被称之为单元格 单元格左方会有 蓝色 或者 绿色 两种颜色。绿色表示编辑模式；蓝色表示命令模式。 **编辑模式** ![edit_green](./assets/edit_green.jpg) **命令模式** ![command_blue](./assets/command_blue.jpg) 通用操作： Shift+ Enter ：运行单元格，且以命令模式切换到下一个单元格 Ctrl + Enter ：运行单元格，且进入命令模式 编辑模式操作： Esc ：进入命令模式 命令模式操作： **h :打开帮助** Enter :进入编辑模式 x :剪切单元格 c :复制单元格 v :粘贴单元格 dd :删除整个单元格 ii :终止运行 ## 开始演示效果 ### 试一下推流 ```python from maix import camera, display, image #引入python模块包 while True: img camera.capture() #从摄像头中获取一张图像 display.show(img) #将图像显示出来 #因为这是死循环，所以按一下 Esc 进入编辑模式然后 ii 终止一下代码 ``` 效果如下（视频被截成图片了）： ![推流](./assets/forever_show.jpeg) ### 设置一下图像分辨率 下面就直接捕获原图和使用 image.resize() 放一起对比一下 #### 试试 240*240 的显示效果 ``` python from maix import camera, display camera.config(size (240, 240)) #设置获取图像分辨率 img camera.capture() print(img) display.show(img) img.save(\"240x240.jpg\") ``` ![240*240](./assets/240_240.jpeg) #### 240\\*240图片resize到224\\*224 ```python from maix import camera, display camera.config(size (240, 240)) img camera.capture().resize(224, 224) display.show(img) ``` ![240*240 >224*224](./assets/240_240_224_224.png) #### 试试 320*240 的显示效果 ```python from maix import camera, display camera.config(size (320, 240)) img camera.capture() print(img) display.show(img) img.save(\"320x240.jpg\") ``` ![320*240](./assets/320_240.jpeg) #### 320\\*240图像resize到224\\*224 ```python from maix import camera, display camera.config(size (320, 240)) img camera.capture().resize(224, 244) display.show(img) ``` ![320*240 >224*224](./assets/320_240_224_224.png) #### 再试试 320*180 显示效果 ```python from maix import camera, display camera.config(size (320, 180)) #设置摄像头分辨率 img camera.capture() print(img) display.show(img) img.save(\"320x180.jpg\") ``` ![320*180](./assets/320_180.jpeg) #### 320\\*180图像resize到224\\*224 ```python from maix import camera, display camera.config(size (320, 180)) img camera.capture().resize(224, 244) display.show(img) ``` ![320*180 >224*224](./assets/320_180_224_224.png)"},"/news/MaixPy3/camera_lens_corr/v831_lens_corr.html":{"title":"MaxiPy3 Image.lens_corr 畸变矫正的用法","content":" title: MaxiPy3 Image.lens_corr 畸变矫正的用法 keywords: MaixPy3, desc: 这篇是关于镜头畸变矫正 `lens_corr` 函数的现象和用法。 date: 2023 05 08 tags: MaixPy3, lens_corr, image 这篇是关于镜头畸变矫正 `lens_corr` 函数的现象和用法。 ## 准备工作 这些交代一些相关的测试场景、以及准备工作等相关说明。 ![sensor](./assets/sensor.jpg) ### Jupyter 基础用法 这里默认大家已掌握 `Jupyter` 的相关使用方法，还有疑惑的小伙伴请自行学习。 ## 用法演示及效果 ### 获取一张 640*360 图像 先来试试摄像头正常捕捉 640*360 的图像效果。 ```python from maix import camera, display, image camera.config(size (640, 360)) while True: img camera.capture() display.show(img) ``` ![image](./assets/image.jpg) ### 添加 lens_corr 畸变矫正函数 相关代码行：`img img.lens_corr(strength 1.8, zoom 1.0)` **strength**：是一个浮点数而该值确定了对图像进行去鱼眼效果的程度. **zoom**：是在对图像进行缩放的数值（默认值为 1.0）. >使用以上函数对镜头进行畸变校正，去除因镜头畸变造成的图像鱼眼效果。 #### 试试 strength 为 1.8 的效果 ```python from maix import camera, display, image camera.config(size (640, 360)) while True: img camera.capture() img img.lens_corr(strength 1.8, zoom 1.0) display.show(img) ``` ![lens_1.8](./assets/lens_1.8.jpg) #### 试试 strength 为 2.0 的效果 ```python from maix import camera, display, image camera.config(size (640, 360)) while True: img camera.capture() img img.lens_corr(strength 2.0, zoom 1.0) display.show(img) ``` ![lens_2.0](./assets/lens_2.0.jpg) #### 试试 strength 为 2.1 的效果 ```python from maix import camera, display, image camera.config(size (640, 360)) while True: img camera.capture() img img.lens_corr(strength 2.1, zoom 0.9) display.show(img) ``` ![lens_2.1](./assets/lens_2.1.jpg) #### 畸变矫正前与后的对比 这里再获取一张未进行畸变矫正前的图像与上文进行对比，让效果更直观明显点。 ```python from maix import camera, display, image camera.config(size (640, 360)) while True: img camera.capture() display.show(img) ``` ![lens](./assets/lens.jpg)"},"/news/MaixPy3/v831_Distance/v831_Distance.html":{"title":"V831完美的单目测距","content":" title: V831完美的单目测距 keywords: V831, 单目, 测距 date: 2022 03 28 desc: V831完美的单目测距 tags: V83x,单目测距 <! more > 作者[我与nano](https://qichenxi.blog.csdn.net/?type blog)，[原文链接](https://blog.csdn.net/qq_51963216/article/details/123745657) ## 前言 经过一下午的努力，最终终于实现了完美的单目测距，网上教的都是opencv怎么测算距离，人家有函数唉，入手了V831，做了人脸识别，同时进行了测距，K210通用。废话不多说上图。 ![单目测距](./assets/distance_measure.png) ![摄像头距离](./assets/Camera_length.png) 它那个镜头其实还要在靠近里面一点，距离应该是28.4到28.5之间。测得真的特别准。 ## 单目测距的原理 ![principle](./assets/principle.png) 小孔成像。很简单，用的是小孔成像，原理大家都知道。该怎么做呢。 我们需要以下几个参数： 1、相机焦距 2、物体宽度 3、一个常数 ## 参数计算 ### 相机焦距 假设我们有一个宽度为 W 的目标。然后我们将这个目标放在距离我们的相机为 D 的位置。我们用相机对物体进行拍照并且测量物体的像素宽度 P 。这样我们就得出了相机焦距的公式： F (P x D) / W 举个例子，假设我在离相机距离 D 28cm的地方放一张 待识别图片（W 13)并且拍下一张照片。我测量出照片的像素宽度为 P 53 像素 ![](./assets/length_calculate.png) 因此我的焦距 F 是： F (53*28) / 13 116 有人会问像素怎么获得呢，直接看代码吧 ```python img.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color bg_color, thickness 2) img.draw_rectangle(box[0], box[1] font_wh[1], box[0] + font_wh[0], box[1], color bg_color, thickness 1) img.draw_string(box[0], box[1] font_wh[1], disp_str, color font_color) img.draw_string(0,30, \"x \"+str(((box[0]+box[3])/2) 35), color font_color) img.draw_string(70,30, \"y \"+str((box[1]+box[2])/2), color font_color) Lm (box[1]+box[3])/2 length K*13/Lm img.draw_string(0,60 , \"Z \"+str(length), color font_color) ``` 你识别到一个物体，然后给它画框，用一个列表表示出来四个点 Lm （box[1]+box[3]）/2 这个就是像素值 ### 测距 继续将相机移动，靠近或者离远物体或者目标时，可以用相似三角形计算出物体离相机的距离： L (W x F) / P 假设我将相机移到距离目标 28cm 的地方识别物体。通过自动的图形处理我可以获得图片的像素为 53像素。将这个代入公式，得： L (13 x 116) / 53 28 这样我们就精准的算出了距离。 附上代码 ```python from maix import camera, image, display import serial ser serial.Serial(\"/dev/ttyS1\",115200) # 连接串口 K 116 class Face_recognize : score_threshold 70 #识别分数阈值 input_size (224, 224, 3) #输入图片尺寸 input_size_fe (128, 128, 3) #输入人脸数据 feature_len 256 #人脸数据宽度 steps [8, 16, 32] # channel_num 0 #通道数量 users [] #初始化用户列表 threshold 0.5 #人脸阈值 nms 0.3 max_face_num 3 #输出的画面中的人脸 def __init__(self): from maix import nn, camera, image, display from maix.nn.app.face import FaceRecognize for i in range(len(self.steps)): self.channel_num + self.input_size[1] / self.steps[i] * (self.input_size[0] / self.steps[i]) * 2 self.channel_num int(self.channel_num) #统计通道数量 global face_recognizer face_recognizer Face_recognize() while True: img camera.capture() #获取224*224*3的图像数据 AI_img img.copy().resize(224, 224) faces face_recognizer.face_recognizer.get_faces(AI_img.tobytes(),False) #提取人脸特征信息 if faces: for prob, box, landmarks, feature in faces: disp_str \"face\" bg_color (0, 255, 0) font_color (255, 0, 0) box,points face_recognizer.map_face(box,landmarks) font_wh image.get_string_size(disp_str) for p in points: img.draw_rectangle(p[0] 1, p[1] 1, p[0] + 1, p[1] + 1, color bg_color) img.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color bg_color, thickness 2) img.draw_rectangle(box[0], box[1] font_wh[1], box[0] + font_wh[0], box[1], color bg_color, thickness 1) img.draw_string(box[0], box[1] font_wh[1], disp_str, color font_color) img.draw_string(0,30, \"x \"+str(((box[0]+box[3])/2 28)), color font_color) img.draw_string(70,30, \"y \"+str((box[1]+box[2])/2 20), color font_color) x (box[0]+box[3])/2 28 y (box[1]+box[2])/2 Lm (box[1]+box[3])/2 length K*13/Lm img.draw_string(0,60 , \"Z \"+str(round(length)), color font_color) display.show(img) ``` ## 总结 **主要原理就是小孔成像**"},"/news/MaixPy3/run_lvgl/run_lvgl.html":{"title":"V831 如何使用 libmaix SDK C++ 开发","content":" title: V831 如何使用 libmaix SDK C++ 开发 keywords: V831, 交叉编译, lvgl date: 2022 05 19 desc: V831 如何使用 libmaix SDK C++ 开发 交叉编译 tags: V831，交叉编译 <! more > 作者[Song](QQ群友)，原文文件 [点我下载](https://dl.sipeed.com/fileList/others/wiki_news/v831_lvgl_news/220519UbuntuForV831%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.pptx) 下面为重新整理的部分内容 ## 准备环境 ### 准备 linux 一般在 linux 系统下开发比 windows 系统里问题少。因此首先自己整一个 linux 环境先。 物理机和虚拟机都可以 下面使用 Ubuntu18.04 作为实验系统。 首先安装相关依赖 `sudo apt install build essential cmake python3 sshpass git` 然后确保一下cmake版本> 3.9 ![](./assets/cmake version.png) ### 配置交叉编译链 先下载这个[点我跳转](https://dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/Toolchain) ![](./assets/toolchain.png) 接着再对应的下载目录执行下面的命令将工具链解压到 /opt 目录下 `sudo tar Jxvf toolchain sunxi musl pack 2021 01 09.tar.xz C /opt` ### 获取libmaix源码 新建一个文件夹后打开文件夹。 在对应文件夹的终端使用下面命令来获取源码 `git clone https://github.com/sipeed/libmaix recursive` 一定要确保全部下载完成，否则后面会因为找不到文件编译出错。 ### 开始编译 #### 尝试编译helloworld 先进入 libmaix 源码目录的 helloworld 文件夹里 ```bash cd libmaix/examples/hello world ``` 根据 CPU 架构选择工具链和前缀 ```bash python3 project.py toolchain /opt/toolchain sunxi musl/toolchain/bin toolchain prefix arm openwrt linux muslgnueabi config ``` ![](./assets/helloworld.png) 接着就可以编译 helloworld 了。在上面的命令成功执行后接着执行下面的命令 ```bash python3 project.py menuconfig ``` 若出现以下画面，则说明下载内容完整。若报错先尝试使用sudo执行，否则需重新下载解压 ![](./assets/helloworld menuconfig.png) 如第三项选择了Enable 3rd party component，则在编译时时间就会较长，因为会编译所有勾选的第三方组件。编译过程中可能会报一些warning，但最终出现下图画面则说明编译过程无误 <img src \"./assets/enable 3rd party component.png\"> <img src \"./assets/finish helloworld.png\"> 前面的都顺利结束后在当前目录下会有一个 dist 文件夹。里面的 helloworld 文件就是 v831 的可执行程序。 我们可以用 ssh 或者使用 v831在电脑上显示的U盘 把 helloworld 可执行文件传输到板子上 接着在对应的目录下直接执行就可以看到结果了 ![](./assets/run helloworld.png) #### lvgl编译与测试 在 libmaix 源码的路径下的 /examples/mpp_v83x_vivo 执行下面命令后按照图示配置 ```bash python3 project.py menuconfig ``` <html> <div class \"imbox\"> <img src \"./assets/lvgl 1.png\" > <img src \"./assets/lvgl 2.png\" > </div> </html> 检查选项是否如以上配置所示，确认无误后在命令行执行 ```bash python3 project.py build ``` 注：若同时勾选所有组件，则可能会发生重复定义函数的报错导致编译失败 若出现如图所示情况，则说明编译成功 <img src \"./assets/lvgl 3.png\"> 在板子上运行 <html> <div class \"imbox\"> <img src \"./assets/lvgl 4.png\" height 300> <img src \"./assets/lvgl 5.png\" height 300> <style> .imbox{ display:flex; flex direction: row; } </style> </div> </html>"},"/news/MaixPy3/v831_usage/v831_usage.html":{"title":"M2DOCK 上手视觉指南","content":" title: M2DOCK 上手视觉指南 tags: M2DOCK, V831, 避坑指南, 上手指南 keywords: V831, 视觉指南，避坑, 上手 update: date: 2023 05 15 version: v0.1 author: lyx content: 编写文档 date: 2023 06 01 version: v0.2 author: lyx content: 填充大纲 date: 2023 06 08 version: v0.3 author: lyx content: 补充内容细节 ## 产品介绍 > 铛 ~ 新的 2023 年当然要有新的上手指南辣（虽然已经过去5个月）总有事情要被鸽但能填上就是好坑。 > 新的上手指南还是旧的目的，希望大家可以借助这篇文章在使用 M2DOCK 时更加顺利一点吧！ ![m2dock](https://wiki.sipeed.com/hardware/assets/maixII/m2dock.jpg) 本篇文章以 `视觉` 为主题阐述如何在 M2DOCK（V831）从基础的开箱上手再到视觉的衍生（深度开发）的使用全过程，因篇幅的有限这里不再对产品进行详细介绍，想要了解相关产品介绍可点击资料进行查看。 **相关资料及硬件参数：[点击查看](https://wiki.sipeed.com/hardware/zh/maixII/M2/resources.html) 购买链接：[点击前往](https://item.taobao.com/item.htm?id 635874427363)** <iframe src \"//player.bilibili.com/player.html?aid 298543445&bvid BV1sF411u7xb&cid 586467021&page 1\" scrolling \"no\" border \"0\" frameborder \"no\" framespacing \"0\" allowfullscreen \"true\"> </iframe> ## 前情提要 **【有基础可跳过】**促使我们做上手指南的原因永远都是以降低用户使用难度为目的，但一些基础知识（Python 语法）我们还是需掌握熟悉的，而大部分的小伙伴是从 `K210（MaixPy)` 换代升级到 `M2DOCK（MaixPy3)` 的，但我们区分这两者之间的不同吗？显然刚接触的小伙伴们是不清楚的。 >**我们可以这么来理解**：本质上它们都是专门为 AloT 提供的 Python 开发环境，提供了各类各样的模块。MaixPy 基于 MicroPython 的环境制作和 MCU 无系统的，而后者 MaixPy3 则是基于 Linux Python3 的环境以及 Linux 系统，可点击：[[关于 MaixPy 与 MaixPy3 的区别]](https://wiki.sipeed.com/news/MaixPy3/difference.html) 查看更多。 根据下文的链接自行学习相关的 Python 基础语法及知识： [什么是 Python ?](https://wiki.sipeed.com/soft/maixpy3/zh/origin/python.html?highlight python) [国内 Python 基础教程](https://wiki.sipeed.com/soft/maixpy3/zh/origin/video.html) [【适合有一定基础】大佬鼠の嵌入式 Python 入门教程[1]](https://wiki.sipeed.com/soft/maixpy3/zh/origin/hello_world.html) [【适合有一定基础】大佬鼠の嵌入式 Python 入门教程[2]](https://wiki.sipeed.com/soft/maixpy3/zh/origin/loop_python.html) ## 准备工作（必看） 充足的准备能让后续的上手旅程更事半功倍（为了不掉坑里~）文档以 `M2DOCK` 的全功能套餐来演示，我们收到后会有一套 M2DOCK 板卡、Type C 线 以及 SD 镜像卡，但还需准备一个 USB 3.0 读卡器以作备用。 ![maixii](./assest/maixii.jpg) ### 上手流程图 上手指南搭配流程图一起食用更佳~ ![steps](./assest/steps.png) ### 烧录镜像系统 准备完相关的硬件工具后就是开启软件类的的相关准备操作，我们先进行烧录 M2DOCK 相关的适配系统。 > 文档示例环境：**Windows10** > 镜像版本：**v831 m2dock maixpy3 0.5.4 20230505** > 1. 在官方淘宝店购买过（预烧录好）镜像 SD 卡的小伙伴可跳过进入下一步。 > 2. 如果没有购入官方相关镜像卡，建议用户购买正规正版（防止出现烧录失败现象）的镜像卡。 > 3. 非必要的情况下不建议多次且随意进行镜像烧录。 **镜像文件命名说明** 对于 V831 的镜像文件名字是有对应的规则，以后大家可以根据自己的需求来进行下载。 就以 `v831 m2dock maixhub 0.5.1 20220701.zip`和 ` v831 m2dock maixpy3 0.5.1 20220701.zip` 来对比说明 名称 含义 maixpy3 0.5.1 此镜像是给 [MaixPy3](https://wiki.sipeed.com/maixpy3) 专用，并内置了`0.5.1`的版本，但其中 **无** 内置 maixhub app maixhub 0.5.1 此镜像是给 [MaixPy3](https://wiki.sipeed.com/maixpy3) 专用，并内置了`0.5.1`的版本，但其中 内置 maixhub app m2dock 可使用 MaixII Dock 开发板平台 20220701 镜像更新日期 > 上述镜像均为开源版，只适用于 TF 卡烧录启动 **获取相关的镜像包及工具** 1. V831 系统镜像下载站 [SDK_MaixII/release](https://dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/release) 2. V831 系统镜像百度云 [点我](https://pan.baidu.com/e/1vCExI3_48Q90JrxO70JdiQ) 3. 烧录工具 [PhoenixCard](https://dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/tools) 4. 内存卡格式化工具 [SD Card Formatter](https://www.sdcard.org/downloads/formatter/eula_windows/SDCardFormatterv5_WinEN.zip) **开始进行烧录工作** **第一步**：先使用读卡器将镜像卡接入 USB 端，使用格式化工具 `SD Card Formatter` 进行格式化操作。 **第二步**：格式化完成后，再使用 `PhoenixCard` 烧录工具进行烧录。 **烧录流程示例**：可前往 [Windows/Linux M2dock 系统烧录](https://wiki.sipeed.com/hardware/zh/maixII/M2/flash.html) 查看相关示例，下图显示绿色代表烧录成功。 ![img](./assest/img.png) 系统相当于燃机的原料，我们把系统烧录完成好后接着下一步安装需使用到的软件。 ### 安装 MaixPy3 IDE `MaixPy3 IDE` 是基于 `Jupyter` 实现的 `Python3` 集成开发环境，运行界面可视化的操作降低使用难度，支持电脑端（支持跨平台）编辑或运行 Python 代码并实时显示效果，故而对无相关基础的用户们较友好。 ![hello](./assest/hello.jpg) > `注意事项（超重要！）`：**下载时确保我们安装的软件包版本（大于 0.5.0）且在安装过程中会弹出安装驱动程序的提示，请根据提示安装驱动并确保安装完成才能进行下一步操作。** ![usb](/news/MaixPy3/v831_usage/assest/usb.jpg) 接下来根据 `注意事项` 来自行下载安装包并安装好驱动及软件，根据示例文档熟悉界面的基础用法。 **软件包下载链接：** MaixPy3 IDE 下载站：[点击](https://dl.sipeed.com/shareURL/MaixII/MaixPy3 IDE) MaixPy3 IDE 百度云：[点击](https://pan.baidu.com/s/1d5zbIDSOBUvIta_rRhLx_A) **示例文档：** 多平台安装 MaixPy3 IDE 方法：[Windows/Macos/Linux MaixPy3 IDE](https://wiki.sipeed.com/soft/maixpy3/zh/tools/MaixPy3_IDE.html) 软件使用文档：[MaixPy3 IDE 界面介绍](https://wiki.sipeed.com/soft/maixpy3/zh/tools/MaixPy3_IDE.html#MaixPy3 IDE %E7%95%8C%E9%9D%A2%E4%BB%8B%E7%BB%8D) > 一起搭配我们的【M2DOCK 开箱大放送】视频食用更佳噢~ <iframe src \"//player.bilibili.com/player.html?aid 384617683&bvid BV14Z4y147Lg&cid 734640023&page 1\" scrolling \"no\" border \"0\" frameborder \"no\" framespacing \"0\" allowfullscreen \"true\"> </iframe> ### 上电接线方式 准备好相关的软件以及基础工作我们开始学习如何正确接线并上电。 **第一步**：USB Type C 数据线【需自行准备的话】请准备质量可靠或者是手机附赠的数据线，质量差的数据线会因电压问题造成开发板处于非正常工作状态导致后续影响使用，有些 Type C 线只能供电。 ![type c](./k210_usage/../../../MaixPy/mixly_application/accets/k210_usage/type_c.jpg) **第二步**：把我们准备的镜像卡插入 M2DOCK 的卡槽内，并确定烧录的版本（大于 0.5.1）即可。 ![sd](./assest/sd.jpg) **第三步**：将 `M2DOCK` 与电脑通过 OTG 标识的 USB 口连接，确认设备通电亮起（power）电源**红灯**，请看下图红圈别接错 USB 口的位置，OTG 标识的丝印在板子背面。 ![otg](./assest/otg.jpg) **第四步**：确认屏幕出现 logo 或二维码（wiki）表示系统启动开始工作，同时电脑会弹出 U 盘标识（意味着板卡系统已准备就绪）即可进行下一环开始使用！ ![u_logo](./assest/u_logo.jpg) > **如果出现异常情况**：通电后无法弹出 U 盘标识（常见于 Windows 平台）根据第五步卸载相关驱动即可。 **衍生第五步**：打开设备管理器后，根据示例图找到相关的 `Android ADB Interface` 手机驱动（常见于 XX 手机助手）右键进行卸载设备。 ![adb](./assest/adb.jpg) 然后勾选卸载驱动（重要！！一定要勾选）进行卸载即可，U 盘自动弹出也代表底层硬件正常可用。 ![delete](./assest/delete.jpg) > 如果 U 盘还是没有如上述步骤出现，可以重烧系统或重启设备或考虑换台电脑操作，有可能是个别系统驱动不兼容导致的，实在是解决不了请找官方的淘宝客服。 ## 上手运行程序 > 这里后不再重复任何基础操作知识，默认大家会操作 [Jupyter](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E9%80%89%E6%8B%A9 RPyc Python %E6%A0%B8%E5%BF%83%E8%A1%A8%E7%A4%BA%E5%9C%A8%E6%9D%BF%E5%AD%90%E4%B8%8A%E8%BF%90%E8%A1%8C Python %E7%A8%8B%E5%BA%8F) 相关运行界面及方法。 开始体验运行代码前，我们先了解 M2DOCK 支持多种编程方式，分别是 Linux shell（adb）命令行、Jupyter notebook（Python）开发、U 盘编辑运行（Python）等。Linux shell 更多的是专业开发者或是熟悉 Linux 终端的同学进行使用，而如果是无基础的萌新更推荐其余两种方式。 >下文全以适配软件 MaixPy3 IDE 的使用来示例。 **先熟悉相关的运行环境** IDE 软件启动时会附带一个 `keep_adb.exe` 命令行终端的程序提供给熟悉 linux 终端操作开发板的同学，软件版本 0.4.2 后 keep_adb 服务会自动调用 adb 配置映射（forward）端口（22，18811，18812）与板子连接的 ide 服务是否工作。 **如何进行判断**：可以在交互终端输入 `ps grep mjpg` 查看是否存在下图红框所指示的服务。 ![keep_adb](./assest/keep_adb.jpg) > 如果发现不存在 ide 服务（`python c 'from maix import mjpg;mjpg.start();`）我们可以手动运行相关服务，并把现象汇报到社群，目前发现该现象主要出现在 Windows 11 系统之间的差异上。 最后确认系统防火墙是否阻止了软件底层所需要 `TCP 18811 18812` 的端口号（主用于运行程序和图像传输） **了解更多**：可以点此查看关于 [MaixPy3](https://wiki.sipeed.com/soft/maixpy3/zh/tools/MaixPy3_IDE.html) IDE 的更加详细的介绍，此处不再赘述。 > **启动 MaixPy3 IDE 时会弹出 Jupyter 的编辑网页，我们先来测试板卡的连接以及外设是否正常可用。** ### 测试板卡连接 复制下列代码块，再点击上方菜单栏中的运行，测试板子连接是否正常。 ```python3 import platform print(platform.platform()) import time print(time.asctime()) ``` ![test](./assest/test.jpg) **由运行后打印出的结果我们可知以下信息：** 1. 运行这段代码的时间是 [ rpyc kernel ]( running at Wed Jul 13 15:20:20 2022 ) 2. 运行这段代码的平台是 Linux 4.9.118 armv7l with libc 3. 运行这段代码时：板子系统时间是 Thu Jan 1 04:04:55 1970。 当代码运行的时间为当前时间，并打印出以上代码，说明开发板已经连接上并可以正常的使用。 > 关于更详细或报错的话请查看 [如何运行代码](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81) 进行排查或了解。 ### 测试屏幕及摄像头 > 当确定板卡的连接状态正常后，我们来测试屏幕以及摄像头的功能是否正常。 运行以下程序后可在代码下方看见摄像头实时获取的图像。 ```python3 from maix import camera, display, image #引入python模块包 while True: img camera.capture() #从摄像头中获取一张图像 display.show(img) #将图像显示出来 ``` ![sensor](./assest/sensor.png) 图中我们看见运行程序后可实时看到摄像头捕捉的画面，正面我们的屏幕以及摄像头都是正常可用的。 >更多的图像处理基础用法：[查看](https://wiki.sipeed.com/soft/maixpy3/zh/usage/vision/maixpy3 example.html#%E4%BB%8E%E6%91%84%E5%83%8F%E5%A4%B4%E8%8E%B7%E5%8F%96%E5%9B%BE%E5%83%8F%E5%B9%B6%E6%98%BE%E7%A4%BA) ### 测试拍照功能 ```python from maix import camera, display, image display.show(camera.capture()) ``` ![hello_world](https://wiki.sipeed.com/hardware/zh/maixII/M2/asserts/hello_world.jpg) > **如果屏幕没有显示内容**：那么首先确认一下镜像镜像版本，并且确认一下外设和驱动对的上。 ## 基础使用 上文我们使用了 Maixpy3 IDE 搭载的 **Jupyter（Python）**运行代码并测试了屏幕及摄像头的功能，接下来我们来体验 Linux shell 命令行的使用并给 M2DOCK 进行联网。 >命令行也就是所谓的 Linux Shell 还是用户使用 Linux 的桥梁，Shell 是指一种应用程序，这个应用程序提供了操作界面，用户通过这个界面访问操作系统内核的服务，使用 shell 需要使用者具备一定的 Linux 基础知识 [Shell 教程](https://www.runoob.com/linux/linux shell.html)/[部分常用 Linux 命令](https://wiki.sipeed.com/hardware/zh/maixII/M2/usage.html#%E9%83%A8%E5%88%86%E5%B8%B8%E7%94%A8 Linux %E5%91%BD%E4%BB%A4)可根据需求进行学习。 ### 联网 M2Dock 带有 2.4G 无线模组，可以用来连接 2.4G 频段的无线网络，因镜像的更新（WiFi）链接方式有两种可供大家选择，但是文档示例以最新镜像方法为示例标准，更多可查询下文给出的参考链接。 **使用以下命令行进行联网 确保镜像系统：0.5.4（20230207）** 使用下面的命令来连接名称：`Sipeed_Guest` 密码：`qwert123` 的无线网络。 ``` wifi_connect_ap_test Sipeed_Guest qwert123 ``` ![wlan](./assest/wlan.jpg) 连接成功后可使用 `ifconfig` 命令查询 `wlan0` 的 IP 地址，更多命令行联网的详情请看[ V0.5.4 联网.](https://wiki.sipeed.com/hardware/zh/maixII/M2/usage.html#V0.5.4) **修改 wpa_supplicant.conf 进行联网：（V0.5.4）前镜像** 这个办法适用于 V0.5.4 前的镜像系统，通过修改 U 盘里的 `wpa_supplicant.conf` 文件修改名称及密码来联网，更加具体的操作请看[ V0.5.4 前镜像联网](https://wiki.sipeed.com/hardware/zh/maixII/M2/usage.html#V0.5.4 %E4%B9%8B%E5%89%8D%E7%9A%84%E9%95%9C%E5%83%8F) 相关资料。 ### 配置开机脚本 >上文我们尝试了怎么使用 Linux shell 来进行联网操作，这里我们来尝试使用 U 盘配置开机脚本。 **对于 M2DOCK 如何使用 U 盘设置开机脚本呢？其实很简单只需要一下几个步骤：** **第一步**：把（待存）脚本存成名为 `main.py` 的文件，然后根据第二步判断存放位置。 **第二步**：判断 U 盘目录下是否有 app 的文件夹，如果有就把 `main.py` 存进 `app` 文件夹后进行下一步，如果没有直接把 `main.py` 存放在 U 盘即可进行下一步。 **第三步**：存放好后使用电脑操作系统自带的移除 U 盘方式来保证文件在没有损坏的情况下保存进板卡，否则会因为不当操作而导致 `main.py` 没有正常保存到 U 盘（板卡系统）里面。 >**注意事项：MaixPy3 IDE 运行时会停止 M2Dock 的开机脚本程序，所以我们应该在电脑托盘找到并退出 MaixPy3 IDE 或者选择仅使用板子上的 TypeC 串口来进行供电以查看开机运行脚本效果。** 以下为 root 目录下 main.py 文件里的出厂默认开机脚本： ```python #!/usr/bin/env python from maix import camera, display, image, nn image.load_freetype(\"/home/res/sans.ttf\") qrcode image.open('/home/res/qrcode.png') canvas image.new((display.width(), display.height()), (0xFF, 0xFF, 0xFF), \"RGB\") canvas.draw_image(qrcode, (canvas.width qrcode.width) // 2, (canvas.height qrcode.height) // 2) info \"wiki.sipeed.com/maixpy3\" w, h image.get_string_size(info, 1.2) canvas.draw_string((canvas.width w) // 2 + 5, canvas.height h 5, info, 1.2, color (0x00, 0x00, 0x00)) for i in range(120): img camera.capture().draw_image(canvas, alpha 0.7) display.show(img) ``` ![logo](./assest/logo.jpg) > 上手里不再关于开机脚本有关于更多的 [配置开机脚本](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E9%85%8D%E7%BD%AE%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC) 的详情资料可前往查看。 > 如何退出 MaixPy3 IDE：[操作流程](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E5%A6%82%E4%BD%95%E9%80%80%E5%87%BA MaixPy3 IDE) 可前往查看。 ### 传输文件 在使用 U 盘进行传输文件之前我们需要先了解电脑端 U 盘的目录与 M2DOCK 文件系统目录的对应规则。 >规则：电脑上的 U 盘对应着 M2DOCK 文件系统的 /root 目录。 传输文件操作如下：（前提 M2DOCK 通过 OTG 口连接电脑端） **第一步**：将文件拖拽进 U 盘后相当于完成存储到 M2DOCK 系统上的操作。 **第二步**：存储后务必使用电脑系统自带的 U 盘移除相关的功能来断开电脑与 U 盘的通信。 **第三步**：最后进行重启（按下 RST 键或者重新插拔 USB）来使 m2dock 再次重新加载文件系统，否则会因为板卡与电脑非正常断开通信而导致文件系统损坏，保存失败。 ### 图像处理 通过上文我们清楚了如何使用 Python 运行程序、如何使用 Linux shell 进行联网以及使用 U 盘设置开机脚本，熟悉的朋友们都知道 MAIX 系列主打的就是视觉 + AI 芯片，那图像处理是我们必不可少的体验过程。 >图像处理还分传统以及 AI 视觉，而在 M2dock 上我们主要学习传统的背景知识以及用法。 **传统视觉背景知识**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/usage/vision/back information.html) 我们需要了解图像传感器 摄像头、以及颜色空间和坐标系统的相关知识，方便后续在体验用法时更好理解。 **MaixPy 基础使用示例**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/usage/vision/maixpy3 example.html) 这里涵盖了一些基础使用（画线圈框）还有传统视觉应用（寻迹寻色寻线阈值处理）的示例。 **传统图像处理模块**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/usage/vision/image_example.html) 这里涵盖了传统视觉、颜色统计追踪、标记追踪、图像滤波、特征检测等模块使用的示例。 ### 硬件外设 这个章节更多的讲述的是认识一些经典外设并学会使用调用它的示例。 1. [【GPIO】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/GPIO.html)在？点个灯用个按键。 2. [【I2C】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/I2C.html)如何连接以及使用 I2C。 3. [【PWM 脉冲宽度调制】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/PWM.html)关于 PWM 的基础使用以及深入了解示例。 4. [【UART】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/UART.html)认识定义并学会使用 UART 进行传递字符串。 5. [【SPI】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/SPI.html)熟悉 SPI 的基础使用以及如何驱动 WS2812B 灯珠。 6. [【EVENT】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/event.html)如何通过输入事件设备来检测外接设备的变化。 7. [【ADC】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/ADC.html)了解相关的 ADC 通讯协议并实现旋钮控制、触控测试等。 8. [【WATCHDOG 看门狗】](https://wiki.sipeed.com/soft/maixpy3/zh/usage/hardware/watchdog.html)了解看门狗的相关原理并实现它。 ### 网络应用 **Python3 网络应用**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/usage/net.html) 这一章是相关的 Python 网络应用的一些示例以及库的使用方法，讲述了上云需了解的 HTTP/MQTT 相关的定义基础知识（网络应用不代表联网，联网请看同级目录第一个）以及如何进行 MJPG 图传。 ### 媒体功能 这一章节讲述的是在 M2DOCK 上如何实现播放视频以及录音播放的使用示例。 **播放视频**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/usage/Audio/play_mp4.html) **录音与播放**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/usage/Audio/audio.html) ## 进阶使用 > 到达进阶使用这里后，这里则需要小伙伴们具备一些 Linux 基础了才能继续往下走学习。 ### 认识 openwrt 系统 全志 V831 使用 Tina Linux 系统移植自 OpenWrt。 OpenWrt 可以被描述为一个嵌入式的 Linux 发行版，详情可看 [官方网址](https://openwrt.org) 和 [官方开源仓库](https://github.com/openwrt/openwrt)。 **更多相关的详情点击**：[详情资料](https://wiki.sipeed.com/hardware/zh/maixII/M2/usage.html#%E8%AE%A4%E8%AF%86 openwrt %E7%B3%BB%E7%BB%9F) ### Opkg 包管理器 Opkg 是一个轻量快速的套件管理系统，目前已成为 Opensource 界嵌入式系统标准。常用于 路由、交换机等 嵌入式设备中，用来管理软件包的安装升级与下载。 **相关的常用命令**：[点击查看](https://wiki.sipeed.com/hardware/zh/maixII/M2/usage.html#Opkg %E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8) [pip](https://pypi.org/project/pip/) 是 Python 包管理工具，该工具提供了对 Python 包的查找、下载、安装、卸载的功能。 **如何使用示例**：[点击查看](https://wiki.sipeed.com/hardware/zh/maixII/M2/usage.html#pip %E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8) ### 更新 MaixPy3 包 有时镜像包更新但我们确不想再次进行烧录板子以作更新，这时可以手工更新 MaixPy3 达到更新目的。 **MaixPy3 最新安装包**：[点击前往下载](https://pypi.org/project/maixpy3/#history) **Maixpy3 更新操作**：[操作示例](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E6%9B%B4%E6%96%B0 MaixPy3 %E5%8C%85) ![maixpy3_cp38](./assest/maixpy3_cp38.jpg) ### 使用 USB 摄像头（主机模式） >M2DOCK 是双 Type c 接口的（分别是 UART/OTG）而 OTG 接口是默认作为 USB 从机来使用的。 如果想使用 USB 摄像头则需手动更改端口为主机模式，从板子上的串口 USB（UART）来操作板子，并执行以下命令修改 OTG 口为主机模式使用。 ```shell echo \"usb_host\" > /sys/devices/platform/soc/usbc0/otg_role ``` ### 将 USB OTG 口作为从机 M2Dock 默认的 OTG 口就是 USB 从机设备，如有其他原因需重新设置成从机设备的话，只需在 M2DOCK 上执行以下命令即可。 ```shell echo \"usb_device\" > /sys/devices/platform/soc/usbc0/otg_role ``` ### 更换屏幕 目前开发板支持的屏幕有 1.3寸、2.4寸、2.8寸 的 IPS 屏，且只是支持在我们淘宝上售卖的显示屏；对于别的屏幕有需求的，可以走商务通道进行定制。 **如何进行屏幕的切换及更新设备树**：[点击查看](https://wiki.sipeed.com/hardware/zh/maixII/M2/other.html#%E5%88%87%E6%8D%A2%E5%B1%8F%E5%B9%95) ### 更换摄像头 目前 MaixII Dock 开发板目前支持的摄像头有 sp2305、vs3205、ov2685（只支持在官方店上再售卖的摄像头，有别的摄像头需求可以进行商务定制），摄像头之间的切换同样时需要更换设备树文件，更换方式上面的更换屏幕一样的。 **如何进行摄像头以及设备树的切换**：[点击查看](https://wiki.sipeed.com/hardware/zh/maixII/M2/other.html#%E6%9B%B4%E6%8D%A2%E6%91%84%E5%83%8F%E5%A4%B4) ### 编译链 有需求的可以自行尝试，但是对于 V831 还是推荐使用 MaixPy3 和 MaixHub。 **Linux 系统下 V831 使用编译链**：[toolchain sunxi musl pack 2021 01 09.tar.xz](https://dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/Toolchain) ## 使用文档（资源） 无论是在 K210 还是 M2DOCK（V831）上一定要学会使用我们公开的文档资料，去借助资料的力量帮助自己在学习的道路上往前走，学会借助资源完善自身的不足，可以让你少走很多的坑以及弯路。 1. 学会搜索并利用官方的 `文档社区` 以及 `github issue` 资源，会让新手小白少走很多弯路雷坑。 2. 文档资源在 `常见问题 FAQ` 中基本涵盖了所有的坑，使用途中报错可以先查看排错。 3. 想要实现更多的功能示例或需要更多的脚本源码，可前往 MaixPy3 的源码例程仓库查找。 **文档搜索例程**：[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/how_to_read.html) **BBS 社区教程贴**：[点击前往](https://bbs.sipeed.com/thread/492) **MaixPy3 源码仓库**：[点击前往](https://github.com/sipeed/maixpy3) **MaixPy3 issue**：[点击前往](https://github.com/sipeed/MaixPy3/issues) **MaixPy3 常见问题指南**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8C%87%E5%8D%97) **V831 源码**：[点击前往](https://github.com/Tina Linux/tina V83x) **V83 工具链**：[点击前往](https://dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/Toolchain) **V831 常见问题与解决方法**：[点击前往](https://wiki.sipeed.com/soft/maixpy3/zh/question/maixpy3_faq.html) **BBS 社区常见问题汇总贴**：[点击查看](https://bbs.sipeed.com/thread/489) **相关社群汇总贴**：[点击查看](https://wiki.sipeed.com/community.html) ### 更多资源（教程文章） 这里的文章大多数是来自社区以及博文精选，可供参考。 1. **MaixPy3 Image.lens_corr 畸变矫正的用法**：[点击前往](https://wiki.sipeed.com/news/MaixPy3/camera_lens_corr/v831_lens_corr.html) 2. **给 M2Dock 安装 Opencv**：[点击前往](https://wiki.sipeed.com/news/others/v831_opencv/v831_opencv.html) 3. **使用 SSH 来连接 M2Dock**：[点击前往](https://wiki.sipeed.com/news/others/831_ssh/831_ssh.html) 4. **在线图传调试 LAB 阈值**：[点击前往](https://wiki.sipeed.com/news/others/threshold/threshold.html) 5. **MaixPy3 Image.resize 的效果**：[点击前往](https://wiki.sipeed.com/news/MaixPy3/camera_resize/camera_resize.html) 6. **MaixII 通过 USB OTG 口连接U盘**：[点击前往](https://wiki.sipeed.com/news/others/maixII_connect_udisk.html) 7. **在V831上（awnn）跑 pytorch resnet18 模型**：[点击前往](https://wiki.sipeed.com/news/others/v831_resnet18/v831_resnet18.html) 8. **V831 如何使用 libmaix SDK C++ 开发**：[点击前往](https://wiki.sipeed.com/news/MaixPy3/run_lvgl/run_lvgl.html) 9. **V831完美的单目测距**：[点击前往](https://wiki.sipeed.com/news/MaixPy3/v831_Distance/v831_Distance.html) 10. **V831的人脸识别**：[点击前往](https://wiki.sipeed.com/news/MaixPy3/key_face_recognize.html) ## 体验 AI 应用 上文我们说过了 MAIX 系列主打的就是 视觉 + AI 的特性，所以 AI 算法应用也是上手体验里不可少的一环。 [边缘检测](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/Edge_detection.html) [物品分类](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/resnet.html) [物体检测](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/yolo.html) [数字识别](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/number_recognize.html) [人脸识别](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/face_recognize.html) [自学习分类](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/self_learn.html) [车牌识别](https://wiki.sipeed.com/soft/maixpy3/zh/usage/AI_net/car_registration_plate_recognition.html) ## 训练 AI 模型 >训练自己的 AI 模型有两种方法：分别是在线训练以及本地训练。 **在线训练**：则是指适配了 MaixPy3 的 MaixHub 在线训练平台，还有支持的相关设备端镜像，更多详细资料请前往 [相关使用](https://maixhub.com/app/1)查看。 **本地训练**：则是不依靠任何在线训练平台，自行了解相关知识并进行环境搭建、制作数据集、训练相关模型。 相关资料教程文档： 1. [深度神经网络（DNN）基础知识](https://wiki.sipeed.com/soft/maixpy3/zh/usage/train_AI/information.html) 2. [本地训练环境搭建](https://wiki.sipeed.com/soft/maixpy3/zh/usage/train_AI/ready.html) 3. [v831 部署 Sobel 卷积边缘检测](https://wiki.sipeed.com/soft/maixpy3/zh/usage/train_AI/v831_sobel.html) 4. [如何制作数据集](https://wiki.sipeed.com/soft/maixpy3/zh/usage/train_AI/data.html) 5. [图像分类模型训练过程](https://wiki.sipeed.com/soft/maixpy3/zh/usage/train_AI/train_resnet.html) 6. [目标检测本地训练教程](https://wiki.sipeed.com/soft/maixpy3/zh/usage/train_AI/train_yolov2.html) ## 核心 API 手册 这个章节可以搭配下文的编译与开发一起食用更佳噢~ [MaixPy3 image 模块](https://wiki.sipeed.com/soft/maixpy3/zh/api/maix/image.html) [MaixPy3 display 模块](https://wiki.sipeed.com/soft/maixpy3/zh/api/maix/display.html) [MaixPy3 camera 模块](https://wiki.sipeed.com/soft/maixpy3/zh/api/maix/camera.html) [MaixPy3 nn模块（maix.nn）](https://wiki.sipeed.com/soft/maixpy3/zh/api/maix/nn.html) ## 编译与开发 > 当你走到这时已经代表你熟悉（V831）的基础操作准备深层了解，以下的文档是为了开发者写的参考文，希望可以基于此让更多的伙伴进入 Linux 嵌入式开发的领域。 **相关资料系列合集：** 1. [MaixPy3 架构介绍](https://wiki.sipeed.com/soft/maixpy3/zh/others/framework.html) 2. [MaixPy3 开发文档](https://wiki.sipeed.com/soft/maixpy3/zh/others/develop.html) 3. [如何适配你的平台](https://wiki.sipeed.com/soft/maixpy3/zh/others/platform.html) 4. [MaixPy3 视觉模块开发](https://wiki.sipeed.com/soft/maixpy3/zh/develop/opmv_cv.html) ### 系统环境搭建 Ubuntu 镜像下载: [中科大源](https://mirrors.ustc.edu.cn/ubuntu releases/) 安装 vscode 和换源：这里借助一下 [小鱼脚本](https://fishros.org.cn/forum/topic/20/%E5%B0%8F%E9%B1%BC%E7%9A%84%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E7%B3%BB%E5%88%97) 工具链: [toolchain sunxi musl pack 2021 01 09.tar.xz](https://dl.sipeed.com/shareURL/MaixII/MaixII Dock/SDK/Toolchain) ### MaixPy3 架构介绍 因篇幅过多这里不详细介绍，小伙伴们可根据指路前往：[MaixPy3 架构介绍](https://wiki.sipeed.com/soft/maixpy3/zh/others/framework.html) ### 为什么采用 libmaix 开发 ```C++ + + User develop sipeed all product. + + + + + + Run Python Code Run C/C++ Code + ^ + + ^ + + + + maixpy3 + ^ + + + + libmaix + + + ^ + + + + + openwrt debian Linux armbian ubuntu + + + + + + ^ ^ ^ ^ + ++ + ++ + ++ + + + x86/64 AX620A V83X R329 debian V85X ubuntu more... + + + + + + + + ``` 上文中我们可以清楚的看到平时用的 `Python` 的接口底层实现也是通过了 `libmaix` 的开发成果，平时需要 `Python` 语言调参验证原型功能，是为了快速验证我们的开发板可用于不同的场景和功能，方便我们快速验证功能外设是否正常，同时我们也需要 `C / C++` 优化性能和减少内存占用用于开发商业项目，那么，直接使用 libmaix 进行开发就显得尤为重要了。 一开始采用的 `Python` 需要一定时间过渡到 `C++` ，特别是成熟的项目更需要脱离 `Python`，为了更成熟精简的项目结构和更好的性能就得看看 `libmaix` 的表现了。 #### 首先要配置好开发环境 > 参考下文给出的资料文章链接配置相关开发环境。 1. V831 如何使用 libmaix SDK C++ 开发: [点我跳转](https://wiki.sipeed.com/news/MaixPy3/run_lvgl/run_lvgl.html) 2. Linux 连接不上 adb 设备: [点我跳转](https://wiki.sipeed.com/news/others/linux_adb/linux_adb.html) 完成上面的环境配置后，这里提供了可运行的 `Demo` 内容就是如何使用 V831 LINUX C++ 进行图像视觉处理和开发，在此我们提供了 `串口 + mv cv ai` 的示例项目，供开发者评估使用，此处不涉及到 ISP 调试，需要进一步 ISP 图像调试则需要联系 SIPEED。 > 相关资料：[libmaix](https://github.com/sipeed/libmaix/blob/6ad1102a0527bd3d394c0b1de82cbf64d6eac40d/components/maix_dls831/src/dls831_uvai.cpp#L435 L663) **操作步骤**：连接上板子的 OTG 接口后，在 `/libmaix/libmaix/examples/app_dls831` 目录下使用 `make` 下进行编译（编写好的脚本会自动把编译好的文件上传并运行）。 ![libmaix](./assest/libmaix.jpg) 我们可以看到程序是保持稳定三十帧的运行速率。 <html> <img src \"./assest/h26x_831.jpg\" width 45%> <img src \"./assest/fps.jpg\" width 45%> </html> > 接下来我们来认识一下现有的库：分别是 AI、Opencv、Openmv、LVGL。 ### AI 它的实现方式与 `Python` 的流程类似，并在 `C++` 中也需配置相关模型的参数。 **以 YOLOv2 为例** >YOLOv2 是一种基于深度学习的目标检测算法，它是 YOLO（you only look once）的改进版本。 **YOLOv2 相比于 YOLO 主要有以下几个不同的改进点：** 1. 使用 `batch normalization` 来提高模型的稳定性和泛化能力，同时去掉了 `dropout` 层。 2. 使用了高分辨率的图像（448×448）来微调分类网络，然后再用于检测网络并提高了检测的精度。 3. 引入 `anchor boxes` 的概念，根据数据集的边界框分布进行 `k means` 聚类，得到最合适的 `anchor boxes` 的尺寸和比例提高了召回率。 4. 使用了直接位置预测的方法，将边界框的中心坐标相对于网格单元的偏移量用 `logistic` 回归函数进行归一化，使得模型更容易学习。 5. 使用了多尺度训练的策略动态地改变输入图像的尺寸，使得模型能够适应不同大小的目标。 **YOLOv2 的优点主要有以下几个方面：** 1. 速度快：YOLOv2 相比于基于区域提议的方法，只需对图像进行一次前向传播大大减少计算量和时间。 2. 精度高：YOLOv2 相比于 YOLO 来说在 `mAP`（平均精度）上提升了约 10 个百分点，在小目标上也有明显的改善。 3. 通用性强：YOLOv2 可以同时在 `COCO` 和 `ImageNet` 数据集上进行训练，得到一个能够检测 9000 多种物体的模型。 ![YOLOv2](./assest/YOLOv2.jpg) **接下来我们来尝试采用人脸模型为测试：** 在出厂镜像中我们已内置了相关的人脸检测的模型，无需用户再次下载。 ```cpp static struct _nn_yolo_face_ { \t//模型地址，需要提前通过adb传到板子里，下列模型出厂固件已经自带 const char *model_path_param \"/home/model/face/yolo2_face_awnn.param\"; const char *model_path_bin \"/home/model/face/yolo2_face_awnn.bin\"; const char *inputs_names[1] {\"input0\"}; const char *outputs_names[1] {\"output0\"}; const float opt_param_mean 127.5; const float opt_param_norm 0.0078125; //网络的输入参数 libmaix_nn_layer_t input { .w 224, .h 224, .c 3, .dtype LIBMAIX_NN_DTYPE_UINT8, }; libmaix_nn_layer_t out_fmap { .w 7, .h 7, .c 30,//根据上图的网络结构计算公式(sizeof(labels)+5) * 5 .dtype LIBMAIX_NN_DTYPE_FLOAT, }; libmaix_nn_t *nn; libmaix_nn_model_path_t model_path; libmaix_nn_opt_param_t opt_param; // yolo2 decode const char *labels[1] {\"face\"};//你有多少个类别，就填多少 const float anchors[10] {1.19, 1.98, 2.79, 4.59, 4.53, 8.92, 8.06, 5.29, 10.32, 10.65}; libmaix_nn_decoder_t *yolo2_decoder; libmaix_nn_decoder_yolo2_result_t yolo2_result; libmaix_nn_decoder_yolo2_config_t yolo2_config { .classes_num sizeof(labels) / sizeof(anchors[0]), .threshold 0.5, .nms_value 0.3, .anchors_num (sizeof(anchors) / sizeof(anchors[0])) / 2, .anchors (float *)anchors, .net_in_width 224, .net_in_height 224, .net_out_width 7, .net_out_height 7, .input_width 224, .input_height 224 }; } nn_yolo_face_app; auto self (_nn_yolo_face_ *)app >userdata; self >opt_param.awnn.input_names (char **)self >inputs_names; self >opt_param.awnn.output_names (char **)self >outputs_names; self >opt_param.awnn.input_num sizeof(self >inputs_names) / sizeof(self >inputs_names[0]); self >opt_param.awnn.output_num sizeof(self >outputs_names) / sizeof(self >outputs_names[0]); self >opt_param.awnn.mean[0] self >opt_param_mean; self >opt_param.awnn.mean[1] self >opt_param.awnn.mean[0]; self >opt_param.awnn.mean[2] self >opt_param.awnn.mean[0]; self >opt_param.awnn.norm[0] self >opt_param_norm; self >opt_param.awnn.norm[1] self >opt_param.awnn.norm[0]; self >opt_param.awnn.norm[2] self >opt_param.awnn.norm[0]; self >model_path.awnn.param_path (char *)self >model_path_param; self >model_path.awnn.bin_path (char *)self >model_path_bin; self >input.need_quantization true; self >out_fmap.data (float *)malloc(self >out_fmap.w * self >out_fmap.h * self >out_fmap.c * sizeof(float)); if (!self >out_fmap.data) { LIBMAIX_INFO_PRINTF(\"no memory!!!\\n\"); return 1; } self >input.buff_quantization (uint8_t *)malloc(self >input.w * self >input.h * self >input.c); if (!self >input.buff_quantization) { LIBMAIX_INFO_PRINTF(\"no memory!!!\\n\"); return 1; } LIBMAIX_INFO_PRINTF(\" nn create\\n\"); self >nn libmaix_nn_create(); if (!self >nn) { LIBMAIX_INFO_PRINTF(\"libmaix_nn object create fail\\n\"); return 1; } LIBMAIX_INFO_PRINTF(\" nn object init\\n\"); err self >nn >init(self >nn); if (err ! LIBMAIX_ERR_NONE) { LIBMAIX_INFO_PRINTF(\"libmaix_nn init fail: %s\\n\", libmaix_get_err_msg(err)); return 1; } LIBMAIX_INFO_PRINTF(\" nn object load model\\n\"); err self >nn >load(self >nn, &self >model_path, &self >opt_param); if (err ! LIBMAIX_ERR_NONE) { LIBMAIX_INFO_PRINTF(\"libmaix_nn load fail: %s\\n\", libmaix_get_err_msg(err)); return 1; } LIBMAIX_INFO_PRINTF(\" yolo2 decoder create\\n\"); self >yolo2_decoder libmaix_nn_decoder_yolo2_create(libmaix_nn_decoder_yolo2_init, libmaix_nn_decoder_yolo2_deinit, libmaix_nn_decoder_yolo2_decode); if (!self >yolo2_decoder) { LIBMAIX_INFO_PRINTF(\"no mem\\n\"); return 1; } LIBMAIX_INFO_PRINTF(\" yolo2 decoder init\\n\"); err self >yolo2_decoder >init(self >yolo2_decoder, (void *)&self >yolo2_config); if (err ! LIBMAIX_ERR_NONE) { LIBMAIX_INFO_PRINTF(\"decoder init error:%d\\n\", err); return 1; } err self >nn >forward(self >nn, &self >input, &self >out_fmap); if (err ! LIBMAIX_ERR_NONE) { printf(\"libmaix_nn forward fail: %s\\n\", libmaix_get_err_msg(err)); } err self >yolo2_decoder >decode(self >yolo2_decoder, &self >out_fmap, (void *)&self >yolo2_result); if (err ! LIBMAIX_ERR_NONE) { printf(\"yolo2 decode fail: %s\\n\", libmaix_get_err_msg(err)); } if (self >yolo2_result.boxes_num > 0) { LIBMAIX_INFO_PRINTF(\"yolo2_result.boxes_num %d\", self >yolo2_result.boxes_num); } ``` ### OpenCV > 相关的函数可以去官方文档查看：[OpenCV Tutorials](https://docs.opencv.org/4.x/d9/df8/tutorial_root.html) 为了照顾 C 程序在 `/libmaix/components/maix_cv_image/src/libmaix_cv_image.cpp` 下对 Opencv 的函数又做了一层封装，当时还没有全面用 C++ 但现在已经全部迁移到 C++ 了。 可以在提供的 `libmaix/components/maix_dls831/src/dls831_uvai.cpp` 的例子中，看到是如何采用了 Opencv 实现滤波和二值化等操作。 ```C++ void AdaptiveThreshold(cv::Mat &src, cv::Mat &dst, double Maxval, int Subsize, double c, adaptiveMethod method meanFilter) { if (src.channels() > 1) cv::cvtColor(src, src, cv::COLOR_RGB2GRAY); cv::Mat smooth; switch (method) { case meanFilter: cv::blur(src, smooth, cv::Size(Subsize, Subsize)); // 均值滤波 break; case gaaussianFilter: cv::GaussianBlur(src, smooth, cv::Size(Subsize, Subsize), 0, 0); // 高斯滤波 break; case medianFilter: cv::medianBlur(src, smooth, Subsize); // 中值滤波 break; default: break; } smooth smooth c; src.copyTo(dst); for (int r 0; r < src.rows; ++r) { const uchar *srcptr src.ptr<uchar>(r); const uchar *smoothptr smooth.ptr<uchar>(r); uchar *dstptr dst.ptr<uchar>(r); for (int c 0; c < src.cols; ++c) { if (srcptr[c] > smoothptr[c]) { dstptr[c] Maxval; } else dstptr[c] 0; } } } // 自适应阈值 提取边缘 AdaptiveThreshold(gray, gray, 255, 21, 10, meanFilter);` ``` ** 前文的例子中不仅有 Opencv 的常用算法，也提供了 Opencv 的画图方法。 ** ```cpp // 绘制十字线 for (size_t i 0; i < reticle_results.size(); i++) { reticle_result reticle_result reticle_results[i]; cv::line(bgra, Point(reticle_result.lines[0][0], reticle_result.lines[0][1]), Point(reticle_result.lines[0][2], reticle_result.lines[0][3]), Scalar(255, 0, 0, 255), 2, LINE_AA); cv::line(bgra, Point(reticle_result.lines[1][0], reticle_result.lines[1][1]), Point(reticle_result.lines[1][2], reticle_result.lines[1][3]), Scalar(255, 0, 0, 255), 2, LINE_AA); cv::circle(bgra, reticle_result.crossPoint, 5, Scalar(0, 0, 255, 255), 1, LINE_AA); } ``` ### Openmv 当然为了更好的兼容 Openmv 玩家，我们也提供了 Openmv 的函数在 `components/third_party/imlib` 下，函数全部增加了一个 `imlib` 的前缀，其他的功能与Openmv 是一致的。 举个例子：比如 Openmv 的寻找色块函数 [寻找色块 · OpenMV中文入门教程](https://book.openmv.cc/image/blob.html) ```C++ image.find_blobs(thresholds, roi Auto, x_stride 2, y_stride 1, invert False, area_threshold 10, pixels_threshold 10, merge False, margin 0, threshold_cb None, merge_cb None) ``` 根据上面的链接描述，我们再看看 `imlib` 中的使用几乎一模一样。 ```C++ void imlib_find_blobs(list_t *out, image_t *ptr, rectangle_t *roi, unsigned int x_stride, unsigned int y_stride, list_t *thresholds, bool invert, unsigned int area_threshold, unsigned int pixels_threshold, bool merge, int margin, bool (*threshold_cb)(void*,find_blobs_list_lnk_data_t*), void *threshold_cb_arg, bool (*merge_cb)(void*,find_blobs_list_lnk_data_t*,find_blobs_list_lnk_data_t*), void *merge_cb_arg, unsigned int x_hist_bins_max, unsigned int y_hist_bins_max) imlib_find_blobs(&out, img, &roi, x_stride, y_stride, &thresholds, invert, area_threshold, pixels_threshold, merge, margin, NULL, NULL, NULL, NULL, x_hist_bins_max, y_hist_bins_max); ``` 再看看最经典的巡线功能中最重要的识别直线函数：[find_lines 识别直线 · OpenMV中文入门教程](https://book.openmv.cc/example/09 Feature Detection/find lines.html) ```C++ imlib_find_lines(&out, img, &roi, x_stride, y_stride, threshold, theta_margin, rho_margin); ``` 在上面提供的例子中就采用了寻找直线的功能。 ### LVGL LVGL（**注意提供的版本为LVGL7**）的相关函数资料：[百问网 LVGL 中文教程手册文档](http://lvgl.100ask.net/7.11/) >接下来我们来认识一下外设以及相关的使用方法，例如串口、SPI、PWM、IIC 等。 ### 串口 串口的使用非常的简单，我们先设置好波特率，数据位，停止位等参数，打开串口后挂载到 `select` 中，当串口收到数据后会打印一个字节出来。 ```C++ int ret 0; uart_t uart_dev_parm { .baud 115200, .data_bits 8, .stop_bits 1, .parity 'n'}; dls831 >dev_ttyS1 linux_uart_init((char *)\"/dev/ttyS1\", &uart_dev_parm); if (dls831 >dev_ttyS1 < 0) { perror(\" uart /dev/ttyS1 open err!\"); abort(); } FD_ZERO(&dls831 >readfd); write(dls831 >dev_ttyS1, \"dls831!\\r\\n\", sizeof(\"dls831!\\r\\n\"));I2C ``` ```C++ // serial FD_SET(dls831 >dev_ttyS1, &dls831 >readfd); ret select(dls831 >dev_ttyS1 + 1, &dls831 >readfd, NULL, NULL, &dls831 >timeout); if (ret ! 1 && FD_ISSET(dls831 >dev_ttyS1, &dls831 >readfd)) { char tmp[2] {0}; int readByte read(dls831 >dev_ttyS1, &tmp, 1); if (readByte ! 1) { printf(\"readByte %d %X\\n\", readByte, tmp); } } ``` ### SPI 以 WS2812 为例，首先搞清楚设备的 SPI 的四种时序模式：[一文搞懂 spi 协议 4 种模式时序](https://zhuanlan.zhihu.com/p/386787861) ```C++ #define WS2812_SPI_DEVICE \"/dev/spidev1.0\" unsigned char spi_init() { //初始化 int i; _ws2812_fd open (WS2812_SPI_DEVICE, O_RDWR); printf(\"\\r\\n*****ws2812 open success******\\r\\n\"); /* open spi device */ if ((_ws2812_fd) < 0) /* check result */ { printf(\"spi: open failed.\\n\"); /* open failed */ return 1; /* return error */ } else { i SPI_MODE_3; /* set mode */ if (ioctl(_ws2812_fd, SPI_IOC_WR_MODE, &i) < 0) /* config write mode */ { printf(\"spi: write mode set failed.\\n\"); /* write mode set failed */ return 1; /* return error */ } if (ioctl(_ws2812_fd, SPI_IOC_RD_MODE, &i) < 0) /* config read mode */ { printf(\"spi: read mode set failed.\\n\"); /* read mode set failed */ return 1; /* return error */ } i 20000000; /* set spi frequence */ if (ioctl(_ws2812_fd, SPI_IOC_WR_MAX_SPEED_HZ, &i) < 0) /* set write max frequence */ { printf(\"spi: set spi write speed failed.\\n\"); /* set spi write speed failed */ return 1; /* return error */ } if (ioctl(_ws2812_fd, SPI_IOC_RD_MAX_SPEED_HZ, &i) < 0) /* set read max frequence */ { printf(\"spi: set spi read speed failed.\\n\"); /* set spi read speed failed */ return 1; /* return error */ } i 0; if (ioctl(_ws2812_fd, SPI_IOC_WR_LSB_FIRST, &i) < 0) /* set write MSB first */ { printf(\"spi: set spi write msb first failed.\\n\"); /* set spi write msb first failed */ return 1; /* return error */ } if (ioctl(_ws2812_fd, SPI_IOC_RD_LSB_FIRST, &i) < 0) /* set read MSB first */ { printf(\"spi: set spi read msb first failed.\\n\"); /* set spi read msb first failed */ return 1; /* return error */ } i 8; /* set 8 bits */ if (ioctl(_ws2812_fd, SPI_IOC_WR_BITS_PER_WORD, &i) < 0) /* set write bits */ { printf(\"spi: set spi wirte 8 bit failed.\\n\"); /* set spi wirte 8 bit failed */ return 1; /* return error */ } if (ioctl(_ws2812_fd, SPI_IOC_RD_BITS_PER_WORD, &i) < 0) /* set read bits */ { printf(\"spi: set spi read 8 bit failed.\\n\"); /* set spi read 8 bit failed */ return 1; /* return error */ } return 0; /* success return 0 */ } } ``` ```C++ unsigned char spi_write_data(unsigned char *buf, uint16_t len) { struct spi_ioc_transfer k; int l; // ws2812b_interface_debug_print(\"\\r\\n***const char *const fmt***\\r\\n\"); memset(&k, 0, sizeof(k)); /* clear ioc transfer */ k.tx_buf (unsigned long) buf; /* set tx buffer */ k.len len; /* set tx length */ k.cs_change 0; /* set cs change */ l ioctl(_ws2812_fd, SPI_IOC_MESSAGE(1), &k); /* send data */ if (l ! len) /* check length */ { printf(\"spi: length check error.\\n\"); /* length check error */ return 1; /* return error */ } return 0; } // spi.xfer(tx, int(4/1.05e 6)) unsigned char spi_xfer_data(unsigned char *buf, uint16_t len, int clk) { struct spi_ioc_transfer k; int l; // ws2812b_interface_debug_print(\"\\r\\n***const char *const fmt***\\r\\n\"); memset(&k, 0, sizeof(k)); /* clear ioc transfer */ k.tx_buf (unsigned long) buf; /* set tx buffer */ k.len len; /* set tx length */ k.cs_change 0; /* set cs change */ k.speed_hz clk; /* set spi clk */ k.bits_per_word 8; l ioctl(_ws2812_fd, SPI_IOC_MESSAGE(1), &k); /* send data */ if (l ! len) /* check length */ { printf(\"spi: length check error.\\n\"); /* length check error */ return 1; /* return error */ } return 0; } ``` 读写数据的函数编写好后，就可以愉快的封装 WS2812 的亮灯程序啦！ ```C++ uint8_t _set_rgbs_color(uint8_t *color_buf) { uint8_t ret 0; uint8_t i 0; uint8_t j 0; uint8_t k 0; uint8_t tx[25] {0}; uint8_t rgb[3] {0}; uint8_t byte 0; uint8_t ibit 0; uint8_t *p color_buf; for (i 0; i < 2; i++) { rgb[0] p[0]; rgb[1] p[1]; rgb[2] p[2]; for (j 0; j < 3; j++) { uint8_t colorBit[4] {0}; byte rgb[j]; for (ibit 0; ibit < 4; ibit++) { colorBit[ibit] (((byte >> (2 * ibit + 1)) & 1) * 0x60 + ((byte >> (2 * ibit + 0)) & 1) * 0x06 + 0x88); } tx[k++] colorBit[3]; tx[k++] colorBit[2]; tx[k++] colorBit[1]; tx[k++] colorBit[0]; } p + 3; } tx[0] & 0x0f; // spi need clear head high level tx[0] 0x40; tx[24] 0b1000000; // spi need clear end high level ret spi_xfer_data(tx, 25, (int)(4/1.05e 6)); return ret; } ``` ### PWM 通过写寄存器的方式直接对三个 PWM 进行初始化操作。 ```C++ /*pwm*/ void pwm_init()//刚开始初始化50HZ 2.5%占空比 { _pwm_init(\"PH6\", 100, 2.5/100);//为了初始化引脚 _pwm_init(\"PH7\", 100, 2.5/100);//为了初始化引脚 _pwm_init(\"PH8\", 100, 2.5/100);//为了初始化引脚 usleep(100); chdir(\"/sys/class/sunxi_dump\"); system(\"echo 0x0300A080 0x00 > write\"); //PWM DISABLE system(\"echo 0x0300A040 0x00 > write\");//PWM CLOCK DISABLE system(\"echo 0x0300A028 0x00 > write\");//PWM45 system(\"echo 0x0300A02C 0x00 > write\");//PWM67 CLOCK CONFIG PCCR67 24M 不分频 system(\"echo 0x0300A030 0x00 > write\");//PWM89 CLOCK CONFIG PCCR89 24M 不分频 system(\"echo 0x0300A040 0x1D0 > write\");//PWM Clock Gating 打开PWM4 6,7,8时钟 system(\"echo 0x0300A180 0x107 > write\");//PWM4 system(\"echo 0x0300A184 0xea6005dc > write\");//PWM system(\"echo 0x0300A188 0x00 > write\");//PWM system(\"echo 0x0300A1C0 0x107 > write\");//PWM6配置8分频，循环模式 system(\"echo 0x0300A1C4 0xea6005dc > write\");//PWM6初始波形定义 system(\"echo 0x0300A1C8 0x00 > write\");//PWM6初始计数值为0 system(\"echo 0x0300A1E0 0x107 > write\");//PWM7配置8分频，循环模式 system(\"echo 0x0300A1E4 0xea6005dc > write\");//PWM7初始波形定义 system(\"echo 0x0300A1E8 0x00 > write\");//PWM7初始计数值为0 system(\"echo 0x0300A200 0x107 > write\");//PWM8配置8分频，循环模式 system(\"echo 0x0300A204 0xea6005dc > write\");//PWM8初始波形定义 system(\"echo 0x0300A208 0x00 > write\");//PWM8初始计数值为0 system(\"echo 0x0300A080 0x1D0 > write\");//ENABLE PWM4 6,7,8 } void pwm_deinit() { chdir(\"/sys/class/sunxi_dump\"); system(\"echo 0x0300A080 0x00 > write\"); system(\"echo 0x0300A040 0x00 > write\"); _pwm_deinit(\"PH6\"); _pwm_deinit(\"PH7\"); _pwm_deinit(\"PH8\"); } //设置PWM输出的频率，占空比，最大30KHZ //0 pwm6 //1 pwm7 //2 pwm8 void pwm_set(uint8_t pwm_id,uint32_t freq,float duty) { char data_buf[128]; unsigned int reg_freq_count 0; unsigned int reg_duty_count 0; unsigned int reg_data 0; memset(data_buf,0,sizeof(data_buf)); reg_freq_count (int)(3000000/freq); reg_duty_count (int)(reg_freq_count*duty/100); reg_data (reg_freq_count<<16)+reg_duty_count; switch (pwm_id) { case 0: sprintf(data_buf,\"echo 0x0300A1C4 0x%x > write\",reg_data); break; case 1: sprintf(data_buf,\"echo 0x0300A1E4 0x%x > write\",reg_data); break; case 2: sprintf(data_buf,\"echo 0x0300A204 0x%x > write\",reg_data); break; default: break; } ``` 通过封装好的 `pwm_set` 就可以简单的控制三个 `pwm` 的输出频率了。 ### IIC 以 MPU6050 为例，首先查询你所用芯片的寄存器手册，配置相关寄存器设置。 ```C++ #define WHO_AM_I_REG 0x75 #define POWR_MGNT_REG 0x6B #define ACCL_CONF_REG 0x1C #define GYRO_CONF_REG 0x1B #define SMPL_DVDR_REG 0x19 #define CONFIG_REG 0x1A #define ACCL_XH_REG 0x3B #define ACCL_XL_REG 0x3C #define ACCL_YH_REG 0x3D #define ACCL_YL_REG 0x3E #define ACCL_ZH_REG 0x3F #define ACCL_ZL_REG 0x40 #define GYRO_XH_REG 0x43 #define GYRO_XL_REG 0x44 #define GYRO_YH_REG 0x45 #define GYRO_YL_REG 0x46 #define GYRO_ZH_REG 0x47 #define GYRO_ZL_REG 0x48 #define TEMP_HI_REG 0x41 #define TEMP_LO_REG 0x42 #define FIFO EN_REG 0x23 #define FIFO_CH_REG 0x72 #define FIFO_CL_REG 0x73 #define FIFO_REG 0x74 char i2c_write(int file, uint8_t address, uint8_t command, uint8_t value) { uint8_t buf[2] {command, value}; struct i2c_msg msgs[1] { { .addr address, .flags 0, .len 2, .buf buf, }, }; struct i2c_rdwr_ioctl_data data { .msgs msgs, .nmsgs 1, }; if (ioctl(file, I2C_RDWR, &data) < 0) { return 1; } return 0; } char i2c_read(int file, uint8_t address, uint8_t command) { uint8_t buf[1]; struct i2c_msg msgs[2] { { .addr address, .flags 0, .len 1, .buf &command, }, { .addr address, .flags I2C_M_RD, .len 1, .buf buf, }, }; struct i2c_rdwr_ioctl_data data { .msgs msgs, .nmsgs 2, }; if (ioctl(file, I2C_RDWR, &data) < 0) { return 1; } return buf[0]; } void mpu6050_init(uint8_t i2c_number, uint8_t slave_addr) { \tfile open(\"/dev/i2c 2\", O_RDWR); if (file < 0) { printf(\"I2C %hhu Not Found\\n\", i2c_number); \t\texit(1); } \ti2c_address slave_addr; if (ioctl(file, I2C_SLAVE, i2c_address) < 0) { close(file); printf(\"I2C Slave Not Found\"); \t\texit(1); } \ti2c_write(file,slave_addr,POWR_MGNT_REG, 0x00); \ti2c_write(file,slave_addr,ACCL_CONF_REG, 0x01); \ti2c_write(file,slave_addr,GYRO_CONF_REG, 0x18); i2c_write(file,slave_addr,SMPL_DVDR_REG, 0x07); \ti2c_write(file,slave_addr,CONFIG_REG, 0x06); } ``` 在初始化 mpu6050 时需先查阅原理图，根据 `M2DCOK` 的原理图可得知 `IIC` 的 `PH11` 和 `PH12` 分别是 `SCL` 和 `SDA` 两根信号线，且对应的设备是 `/dev/i2c 2`，这样看来 `i2c_number` 就应该为 `/dev/i2c 2`。 **第一步**：我们可以通过命令去查找 `mpu6050` 在 `IIC` 上的地址 ```shell i2cdetetc y 2 ``` ![i2c](./assest/i2c.jpg) >我们可从上图得知有两个地址：62 以及 68，62 是板卡上自带的三轴传感器，而 68 则是我们的 mpu6050 挂载在 IIC 上的地址。 **第二步**：拿到地址后也可以通过命令直接去查看 mpu6050 中寄存器的值 ```shell i2cdump y 2 0x68 ``` ![6050](./assest/6050.jpg) **第三步**：分别取出高八位和低八位的值后，拼接起来后再通过一层换算才能得到真实的数据，以加速度、角速度和温度为例，打印出换算后的个值。 ```C++ int16_t twos_complement(uint8_t higher_byte, uint8_t lower_byte) { \tuint16_t word (uint16_t)((higher_byte << 8) lower_byte); \tint16_t signed_word; \tif((word & 0x8000) ! 0) \t{ \t\tword ~word + 0x0001; \t\tsigned_word (int16_t)(word * 1); \t\treturn signed_word; \t} \telse \t{ \t\tsigned_word (int16_t)word; \t\treturn signed_word; \t} } mpu6050_init(2, 0x68); axh i2c_read(file,i2c_address,ACCL_XH_REG); axl i2c_read(file,i2c_address,ACCL_XL_REG); ayh i2c_read(file,i2c_address,ACCL_YH_REG); ayl i2c_read(file,i2c_address,ACCL_YL_REG); azh i2c_read(file,i2c_address,ACCL_ZH_REG); azl i2c_read(file,i2c_address,ACCL_ZL_REG); gxh i2c_read(file,i2c_address,GYRO_XH_REG); gxl i2c_read(file,i2c_address,GYRO_XL_REG); gyh i2c_read(file,i2c_address,GYRO_YH_REG); gyl i2c_read(file,i2c_address,GYRO_YL_REG); gzh i2c_read(file,i2c_address,GYRO_ZH_REG); gzl i2c_read(file,i2c_address,GYRO_ZL_REG); th i2c_read(file,i2c_address,TEMP_HI_REG); tl i2c_read(file,i2c_address,TEMP_LO_REG); axw twos_complement(axh, axl); ayw twos_complement(ayh, ayl); azw twos_complement(azh, azl); gxw twos_complement(gxh, gxl); gyw twos_complement(gyh, gyl); gzw twos_complement(gzh, gzl); tw twos_complement(th, tl); ``` 最后打印结果如下图： ![print](./assest/print.jpg) ## 常见问题 A&Q 很多的问题的出现都是误操导致的，如果 AQ 里没有你遇见的问题，那就自己尝试解决问题，一步一步往回溯源根据报错信息遗漏哪一步哪一环。 [MaixPy3 常见问题与解决方法](https://wiki.sipeed.com/soft/maixpy3/zh/question/maixpy3_faq.html) [M2DOCK 常见问题指南](https://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII Dock.html#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8C%87%E5%8D%97) [Github issues](https://github.com/sipeed/MaixPy3/issues) [BBS 社区常见问题汇总贴](https://bbs.sipeed.com/thread/489) [相关讨论社群](https://wiki.sipeed.com/community.html)"},"/news/MaixPy3/key_face_recognize.html":{"title":"V831的人脸识别","content":" title: V831的人脸识别 keywords: MaixII Dock, MaixPy3, 人脸识别, V831 desc: V831的人脸识别 date: 2022 03 15 tags: MaixII Dock, MaixPy3 在文档中看到 V831 可以用来实现人脸识别，于是就将按键也添加到人脸识别中。 <! more > 实现一个可以通过按键进行控制的人脸识别，进行人脸信息的添加和删除控制 ## 源码 ```python from maix import nn, camera, image, display from maix.nn.app.face import FaceRecognize import time from evdev import InputDevice from select import select score_threshold 70 #识别分数阈值 input_size (224, 224, 3) #输入图片尺寸 input_size_fe (128, 128, 3) #输入人脸数据 feature_len 256 #人脸数据宽度 steps [8, 16, 32] # channel_num 0 #通道数量 users [] #初始化用户列表 names [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"] #人脸标签定义 model { \"param\": \"/home/model/face_recognize/model_int8.param\", \"bin\": \"/home/model/face_recognize/model_int8.bin\" } model_fe { \"param\": \"/home/model/face_recognize/fe_res18_117.param\", \"bin\": \"/home/model/face_recognize/fe_res18_117.bin\" } for i in range(len(steps)): channel_num + input_size[1] / steps[i] * (input_size[0] / steps[i]) * 2 channel_num int(channel_num) #统计通道数量 options { #准备人脸输出参数 \"model_type\": \"awnn\", \"inputs\": { \"input0\": input_size }, \"outputs\": { \"output0\": (1, 4, channel_num) , \"431\": (1, 2, channel_num) , \"output2\": (1, 10, channel_num) }, \"mean\": [127.5, 127.5, 127.5], \"norm\": [0.0078125, 0.0078125, 0.0078125], } options_fe { #准备特征提取参数 \"model_type\": \"awnn\", \"inputs\": { \"inputs_blob\": input_size_fe }, \"outputs\": { \"FC_blob\": (1, 1, feature_len) }, \"mean\": [127.5, 127.5, 127.5], \"norm\": [0.0078125, 0.0078125, 0.0078125], } keys InputDevice('/dev/input/event0') threshold 0.5 #人脸阈值 nms 0.3 max_face_num 1 #输出的画面中的人脸的最大个数 print(\" load model:\", model) m nn.load(model, opt options) print(\" load ok\") print(\" load model:\", model_fe) m_fe nn.load(model_fe, opt options_fe) print(\" load ok\") face_recognizer FaceRecognize(m, m_fe, feature_len, input_size, threshold, nms, max_face_num) def get_key(): #按键检测函数 r,w,x select([keys], [], [],0) if r: for event in keys.read(): if event.value 1 and event.code 0x02: # 右键 return 1 elif event.value 1 and event.code 0x03: # 左键 return 2 elif event.value 2 and event.code 0x03: # 左键连按 return 3 return 0 def map_face(box,points): #将224*224空间的位置转换到240*240或320*240空间内 # print(box,points) if display.width() display.height(): def tran(x): return int(x/224*display.width()) box list(map(tran, box)) def tran_p(p): return list(map(tran, p)) points list(map(tran_p, points)) else: # 168x224(320x240) > 224x224(240x240) > 320x240 s (224*display.height()/display.width()) # 168x224 w, h, c display.width()/224, display.height()/224, 224/s t, d c*h, (224 s) // 2 # d 224 s // 2 28 box[0], box[1], box[2], box[3] int(box[0]*w), int((box[1] 28)*t), int(box[2]*w), int((box[3])*t) def tran_p(p): return [int(p[0]*w), int((p[1] d)*t)] # 224 168 / 2 28 so 168 / (old_h 28) 240 / new_h points list(map(tran_p, points)) # print(box,points) return box,points def darw_info(draw, box, points, disp_str, bg_color (255, 0, 0), font_color (255, 255, 255)): #画框函数 box,points map_face(box,points) font_wh image.get_string_size(disp_str) for p in points: draw.draw_rectangle(p[0] 1, p[1] 1, p[0] + 1, p[1] + 1, color bg_color) draw.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color bg_color, thickness 2) draw.draw_rectangle(box[0], box[1] font_wh[1], box[0] + font_wh[0], box[1], color bg_color, thickness 1) draw.draw_string(box[0], box[1] font_wh[1], disp_str, color font_color) def recognize(feature): #进行人脸匹配 def _compare(user): #定义映射函数 return face_recognizer.compare(user, feature) #推测匹配分数 score相关分数 face_score_l list(map(_compare,users)) #映射特征数据在记录中的比对分数 return max(enumerate(face_score_l), key lambda x: x[ 1]) #提取出人脸分数最大值和最大值所在的位置 def run(): img camera.capture() #获取224*224*3的图像数据 AI_img img.copy().resize(224, 224) if not img: time.sleep(0.02) return faces face_recognizer.get_faces(AI_img.tobytes(),False) #提取人脸特征信息 if faces: for prob, box, landmarks, feature in faces: key_val get_key() if key_val 1: # 右键添加人脸记录 if len(users) < len(names): print(\"add user:\", len(users)) users.append(feature) else: print(\"user full\") elif key_val 2: # 左键删除人脸记录 if len(users) > 0: print(\"remove user:\", names[len(users) 1]) users.pop() else: print(\"user empty\") if len(users): #判断是否记录人脸 maxIndex recognize(feature) if maxIndex[1] > score_threshold: #判断人脸识别阈值,当分数大于阈值时认为是同一张脸,当分数小于阈值时认为是相似脸 darw_info(img, box, landmarks, \"{}:{:.2f}\".format(names[maxIndex[0]], maxIndex[1]), font_color (0, 0, 255, 255), bg_color (0, 255, 0, 255)) print(\"user: {}, score: {:.2f}\".format(names[maxIndex[0]], maxIndex[1])) else: darw_info(img, box, landmarks, \"{}:{:.2f}\".format(names[maxIndex[0]], maxIndex[1]), font_color (255, 255, 255, 255), bg_color (255, 0, 0, 255)) print(\"maybe user: {}, score: {:.2f}\".format(names[maxIndex[0]], maxIndex[1])) else: #没有记录脸 darw_info(img, box, landmarks, \"error face\", font_color (255, 255, 255, 255), bg_color (255, 0, 0, 255)) display.show(img) if __name__ \"__main__\": import signal def handle_signal_z(signum,frame): print(\"APP OVER\") exit(0) signal.signal(signal.SIGINT,handle_signal_z) while True: run() ```"},"/news/MaixPy3/difference.html":{"title":"MaixPy 与 MaixPy3 的区别","content":" title: MaixPy 与 MaixPy3 的区别 keywords: MaixPy, MaixPy3, Python, Python3, MicroPython desc: MaixPy 与 MaixPy3 的区别 date: 2022 03 07 tags: MaixPy,MaixPy3 <! more > ## 区别是？ 因为使用 MaixPy 的同学可能有两类人群，一类是从 MicroPython 一路使用过来的，另一类是从 Python3 过来的，所以针对两边的差异，分别做一下说明。 可以这样理解，它们都是专门为 AIoT 提供的 Python 开发环境，提供了各种各样的模块。 MaixPy 指的是基于 MicroPython 的环境制作的。 MaixPy3 指的是基于 Linux Python3 的环境制作的。 > 前者是基于 MCU 无系统的，后者是基于 Linux 系统。 除了基本的 Python3 语法一致，在提供的模块方面的存在着不小的差异。 ### Python3 与 MicroPython 的区别 大多数时候，Python 的发展以 Python3 为主，以下列出一些与 Python3 的差异化信息。 MicroPython 和 Python3 在 Python 语法上保持高度的一致性，常用的标准语法命令都已经支持。 MicroPython 虽然只实现了 Python3 的标准库和容器库的一些部分，常见容器库有同类功能，但不同名的模块，但大多算法类的 Python 逻辑代码是可以拿来即用的。 MicroPython 兼容实现的 Python3 的异常机制、没有实现元类（metaclass）机制，独立的 GC 机制。 在许当不同的硬件微芯片（最低在 nRF51）的移植上， MicroPython 代码接口缺乏一致性，呈现碎片化。 MicroPython 编译（mpy corss）后得到的是 mpy ，而不是 Python3 的 pyc 文件。 MicroPython 在移植 Python3 代码时，经常缺少各种方法，所以要习惯寻找同类接口，而它们的使用方法除了看文档外就只能看源码。 ### 总结 MaixPy 相比 MaixPy3 功能要更简单（简陋）。 MaixPy 和 MaixPy3 的开发工具不同。 MaixPy 标准库（MicroPython）相比 MaixPy3 有一定的不足。 MaixPy 的外设驱动模块具体函数存在差异。 不同的芯片执行效率有差异，MaixPy 和 MaixPy3 的有着不同的内存与性能消耗。 > 如有更多欢迎补充。"},"/news/MaixPy/K210_kflash_ISP_download_progress.html":{"title":"K210 kflash ISP 下载程序流程","content":" title: K210 kflash ISP 下载程序流程 keywords: K210, kflash, ISP date: 2022 06 09 tags: K210, kflash K210详细的的程序下载流程，包括芯片侧和kflash侧 <! more > 版权声明：本文为 neucrack 的原创文章，遵循 CC 4.0 BY SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://neucrack.com/p/312 有改动 ## 术语 ISP: In System Programming, 在系统编程 ## kflash 下载流程 > 带 开头的是芯片侧的操作 芯片拷贝 `boot rom` (特定的硬件，一次性写入)中的 boot 程序到内存末尾1()，并调用运行这个 boot 程序 boot 程序运行后， 从 otp 读取信息来判断是否需要从 top 中读取新的 boot，因为 boot rom 区域是一次性写入的，如果 boot 写出了 bug，可以用 otp 中写入新的 boot 来挽救，相当于芯片出厂有两次写入 boot 的机会。而事实是 k210 确实用上了这个功能 如果需要使用 otp 中的新 boot，则读取到内存末尾，但是需要在现在正在运行的 boot 前面，比如之前的末尾1是倒数16k，那么这个 otp 的 boot 就需要写到之前,比如倒数32k到倒数16k位置，然后跳转执行这个新的 boot boot 程序判断 boot 引脚是否被拉低，没被拉低则进入正常启动模式，读取整个固件到内存，然后启动，否则进入ISP模式 上位机打开串口 上位机通过串口的 dtr rts 来设置 boot 和 reset 引脚，保持拉低 boot引脚，然后拉低reset引脚再拉高reset引脚， 即让芯片重启的时候保持boot引脚为低电平 芯片boot程序检测，如果boot引脚被拉低了，则进入 ISP 模式(输入boot程序的一部分) 上位机向芯片发送握手信号(b'\\xc0\\xc2\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0')，然后等待响应信号 默认芯片是115200波特率，如果需要更高波特率，发送修改波特率命令给芯片，芯片程序(boot)修改通信波特率 向芯片发送写 ramrum 程序的命令，并将需要 RAMRUM 的程序或者新的 ISP 程序发过去，写到芯片内存的起始地址 注意到，这里没有直接发送要写入到flash的程序过去让boot里面的ISP程序去写入到Flash，而是重新发送了一份ISP程序过去，后面会运行这份新的ISP程序来从串口获取固件并烧录到flash，这可以说是为了更灵活，可以自定义ISP程序，而且ISP程序的大小只要小于前面的 boot 和 otp 的新boot的大小之和就行，boot里面做这些事可能面临boot程序过大或者有bug后期更新的问题。但是代价就是每次下载程序都要花费几秒钟下载新的ISP程序，这样用户每次下载的时间会变长，所以最好的肯定是一次性把boot程序写完美，没有bug。其实也可以在boot的ISP程序中加入写如程序到flash的命令,这样是否使用新的ISP就可选 向芯片发送启动 ramrum 命令 如果是想在ram中运行程序，到这一步为止即可，程序已经在ram中运行了，否则往下一步 接下来就是运行发送过去的新ISP程序了 上位机和ISP程序握手 isp程序默认波特率115200，如果需要更高，这里发送更改命令让isp程序修改串口波特率 通过串口发送程序文件到isp程序，isp程序写入到 flash 通过串口的 dtr 和 rts 控制芯片的reset和boot引脚来正常启动，不进入 ramrum 模式，而是正常从flash加载程序启动"},"/news/MaixPy/K210_usage.html":{"title":"K210 上手（避坑）指南","content":" title: K210 上手（避坑）指南 tags: K210, 避坑指南, 上手指南 keywords: K210 使用指南，避坑, 上手 update: date: 2022 12 30 version: v0.1 author: lyx content: 初次编写文档 date: 2023 02 03 version: v0.2 author: lyx content: 整理框架 补充内容 date: 2023 03 03 version: v0.3 author: lyx content: 补充应用案例以及细节 <div style \"font size: 1.2em;border: 2px solid green; border color:#c33d45;padding:1em; text align:center; background: #c33d45; color: white\"> <div> <span>新版 MaixPy (v4) 已经上线， 完整 Python3 支持，功能更强大， 请看:</span> <a target \"_blank\" style \"color: #ffe0e0\" href \"https://wiki.sipeed.com/maixpy\"> wiki.sipeed.com/maixpy </a> <br> <div style \"height:0.4em\"></div> <span>全新硬件产品 MaixCAM，性能大升级，请看:</span> <a target \"_blank\" style \"color: #ffe0e0\" href \"https://wiki.sipeed.com/maixcam\"> https://wiki.sipeed.com/maixcam </a> </div> <div style \"padding: 1em 0 0 0\"> <a style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #a80202\" href \"https://item.taobao.com/item.htm?id 784724795837\">淘宝</a> <a style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #a80202\" href \"https://www.aliexpress.com/store/911876460\">速卖通</a> </div> </div> **Maix I K210 系列正在被逐渐淘汰，如果你正准备购买 K210, 请立刻选择 MaixCAM;** **也欢迎 K210 用户升级到 MaixCAM** ## 前言 >在 22 年的最后两天终于有时间开始整理填坑了，顶鸽逃跑（不是故意的）看见很多新手小白还是在文档海里扑腾找不到 K210 的资料文档，那就由这篇 K210 的避坑指南让小白的使用之路更顺利一点吧！ **这篇文档以 SIPEED `MaixDuino` 的使用为示例说明，并且大部分内容通用于 K210 系列开发板，可供购入 K210 系列顾客参考使用，`MaixDuino` 相关介绍参数[ 点击 ](https://wiki.sipeed.com/hardware/zh/maix/maixpy_develop_kit_board/maix_duino.html)查询，选购开发板指南可参考[选购指南。](https://wiki.sipeed.com/soft/maixpy/zh/develop_kit_board/get_hardware.html)** ![maixduino_0](./mixly_application/accets/k210_usage/maixduino_0.jpg) >以下为 MaixDuino 全引脚标注图 ![pin](./mixly_application/accets/k210_usage/pin.png) ## 基础知识 在使用板子上手之前，我们需要先掌握一些基础知识**（有基础的小伙伴可跳过）**由于 `MaixPy` 是基于 `MicroPython` 之上进行开发构建的，提供给用户最终的接口是 `Micropython`，所以在使用 `MaixPy` 之初我们需要熟悉下 `MicroPython` 的基础知识与语法以及常用的 `Git` 与 `Github`。 **MaixPy 语法基础知识：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/get_started/knowledge_micropython.html) **Git 和 Github 介绍：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/get_started/knowledge_git_github.html) 以下是图像及音频的背景知识，有需要或感兴趣的小伙伴可以查看。 **图像处理背景知识：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/get_started/knowledge_image.html) **音频处理背景知识：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/get_started/knowledge_audio.html) ## 准备工作 无论是新手小白还是开发者在踏入 `K210 系列开发板` 学习之路前，做好充足的准备工作在一定程度上可以在使用途中避免踩坑。这篇文档是以一份避坑上手步骤的指南为核心来构写的，所以切记！！新手小白千万不可以跳着看，下图是示例硬件 `MaixDuino` 开发板、摄像头、屏幕、以及 USB Type c 数据线。 ![maixduino](./mixly_application/accets/k210_usage/maixduino.jpg) ### 上手流程图 避坑指南可以搭配上手流程图一起使用更佳~ ![steps](./mixly_application/accets/k210_usage/steps.jpg) ### 硬件接线 **USB Type C 数据线** 自行准备质量可靠或者是手机附赠的数据线，质量差的数据线会因电压问题造成开发板处于非正常工作状态导致后续影响使用，有些 Type C 线只能供电。 ![type c](./mixly_application/accets/k210_usage/type_c.jpg) **Micro SD/TF 卡（可选）** 在 K210 开发板上不使用 Micro SD 卡也可操作文件, 我们在内部 Flash 上保留了一部分作为文件系统, 只是 Flash 速度很慢，为了操作方便的话可以选购 Micro SD/TF 卡，以下图例为 SD 卡安装卡槽。 **如何选购 SD/TF 卡传送门：**[点击前往](eed.com/soft/maixpy/zh/develop_kit_board/get_hardware.html#Micro SD 卡 %28TF 卡%29 %28可选%29) ![sd](./mixly_application/accets/k210_usage/sd.jpg) >**注意：MaixPy 不支持挂载文件系统到电脑！！！K210 芯片没有 USB 功能无法模拟 U 盘设备！！！** >**不要再问为什么没有 U 盘或者是显示 SD 卡了！那不是 K210 那是 M2dock 跟 openmv!** **屏幕及摄像头接线** 当我们收到开发板后，首先对硬件进行检查是否有外表损坏，接着再根据屏幕以及摄像头的排线丝印安装到开发板上，即排线上的数字 **“1”** 和板子卡座边上引脚丝印 **“1”** 方位对应接上。 <html> <img src \"./mixly_application/accets/k210_usage/lcd.jpg\" width 45%> <img src \"./mixly_application/accets/k210_usage/sensor.jpg\" width 45%> </html> ### 安装 MaixPy IDE 因 MaixPy IDE 需要一定的下载时间，我们可以提前先挂在后台下载节约小伙伴们的时间。 首先要清楚明白 MaixPy 使用 Micropython 脚本语法，所以不像 `C 语言` 一样需要编译，我们可以在电脑上进行实时的编辑、运行、保存、观看摄像头效果的操作，故而对新手小白比较友好。 **MaixPy IDE 下载传送门：**[点击前往](https://dl.sipeed.com/MAIX/MaixPy/ide/) **MaixPy IDE 安装与使用例程：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/env_maixpyide.html) ![maixpy_logo](./mixly_application/accets/k210_usage/maixpy_logo.jpg) > **MaixPy IDE 支持 Linux、Windows、Macos 等系统如出现安装报错现象请前往 [MaixPy 常见问题 FAQ](https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html?highlight SD#Micro SD %E5%8D%A1%E8%AF%BB%E5%8F%96%E4%B8%8D%E5%88%B0) 或 [BBS【超实用】常见问题汇总贴](https://bbs.sipeed.com/thread/489) 排查问题。** ### 给板子通电 先使用准备的 USB type c 数据线两端分别接入板子及电脑端进行上电操作，方便后续更新固件等使用。 **如果是新购买出厂的开发板的话，上电后会显示红色屏幕。** ![red_lcd](./mixly_application/accets/k210_usage/red_lcd.jpg) > **上电后出现白屏、黄屏、绿屏、蓝屏、闪屏等更多报错现象请前往 [MaixPy 常见问题 FAQ](https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html?highlight SD#Micro SD %E5%8D%A1%E8%AF%BB%E5%8F%96%E4%B8%8D%E5%88%B0) 或 [BBS【超实用】常见问题汇总贴](https://bbs.sipeed.com/thread/489) 排查问题。** ### 安装驱动 因 K210 没有 USB 硬件支持功能需通过 USB 转串口与电脑连接，所以用户需安装串口搭建板子与电脑的连接桥梁，点击文档链接根据板子的型号下载相对应的驱动，安装成功后设备管理器会显示（COMx）端口。 **串口驱动下载传送门：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/env_install_driver.html) ![com](./mixly_application/accets/k210_usage/com.jpg) 如果出现安装失败、安装后设备接入 `PC` 端的设备管理器不显示 `COM` 端口的现象，需要检查系统是不是正版或更新下（Win7 Win8）系统，部分盗版系统会导致驱动安装失败或是安装后不显示。 **更多的不显示 `COM` 端口参考解决方法：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/env_install_driver.html#%E5%85%B3%E4%BA%8E USB %E4%B8%B2%E5%8F%A3%E7%9A%84%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E6%8E%92%E6%9F%A5) ## 如何升级固件（必看） > 升级固件对 K210 系列板子来说至关重要，快速避免掉用户在使用中无限踩雷影响体验感，例如常见的 MaxiPy IDE 连接失败、屏幕白屏/黄屏等现象，所以板子到手后更新固件成了必不可少的一件事情。 **怎么去判定自己需要的什么固件？** **如果是第一次使用 k210 系列版更新固件，请无脑看图选标准固件（序号：15）！** **如果是因为应用需要特殊固件，看应用文档需要什么下载什么！其余一律看功能尾缀！功能尾缀！选择固件。** **K210 Amigo 开发板固件与以上不通用，固件请在（序号 3 6）里选择下载。** ![bin](./mixly_application/accets/k210_usage/bin.png) 参考上方描述选择（**日期最新**）所需的固件并下载到本地，使用 `kflash_gui` 烧录工具对板子进行升级固件。 ![bin_two](./mixly_application/accets/k210_usage/bin_two.png) 如何正确烧录固件示例可参考：[升级固件示例文档](https://wiki.sipeed.com/soft/maixpy/zh/get_started/upgrade_maixpy_firmware.html) 可搭配[ MaixPy 存储系统](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_fs.html)一起食用更佳。 > 注意：因 MaixPy 系列的开发板中 MaixDuino 板载了一块 ESP32 WIFI SOC，一般情况下不推荐更新板载的 ESP32 模块，如在使用途中出现 bug 可以参考[更新板载 ESP32 固件](https://wiki.sipeed.com/soft/maixpy/zh/get_started/upgrade_esp32_firmware.html)进行更新固件 ## 上手运行程序 >使用 MaixPy IDE 进行调试操作的话，板子需烧录固件而且版本必须是 `v0.3.1` 以上, 否则 MaixPy IDE 会出现连接不上的现象。 ### 使用 MaixPy IDE 运行程序（含测试程序） 根据下图将 K210 开发板连接 `MaixPy IDE` 软件，连接成功后步骤 3 的图标会变成红色，接下来运行 `helloworld.py` 测试摄像头及屏幕是否可用，运行后开发板屏幕以及软件会显示摄像头画面。 ![maixpyide](./mixly_application/accets/k210_usage/maixpyide.jpg) **MaixPy 软件使用例程：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/env_maixpyide.html#%E6%B5%8B%E8%AF%95%E8%BF%90%E8%A1%8C) / **测试屏幕及摄像头源码：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_cam_lcd.html) 如出现软件无画面的话，请参考步骤 5 是否被缩放了，更详细的连接过程请参考下文链接，测完后可在文件里`新建文件夹`编辑自己的代码并运行。 ![maixpy_run](./mixly_application/accets/k210_usage/maixpy_run.jpg) ### 使用串口终端运行程序 >如果是有基础的用户较推荐使用终端来调试，`MaixPy IDE` 虽然运行报错会显示但信息可能不完整，而终端会输出更详细的报错信息方便排错。如果出现串口连接终端失败的现象，看看串口是否被占用。 使用前可以先点击了解 [串口定义是什么？](https://wiki.sipeed.com/soft/maixpy/zh/get_started/uart.html) 方便我们理解后续使用更方便。文档提供了多种串口连接工具供用户使用，有 `MaixPy IDE 终端工具`、`Mobaxterm`、`mpfshell lite` 等在 `Windows` 环境下的工具，以及 `Linux` 下的使用方法。 **这里我们更推荐使用 MaixPy IDE 串口终端，以下时连接以及运行示例。** 点击 MaixPy IDE 软件页面上方的 `工具` >`打开终端` >`新终端` >`连接到串口` >`确定默认串口号` >`波特率：115200` 确定自动连接，连接后按复位即可正常编辑。 ![maixpy_tty](./mixly_application/accets/k210_usage/maixpy_tty.png) ![tty_usage](./mixly_application/accets/k210_usage/tty_usage.jpg) 运行 `hello maixpy` 终端会输出打印结果，更详细的资料以及更多连接串口方式请点击下文链接查看。 ```python print(\"hello maixpy\") #命令 #hello maixpy #终端打印结果 ``` ![adb](./mixly_application/accets/k210_usage/adb.jpg) **MobaXterm 下载及使用方法：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/env_serial_tools.html#Mobaxterm) **MaixPy IDE 终端使用方法：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/env_serial_tools.html#MaixPy IDE%E7%BB%88%E7%AB%AF%E5%B7%A5%E5%85%B7) **mpfshell lite 工具介绍及用法：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/mpfshell lite/mpfshell lite.html) **mpfshell lite 使用手册：**[点击前往](https://wiki.sipeed.com/soft/maixpy/zh/get_started/mpfshell lite/mpfshell lite help.html) ### 如何编辑代码并运行 上文我们简单介绍了在 MaixPy IDE 上如何运行代码以及使用串口终端，但实际这些运行都是一次性并不保存到设备里，我们更希望代码保存在文件系统，这样不需要再次敲代码可直接运行程序更为便利快捷，小伙伴们可以参考以下的示例方法进行操作。 **如何编辑并保存文件请参考以下示例：** [方法一： 使用内置编辑器 Micropython Editor(pye)](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A %E4%BD%BF%E7%94%A8%E5%86%85%E7%BD%AE%E7%BC%96%E8%BE%91%E5%99%A8 %3Ca href%3D%22https%3A//github.com/robert hh/Micropython Editor%22 target%3D%22_blank%22%3EMicropython Editor%28pye%29%3C/a%3E) [方法二： 使用 MaixPy IDE](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%9A %E4%BD%BF%E7%94%A8 MaixPy IDE) [方法三： 使用工具 uPyLoader 读取到 PC（电脑)上编辑后再保存到开发板](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E4%B8%89%EF%BC%9A %E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7 %3Ca href%3D%22https%3A//github.com/BetaRavener/uPyLoader%22 target%3D%22_blank%22%3EuPyLoader%3C/a%3E %E8%AF%BB%E5%8F%96%E5%88%B0 PC%EF%BC%88%E7%94%B5%E8%84%91%29%E4%B8%8A%E7%BC%96%E8%BE%91%E5%90%8E%E5%86%8D%E4%BF%9D%E5%AD%98%E5%88%B0%E5%BC%80%E5%8F%91%E6%9D%BF) [方法四： 使用工具 rshell 读取到 PC（电脑)上编辑后再保存到开发板](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E5%9B%9B%EF%BC%9A %E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7 %3Ca href%3D%22https%3A//github.com/dhylands/rshell%22 target%3D%22_blank%22%3Ershell%3C/a%3E %E8%AF%BB%E5%8F%96%E5%88%B0 PC%EF%BC%88%E7%94%B5%E8%84%91%29%E4%B8%8A%E7%BC%96%E8%BE%91%E5%90%8E%E5%86%8D%E4%BF%9D%E5%AD%98%E5%88%B0%E5%BC%80%E5%8F%91%E6%9D%BF) **如何执行文件请参考以下示例：** [方法一： 使用 import 执行](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A %3Ccode%3Eimport%3C/code%3E) [方法二： 使用 exec() 函数来执行](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%9A %3Ccode%3Eexec%28%29%3C/code%3E) [方法三： 使用 MaixPy IDE 来执行](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html#%E6%96%B9%E6%B3%95%E4%B8%89%EF%BC%9A %E4%BD%BF%E7%94%A8 %3Cstrong%3EMaixPy IDE%3C/strong%3E %E6%9D%A5%E6%89%A7%E8%A1%8C) **方法四： 使用 uPyLoader 来执行：连接好后选中文件, 点击 excute 按钮来执行文件** **方法五： 使用 ampy 来直接运行电脑上的文件：执行命令 ampy run file_in_PC.py 来执行位于电脑上的文件（文件不会保存到开发板）** ### 如何上传代码到开发板 我们可以通过多种方式打开编辑器来直接编辑文件系统中的文件，但如果出现代码量庞大或需要高亮支持的情况就不适用了，这时可以在电脑上写完代码放入开发板的文件系统内。 **可参考以下几种方法示例进行操作：** [方法一：使用图形工具 uPyLoader 上传、运行脚本](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html#%E4%BD%BF%E7%94%A8%E5%9B%BE%E5%BD%A2%E5%B7%A5%E5%85%B7 uPyLoader %E4%B8%8A%E4%BC%A0%E3%80%81%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC) [方法二：使用命令行工具运行脚本](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html#%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7) **方法三：SD（TF） 直接运行：拷贝到 SD 卡后， 在终端中执行 `import` 文件名 或者 `exec()` 来运行脚本** [方法四：SD 卡自动拷贝到 Flash 文件系统](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html#SD %E5%8D%A1%E8%87%AA%E5%8A%A8%E6%8B%B7%E8%B4%9D%E5%88%B0 Flash %E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F) ### 如何开机自动运行代码 **如何配置开机自启动脚本相关：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_boot.html) ### 定制专属固件 出于满足部分小伙伴对内存的需求，可通过源码编译所需固件。 [为何需要固件定制](https://wiki.sipeed.com/soft/maixpy/zh/firmware/why_customize_firware.html) [源码编译](https://wiki.sipeed.com/soft/maixpy/zh/firmware/compile.html) ## 存储系统介绍 MaixPy 中的存储介质主要由 `Flash`、`SD` 卡组成，并分为三块区域分别是 `MaixPy.bin 固件区`、`xxx.kmodel 模型区`、`文件系统区：Flash 上为 spiffs（SPI Flash File System）、SD 卡为 Fatfs（FAT file system)` 后续方便小伙伴们使用模型或烧写固件时参考，注意烧写时的不同区域防止报错或烧写失败。 **存储系统介绍：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_fs.html) ## 更多功能应用 >这篇文档完全是按新手小白的使用步骤一步一步来写的，在【更多功能应用】里编写的是 MaixPy 的应用案例以及使用方式，如果是没有接触过 `Python 以及 MicroPython` 的小伙伴们一定要先学会基础的语法知识，切记！没有基础的小伙伴不可以跳过上文！！！更多功能应用是基于上文的基础下写的，可以搭配 [API 文档](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/standard/index.html)和[MaixPy 例程仓库](https://github.com/sipeed/MaixPy v1_scripts)一同学习。 【更多功能应用】分为五大部分：`系统基础功能`、`外设模块拓展`、`图像处理基础（image）`、`传统算法应用`、`神经网络应用（AI）`因示例较多，这里列举几种常用的可点击可前往[更多功能应用](https://wiki.sipeed.com/soft/maixpy/zh/course/index.html)目录下查看所需要的示例。 **系统基础功能：** 包含了 [CPU & RAM](https://wiki.sipeed.com/soft/maixpy/zh/course/others/system.html)、[GUI 支持](https://wiki.sipeed.com/soft/maixpy/zh/course/image/image_draw_font/image_draw_font.html)、[网络支持](https://wiki.sipeed.com/soft/maixpy/zh/course/network/network_config.html)、[媒体功能](https://wiki.sipeed.com/soft/maixpy/zh/course/media/audio.html)、[游戏模拟](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/media/nes.html)。 **外设模块拓展：** 包含了[片上外设](https://wiki.sipeed.com/soft/maixpy/zh/modules/on_chip/gpio.html)、[SP MOD](https://wiki.sipeed.com/soft/maixpy/zh/modules/sp_mod/sp_bt.html)、[Grove](https://wiki.sipeed.com/soft/maixpy/zh/modules/grove/grove_ultrasonic_ranger.html)、[其他外设](https://wiki.sipeed.com/soft/maixpy/zh/develop_kit_board/module_microphone.html)。 **图像处理基础（image）** 包含了[获取图像](https://wiki.sipeed.com/soft/maixpy/zh/course/image/basic/get_images.html)、[显示图像](https://wiki.sipeed.com/soft/maixpy/zh/course/image/basic/display_images.html)、[图像处理基础](https://wiki.sipeed.com/soft/maixpy/zh/course/image/basic/vary.html)、[如何在图像上写字](https://wiki.sipeed.com/soft/maixpy/zh/course/image/basic/draw.html)、[硬件加速图像模块](https://wiki.sipeed.com/soft/maixpy/zh/course/image/basic/acc_image_deal.html)。 **传统算法应用** 传统算法应用里包含了[图像处理](https://wiki.sipeed.com/soft/maixpy/zh/course/image/find_color_blob.html)、[音频处理](https://wiki.sipeed.com/soft/maixpy/zh/course/speech/fft_waterfall.html)。 **神经网络应用（AI）** 包含了[深度神经网络基础](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/basic/dnn_basic.html)、[KPU 硬件加速介绍](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/basic/maixpy_hardware_ai_basic.html)、[AI 图像处理](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/image/face_detect.html)、[AI 音频处理](https://wiki.sipeed.com/soft/maixpy/zh/course/speech/recognizer_cnn.html)、[如何训练模型](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/train/maixhub.html)。 ### 如何正常使用 SD 卡 在【更多功能应用】里的部分示例里需要用到 SD 卡存储模型或固件等，很多小伙伴会遇见 SD 卡文件读取不到，先判断路径是否正确，再判断是否挂载成功了。 查询是否挂载成功的方法如下： ```python import os print(os.listdir(\"/\")) >>['flash'] # 没有挂载 SD 卡 >>['flash', 'sd'] # 挂载 SD 卡成功 ``` 如果挂载不成功的话请根据 [MaixPy 常见问题 FAQ](https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html?highlight SD#Micro SD %E5%8D%A1%E8%AF%BB%E5%8F%96%E4%B8%8D%E5%88%B0) 排查相关错误再进行再次挂载尝试使用。 ### 如何进行配置开发板 在使用 `外设模块拓展` 的示例时，K210 系列板子因硬件引脚的不同需要进行不同的配置写入，可参考 [Board](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/builtin_py/board_info.html)文档进行配置。 ### 如何连接麦克风阵列 [麦克风阵列例程](https://wiki.sipeed.com/hardware/zh/modules/micarray.html) **K210 系列板卡连接麦克风阵列有以下两种方式供参考：** 1. **推荐：使用杜邦线连接板子与麦克风阵列的引脚，在使用例程提供的代码实现声源定位。** 2. 使用麦克风阵列标配排线搭配转接板连接板子 ### 如何获取开发板（机器码） >在【更多功能应用】里的 `神经网络应用（AI）` 讲述了如何获取并运行 AI 模型的，但在获取模型的操作中有一步是需要机器码才能下载相关的模型，机器码是一机一码的一种加密方式，用于模型文件的加密。如果使用别的机器码去加密或者下载以 `smodel` 为文件后缀的模型文件，开发板是无法使用该模型文件的。 **参考以下示例步骤获取机器码：** 1. 将 key_gen.bin 这个固件通过 Kflash 烧录到开发板上。烧录这个机器码固件之后，开发板是处于一个不能使用的状态，上电屏幕只会变成一个白屏。 2. 这时将开发板通过 USB 连接到电脑上，利用【串口连接】中的方式来连接开发板。注：IDE 中的串口终端和 IDE 的连接方式相对独立的，而且串口不能通过多种方式进行连接 3. 利用串口软件连接上开发板，这时按下开发板上的 reset 的按键，就会出现一串字符在终端窗口上，这就机器码。 [机器码固件：key_gen v1.2.bin](https://dl.sipeed.com/shareURL/MaixHub_Tools) ![key](./mixly_application/accets/k210_usage/key.png) >注意：烧录过 key_gen.bin 之后的开发板将永久禁用 K210 的 JTAG 调试功能。 ### 如何获取 AI 模型 除了在示例文档中给出的模型，用户还可在 [MaixHub](https://maixhub.com/model/zoo) 模型库中查找标签为 `nncase` 相关的 AI 模型供 k210 系列板子使用。 ### 如何训练模型及数据集 云端训练以及相关文档介绍：[MaixHub](https://maixhub.com) [什么是人工智能(AI)和机器学习](https://wiki.sipeed.com/ai/zh/basic/what_is_ai.html) [常见代码框架和工具](https://wiki.sipeed.com/ai/zh/basic/code_frameworks.html) [部署模型到 Maix I(M1) K210 系列开发板](https://wiki.sipeed.com/ai/zh/deploy/k210.html) [MaixHub 训练调优方法](https://wiki.sipeed.com/ai/zh/maixhub/train_best.html) `MaixHub` 提供模型训练功能和模型分享功能以及视频教学，用户不需要搭建训练环境以及代码，只需要准备好需要训练的数据集上传训练数据即可快速训练出模型，方便快速制作你的 AI 应用。 本地训练：[Windows 环境配置](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/train/local_windows_1.html)、[Windows 使用教程](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/train/local_windows_2.html)、[Linux 使用教程](https://wiki.sipeed.com/soft/maixpy/zh/course/ai/train/local.html)。 如果是没有任何开发基础的同学们请谨慎使用本地训练，出现问题请自行解决。 ## 库函数 API 手册 API 手册只罗列几种分类出来，如有需要更详细的请点击前往各分类查看下一级目录，可搭配上文【更多功能应用】使用更佳! [库函数 API 手册 标准库](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/standard/index.html) [库函数 API 手册 machine](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine/i2c.html) [库函数 API 手册 Maix](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/Maix/fpioa.html) [库函数 API 手册 helper](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/builtin_py/index.html) [库函数 API 手册 media](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/index.html) [库函数 API 手册 extend](https://wiki.sipeed.com/soft/maixpy/zh/api_reference/extend/index.html) ## 如何编译与开发 **对于想尝试开发 K210 的用户们我们也准备了相对应的文档供大家参考：** [代码框架结构](https://wiki.sipeed.com/soft/maixpy/zh/course/advance/project_framework.html) [如何编译 MaixPy 工程](https://wiki.sipeed.com/soft/maixpy/zh/course/advance/compile.html) [如何用 C 添加一个 MaixPy 模块](https://wiki.sipeed.com/soft/maixpy/zh/course/advance/add_c_module.html) [打包文件系统](https://wiki.sipeed.com/soft/maixpy/zh/course/advance/pack_fs.html) **MaixPy 源码：[点击查看](https://github.com/sipeed/MaixPy)** **相关原厂 K210 SDK：[点击查看](https://www.canaan creative.com/developer)** **以下是裸机开发可参考文章：** [K210裸机开发（〇）简介及准备](https://blog.csdn.net/hgf_fgh/article/details/122402940#:~:text %E6%89%93%E5%BC%80PlatformIO%E4%B8%BB%E9%A1%B5%EF%BC%8C%E5%9C%A8Boards%E9%A1%B5%E9%9D%A2%E6%90%9C%E7%B4%A2K210%EF%BC%8C%E5%9C%A8platform%E5%88%97%E6%89%BE%E5%88%B0kendryte,k210%E5%B9%B6%E7%82%B9%E8%BF%9B%E5%8E%BB%EF%BC%8C%E7%82%B9%E5%87%BBinstall%E5%AE%89%E8%A3%85%E7%AD%89%E5%BE%85%E5%8D%B3%E5%8F%AF%EF%BC%9B) ## 学会使用文档（资源） 为什么会写 **`学会使用文档`** 呢，众所周知 `K210` 系列的板卡已经是 `2019` 年的产物了，各方面的文档也好例程也好早已经是成熟的了，该踩的坑基本都在前几年就被踩完了，现在更多的新手小白踩坑可能都是因为性能上的不足或者是自身使用环境的乱导致出问题。这篇文档的初衷是想要让大家在使用的过程中避坑，但我们还是要学会把文档资源利用起来。 1. 学会搜索并利用官方的`文档社区`以及 `github issue` 资源，会让新手小白少走很多弯路雷坑。 2. 文档资源在 `常见问题 FAQ` 中基本涵盖了所有的坑，使用途中报错可以先查看这篇文档排错。 3. 在使用途中出现故障但无法自行判断（代码/硬件）问题，可以先运行测试程序测试屏幕及摄像头。 4. 想要实现更多的功能示例或需要更多的脚本源码，可前往 `MaixPy` 的源码例程仓库查找。 **文档搜索例程：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/how_to_read.html) **BBS 社区教程贴：**[点击前往](https://bbs.sipeed.com/thread/492) **MaixPy 源码仓库：**[点击前往](https://github.com/sipeed/maixpy) **MaixPy 例程仓库：**[点击前往](https://github.com/sipeed/MaixPy v1_scripts) **MaixPy issue：**[点击前往](https://github.com/sipeed/MaixPy v1issues?page 5&q is%3Aissue+is%3Aopen) **MaixPy 常见问题 FAQ：**[点击查看](https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html) **BBS 社区常见问题汇总贴：**[点击查看](https://bbs.sipeed.com/thread/489) ## Mind+ 积木编程 **MaixDuino K210 实现积木编程例程：**[点击查看](https://wiki.sipeed.com/news/MaixPy/mind_application/mind_application.html) Mind+ 从1.6.6 版本开始支持基于 K210 主控的 Maixduino 开发板，可满足对于 K210 开发有兴趣的用户。 ## 常见问题 FAQ ### 出现 MaixPy 软件包失败现象 卸载干净之前下的软件安装包，重新下载并换磁盘安装。 ![maixpy](./mixly_application/accets/k210_usage/maixpy.jpg) ### 烧录固件途中出现握手失败等报错信息 ![kflash_gui](./mixly_application/accets/k210_usage/kflash_gui.jpg) 一般出现这个问题，先从以下几个方面判断问题（因使用环境不同造就的设备握手失败） 1. 先判断板子上电后设备管理器是否有 `COM` 端口出现，如果没有端口出现返回安装驱动的步骤或者进行更换线材。 2. 设备管理器出现 `COM` 端口，查看是否被别的软件（串口根据、手机助手、蓝牙、外设）占用了串口，查询不出再次更换线材或重启设备也可以。 3. 查看 kflash_gui 的版本（是不是太低）下载页面的配置不要改动并调小波特率。 4. 烧录前按硬件的 BOOT 键后按复位，再松开 BOOT 键尝试能不能烧录。 5. 尝试过以上的方法都不行的话请更换电脑设备尝试，还是不行的话请联系淘宝官方客服。 ### 板子通电后显示白屏、黄屏、红蓝闪屏等现象 ![yellow_lcd](./mixly_application/accets/k210_usage/yellow_lcd.png) 1. 白屏黄屏请参考 [MaixPy 常见问题 FAQ ](https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html?highlight %E7%99%BD%E5%B1%8F#%E7%83%A7%E5%BD%95 MaixPy %E4%B9%8B%E5%90%8E%EF%BC%8CMaixPy %E5%87%BA%E7%8E%B0%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8)解决。 2. 出现红蓝闪屏，请重新烧录固件后然后接稳摄像头运行[测试程序](https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_cam_lcd.html)判断摄像头是否能用，有可能是摄像头或摄像头接口出现问题导致。 ### 摄像头出现黑斑现象 ![sensor_error](./mixly_application/accets/k210_usage/sensor_error.png) 显示黑斑但是有正常画面就是摄像头内片不干净，可以把摄像头拆出来擦一擦。 ### 运行摄像头程序显示：RuntimeError：Sensor timeout! 摄像头连接超时，重新连接下或者是换摄像头。 ### 烧录固件后画面反色 重新擦除烧录，使用代码反色回来[点击](https://wiki.sipeed.com/soft/maixpy/zh/course/image/basic/display_images.html?highlight %E5%8F%8D%E8%89%B2)查看。 **更多报错信息请前往 [MaixPy 常见问题 FAQ](https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html?highlight SD#Micro SD %E5%8D%A1%E8%AF%BB%E5%8F%96%E4%B8%8D%E5%88%B0) 或 [BBS【超实用】常见问题汇总贴](https://bbs.sipeed.com/thread/489) 排查问题。**"},"/news/MaixPy/star_maixpy.html":{"title":"MaixPy 上手指南（避坑）之上手篇","content":" title: MaixPy 上手指南（避坑）之上手篇 keywords: MaixPy, K210, Python, MicroPython desc: MaixPy 上手指南（避坑） 之上手篇 date: 2022 04 01 tags: MaixPy, K210 > 作者：Ray（Rui） 拿到热乎的 K210 开发板，如何上手使用。我接触了许许多多的小白开发者后，整理出来的资料和路线，希望可以减少你们遇到的问题，可以更加愉快的使用 K210 进行自己的项目开发。 <! more > ## K210 开发板 市面上有很多中关于 K210 的开发板，但是并不是所有的开发板都是可以使用 MaixPy 进行开发的。毕竟不同厂商使用的摄像头、屏幕、引脚上使用，都是由差异性的。目前支持的使用 MaixPy 开发的板子有 Sipeed 家的 [Maix 系列](/hardware/zh/maix/index.html)。 如果是试用别家的开发板，并不能很好的兼容 MaixPy，存在差异性。 ## 开箱 拿到开发板，首先需要根据屏幕和摄像头排线上的丝印提示来安装好，即排线上的数字 “1” 和板子卡座边上引脚丝印 “1” 方位对应接上。上电之后，屏幕上会显示出一个红色的界面这是开发板已经正常启动了。（也可能存在部分丝印印反） ### 首先要安装开发环境： 1. [【安装驱动】](/soft/maixpy/zh/get_started/env_install_driver.html) 根据自己使用的开发进行选择需要按安装驱动 2. [【更新固件】](/soft/maixpy/zh/get_started/upgrade_maixpy_firmware.html) 确保使用的是最新版本的固件，并学习一下每个固件之间的[差异](/soft/maixpy/zh/get_started/upgrade_maixpy_firmware.html#固件命名说明) 3. [【安装 MaixPy IDE】](/soft/maixpy/zh/get_started/env_maixpyide.html) 如果安装驱动的时候出现安装失败，或者是安装驱动之后，电脑上没有显示 COM 口的，就需要更新一下系统或者是检查一下自己的系统是不是正版的了。因为有部分的盗版系统安装不上驱动，或者是安装驱动之后并显示。或者通过换 USB 口进行连接，也许就可以检测到开发板 ### 运行代码检测摄像头 将开发板接到电脑上，打开 MaixPy IDE，运行打开的例程代码，检查自己的屏幕和摄像头是否正确连接上了。如果运行例程代码之后，并没有图像出现来屏幕和 IDE 上时，可能摄像头接反了。 ## 开始学习使用 开始使用 K210 之前，一定要学习 Python，如果你连 Python 都不会的，就不要继续往下走，可以快速的过一遍 [Python](/soft/maixpy3/zh/origin/python.html) 的语法和使用，一定要会 Python !一定要会 Python !一定要会 Python ! 现在就当你懂 Python 了，这是就可以开始看 MaixPy 文档中的入门指南，进行对于 MaixPy 的使用和 K210 的基本了解。 【更多功能应用】中将有 MaixPy 更多的使用案例和使用方式，一定要确保自己已经对应入门教程中内容已经了解和掌握了再去看，否则你在学习的时候还是会一脸懵逼，不知所云。 ## 获取 AI 模型文件 在【更多功能应用】中是有讲述如何运行神经网络模型，也知道怎么去获取示例中的模型文件，但是少了如何获取机器码这个操作，这里详细的讲述一下何如获取机器码。 1. 将 [key_gen.bin](https://dl.sipeed.com/fileList/MaixHub_Tools/key_gen_v1.2.bin) 这个固件通过 Kflash 烧录到开发板上。烧录这个机器码固件之后，开发板是处于一个不能使用的状态，上电屏幕只会变成一个白屏。 2. 这时将开发板通过 USB 连接到电脑上，利用[【串口连接】](/soft/maixpy/zh/get_started/env_serial_tools.html)中的方式来连接开发板。注：IDE 中的串口终端和 IDE 的连接方式相对独立的，而且串口不能通过多种方式进行连接 3. 利用串口软件连接上开发板，这时按下开发板上的 reset 的按键，就会出现一串字符在终端窗口上，这就机器码。如果机器码 > 推荐使用 IDE 中的 串口终端进行查看，这个相对别的软件更加适合 K210 机器码是一机一码的一种加密方式，用于模型文件的加密。如果使用别的机器码去加密或者下载以 smodel 为文件后缀的模型文件，开发板是无法使用该模型文件的。"},"/news/MaixPy/mind_application/mind_application.html":{"title":"Maixduino K210 如何实现积木编程","content":" title: Maixduino K210 如何实现积木编程 keywords: K210, Maixduino, Mind++ date: 2022 08 18 tags: K210, Maixduino, Mind++ 快来体验 Maixduino 不一样的有趣玩法 <! more > [原文链接](https://mindplus.dfrobot.com.cn/maixduino) ## 说明 Mind+ 从1.6.6版本开始支持基于 K210 主控的 Maixduino 开发板，可满足对于 K210 开发有兴趣的用户。 ![mind 1](assets/mind 1.jpg) ## 使用流程 ### 器材准备 Mind+ 1.6.6及以上版本 Maixduino主控板 Type C数据线 ### 环境准备 1. 打开 Mind+ 切换至上传模式，扩展库中选择主控板下的 Maixduino 后返回主界面。 ![mind 2](assets/mind 2.jpg) ![mind 3](assets/mind 3.jpg) 1. 使用 USB 线连接主控板与电脑，设备菜单中会出现两个 COM 口，选择其中 Maixduino 的 COM 口，软件会自动烧录固件，右下角小黑窗会显示提示语。 : : : 打开设备管理器 打开系统的设备管理器，方便检查端口或驱动问题。 一键安装串口驱动 如果首次使用软件板子没有出现 COM 口，则可以安装驱动。 恢复设备初始设置 首次使用 Mind+ 或出现异常情况时，可以使用恢复设备初始设置功能擦除板子内的固件,<br>使用时需要先选择 COM 口再选择此功能，恢复完成后手动断开连接再选择端口。 注意 如果是首次使用需要选择 ESP32 (网卡)的 COM 口然后选择恢复设备初始设置功能更新网卡，否则可能会出现模拟输入功能无法使用。 Mind+ 中的固件与 Maixduino 官方固件不同，可以线选择 Maixduino 的 COM 口然后选择恢复设备初始设置，然后断开再次连接，即可自动刷入 Mind+ 固件。 ![mind 4](assets/mind 4.jpg) ### 编程使用 编写一个程序，在屏幕中显示摄像头画面，完成后点击运行，程序即可运行，板子上就可以看到效果了。 ![mind 5](assets/mind 5.jpg) ![mind 6](assets/mind 6.jpg) ## 手动编辑 手动编辑模式中可以手动编写代码，需要先在文件系统新建文件然后打开，再保存，运行程序需要右键选择运行。 ![mind 7](assets/mind 7.jpg) ## 固件说明 Maixduino 有各种版本的固件，Mind+ 图形化部分为保持积木生成代码的稳定，内置的固件包含了图形化需要的库，同时为保持 Maixduino 使用的灵活性，Mind+ 也支持使用其他固件。 ### 如何区分是否为 Mind+ 内置固件？ 1. 如下图，终端中的输出信息以 Maixduino 开头的即为 Mind+ 内置固件。 ![mind 8](assets/mind 8.jpg) 2. 如下图，终端中输出信息为 MiaxPy 或者其他则不是 Mind+ 内置固件，则这些固件可能会缺失图形化中的某些功能导致无法使用，如果需要使用图形化的功能请刷入 Mind+ 内置固件。 ![mind 9](assets/mind 9.jpg) ### Mind+ 中固件烧录逻辑说明 选择 Maixduino 的 COM 口之后，软件会检测板子中是否有固件，如果有固件（不论是 Mind+ 内置的固件或第三方均为有固件）则连接终端开始使用，如果没有则自动烧录固件选择区所选择的固件。 ### 因此如果需要烧录第三方固件，操作方法为： 1. 选择 Maixduino 的 COM 口，选择恢复设备初始设置（这个功能会擦除板子 flash 固件会被擦除）. 2. 在选择固件处点击本地加载，加载想烧录的第三方固件文件，然后点击加载的固件，然后再次选择 Maixduino 的 COM 口，此时因为固件被擦除了就会烧录这个新的固件，等待烧录完成即可。 3. 注意：因 Mind+ 积木生成的代码是固定的，因此如果烧录了第三方固件可能会出现部分功能无法使用（例如引脚映射文件在新的固件下没有会出错）此时可以使用手动编辑功能直接使用代码，如果继续想使用图形化，则可以使用开放扩展库自己写图形化积木扩展实现，教程[点击](https://mindplus.dfrobot.com.cn/extensions user). ![mind 10](assets/mind 10.jpg) ### 同理如果要从第三方固件切换为 Mind+ 内置固件，操作方法为： 1. 选择 Maixduino 的 COM 口，选择恢复设备初始设置（这个功能会擦除板子 flash，固件会被擦除）。 2. 在选择固件处点击官方固件，然后再次选择 Maixduino 的 COM 口，此时因为固件被擦除了就会烧录 Mind+ 内置的官方固件，等待烧录完成即可。 ![mind 11](assets/mind 11.jpg) ## 教程 **社区用户驴友花雕的系列教程** [【花雕测评】【AI】Mind+文字图片显示、呼吸灯及网络应用的22项小实验](https://makelog.dfrobot.com.cn/article 311386.html) [【花雕测评】【AI】Mind+机器视觉之数字图像处理和显示的22种小测试](https://makelog.dfrobot.com.cn/article 311405.html) [【花雕测评】【AI】Mind+机器视觉之颜色、维码与形状识别的8个小实验](https://makelog.dfrobot.com.cn/article 311417.html) **社区用户 hockel 的系别教程** [【mind+ 玩转MAIXDUINO 系列0】 工欲善其事，必先利其器](https://mc.dfrobot.com.cn/thread 307857 1 1.html) [【Mind+ 玩转Maixduino系列1】你好，世界](https://mc.dfrobot.com.cn/thread 307857 1 1.html) [【mind+ Maixduino用户库】NES 游戏扩展库 【mind+ 用户库】Maixduino 中文字模、图片英文显示](https://mc.dfrobot.com.cn/thread 308037 1 1.html) **社区用户 DFByaoZQN5E 的系列教程** [[教程]mind+ k210主板第一课 hello word!](https://mc.dfrobot.com.cn/thread 307820 1 1.html) [[教程]mind+ k210主板第二课 gpio(1)](https://mc.dfrobot.com.cn/thread 307850 1 1.html) [[教程]mind+ k210 第三课 gpio (2)](https://mc.dfrobot.com.cn/thread 307877 1 1.html) [[教程]mind+ k210 第四课 gpio (3)](https://mc.dfrobot.com.cn/thread 307969 1 1.html) **社区用户肥罗 阿勇的教程** [Mind+Maixduino应用案例集合](https://mc.dfrobot.com.cn/thread 307946 1 1.html) **社区用户 hmilycheng 的系列教程** [Maixduino轻松学系列 —— （1）初识Maixduino](https://makelog.dfrobot.com.cn/article 311375.html) [Maixduino轻松学系列 —— （2）Mind+带你畅玩经典红白机游戏](https://makelog.dfrobot.com.cn/article 311392.html) [Maixduino轻松学系列 —— （3）基于Mind+的简易NTP网络时钟](https://makelog.dfrobot.com.cn/article 311401.html) [Maixduino轻松学系列 —— （4）基于Mind+的图像识别：人脸检测](https://makelog.dfrobot.com.cn/article 311411.html) [Maixduino轻松学系列 —— （5）有屏幕的地方就有BAD APPLE](https://makelog.dfrobot.com.cn/article 311418.html) [Maixduino轻松学系列 —— （6）基于ASR语音识别控制红绿灯](https://makelog.dfrobot.com.cn/article 311420.html) [Maixduino轻松学系列 —— （7）超声波传感器的认识与使用](https://makelog.dfrobot.com.cn/article 311425.html) ## 注意事项 & FAQ 0. 断电重启之后，按一下板子上的 RESET 键即可启动程序。 1. 如果是首次使用需要选择 ESP32 (网卡)的 COM 口然后选择恢复设备初始设置功能更新网卡，否则可能会出现模拟输入功能没有读值的情况。 2. 涉及到 SD 卡读取或存储的操作，需要插入内存卡（断电后插拔内存卡）才可正常使用。 ![mind 13](assets/mind 13.jpg) ![mind 12](assets/mind 12.jpg) 3. 不支持的硬件可以使用用户库功能自行添加，详情查看官方文档中自定义用户库教程。 4. 人工智能项目需要导入模型文件，请将模型文件拷贝到内存卡目录下。 [下载连接](https://pan.baidu.com/share/init?surl dTB0UHRKVrCtS4cMrxgDhQ) 提取码：mind 5. 注意变量名字不要与内置的库名字重复，例如不要命名变量为 image ![mind 14](assets/mind 14.jpg) 6. FAQ 问题 解决思路 : : : 在执行有模型的 AI 程序时出现 out of memory 或者 memory not enough 等内存不足的错误怎么办？ 程序使用的模型对应的固件可能不是 Mind+ 内置的，尝试找到对应的固件或[寻找maixpy的固件](https://mc.dfrobot.com.cn/thread 308995 1 1.html)。 报错 kpu: img w xxx,h xxx, but model w xxx,h xxx kpu: check img format err! 怎么办？ 使用的 kmodel 模型文件训练的时候的分辨率与程序中使用的摄像头分辨率不同，尝试修改相机设置窗口。 提示 no module named 'pin' 错误怎么办？ 说明固件不是 Mind+ 中的，如果需要使用 Mind+ 内置固件，则选择 Maixduino 的 COM 口,恢复设备初始设置擦除固件，然后断开再次连接即会自动刷入 Mind+ 提供的固件。如果依然要使用非 Mind+ 内置固件，则需要导入对应依赖库，[点击查看教程](https://mc.dfrobot.com.cn/thread 309510 1 1.html)。 使用 WiFi 连接功能时提示 hard spi Get version fail hard spi 或卡住怎么办？<br>![mind 15](assets/mind 15.jpg) 用到网络功能时需要插上内存卡再使用。 "},"/news/MaixPy/sensor.html":{"title":"Sensor 感光元件曝光控制","content":" title: Sensor 感光元件曝光控制 tags: Sensor, 曝光控制, 修改曝光 date: 2023 06 10 keywords: Sebsor, 曝光控制, 修改曝光 > 最近有社区的小伙伴在实现功能时需对 Sensor 摄像头的曝光强弱进行调整以及修改，可根据下文的代码来进行调整曝光，源代码链接：[点击](https://book.openmv.cc/example/21 Sensor Control/sensor_exposure_control.html)查看。 ## 摄像头型号 我们测过两种型号的摄像头分别是：`OV2640` 以及 `OV5640`，只有 `OV2640` 型号的支持使用 `sensor_exposure_control` 对曝光进行修改以及控制。 ![ov2640](./assets/ov2640.jpg) ## 控制曝光代码 ```python import sensor, image, time # 更改此值以调整曝光。试试10.0 / 0.1 /等。 EXPOSURE_TIME_SCALE 0.01 sensor.reset() # Reset and initialize the sensor. sensor.set_pixformat(sensor.RGB565) # Set pixel format to RGB565 (or GRAYSCALE) sensor.set_framesize(sensor.QVGA) # Set frame size to QVGA (320x240) # 打印出初始曝光时间以进行比较。 print(\"Initial exposure %d\" % sensor.get_exposure_us()) sensor.skip_frames(time 2000) # Wait for settings take effect. clock time.clock() # Create a clock object to track the FPS. # 您必须关闭自动增益控制和自动白平衡，否则他们将更改图像增益以撤消您放置的任何曝光设置... sensor.set_auto_gain(False) sensor.set_auto_whitebal(False) # 需要让以上设置生效 sensor.skip_frames(time 500) print(\"New exposure %d\" % sensor.get_exposure_us()) # 如果要重新打开自动曝光，请执行以下操作：sensor.set_auto_exposure(True) # 请注意，相机传感器将根据需要更改曝光时间。 current_exposure_time_in_microseconds sensor.get_exposure_us() sensor.set_auto_exposure(False, exposure_us int(current_exposure_time_in_microseconds * EXPOSURE_TIME_SCALE)) sensor.set_auto_exposure(False) # 执行：sensor.set_auto_exposure(False)，只是禁用曝光值更新，但不会更改相机传感器确定的曝光值。 while(True): current_exposure_time_in_microseconds sensor.get_exposure_us() print(\"Current Exposure %d\" % current_exposure_time_in_microseconds) clock.tick() # Update the FPS clock. img sensor.snapshot() # Take a picture and return the image. print(clock.fps()) # Note: OpenMV Cam runs about half as fast when connected # to the IDE. The FPS should increase once disconnected. ``` ## 用法以及效果演示 ### 修改 EXPOSURE_TIME_SCALE 的值为 0.1 在上文的代码中修改控制曝光 EXPOSURE_TIME_SCALE 的值为 0.1，看看是什么效果。 ![sensor_one](./assets/sensor_one.png) ### 修改 EXPOSURE_TIME_SCALE 的值为 0.4 递增修改控制曝光 EXPOSURE_TIME_SCALE 的值为 0.4，看看是什么效果。 ![sensor_one](./assets/sensor_two.png) ### 修改 EXPOSURE_TIME_SCALE 的值为 0.8 再次修改控制曝光 EXPOSURE_TIME_SCALE 的值为 0.8，看看是什么效果。 ![sensor_one](./assets/sensor_three.png) > 从应用效果来看 0.1 跟 0.8 的曝光补光的图像差距非常大，用户可根据自己的需求进行修改值即可。"},"/news/MaixPy/reload_python_module.html":{"title":"关于 MicroPython import 指定 flash 或 sd 分区的代码与重载 Python 模块的方法","content":" title: 关于 MicroPython import 指定 flash 或 sd 分区的代码与重载 Python 模块的方法 keywords: MicroPython date: 2022 06 09 tags: MicroPython, reload 如果在 maixpy (micropython) 上同时存在 flash 和 sd 等多个分区挂载 / 目录下，且均存在 boot.py 文件，如何加载指定分区下的 boot.py 模块代码呢？ <! more > [原文链接](https://www.cnblogs.com/juwan/p/14517375.html) https://www.cnblogs.com/juwan/p/14517375.html `import boot` 时取决于 os 的 vfs (虚拟文件系统) 对象，它会根据 os.getcwd() 和 os.chdir('/sd') 决定代码寻找的位置（/sd 分区路径），如果是某目录下的代码，则可以使用类似 import test.boot 的结构来查找并 import 它。 示例： ```python >>> os.chdir('/flash') >>> import boot flash: 2942 >>> os.getcwd() '/flash' >>> ``` 拓展来讲，如何重载 import boot 后的 boot 模块，管理 sys.modules 模块就行，如下示意。 ```python >>> import sys >>> import boot 2433 >>> import boot >>> sys.modules.pop('boot') <module 'boot' from 'boot.py'> >>> sys.modules.pop('boot') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> KeyError: boot >>> os.chdir('/flash') >>> import boot flash: 2479 >>> sys.modules.pop('boot') <module 'boot' from 'boot.py'> >>> os.chdir('/sd') >>> import boot 2488 >>> sys.modules.pop('boot') <module 'boot' from 'boot.py'> >>> ``` 即先使用 sys.modules.pop('boot') 后再重新 import 目标 boot 就行"},"/news/MaixPy/kmodel_datastruct.html":{"title":"K210 kmodel 模型储存数据结构","content":" title: K210 kmodel 模型储存数据结构 keywords: K210, kmodel date: 2022 06 09 tags: K210, kmodel K210 kmodel 模型储存结构 <! more > 版权声明：本文为 neucrack 的原创文章，遵循 CC 4.0 BY SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://neucrack.com/p/307 有改动 ## K210 kmodel 简介 V3 由 nncase v0.1.0 RC5 转换而来 V4 由 nncase v0.2.0 从 tflite 转换而来 V4相比于V3, 支持了更多算子, 但是运算速度更慢, 部分算子使用了CPU运算, K210侧也使用了C++编写, 部分库会拉低速度, 如果你需要移植或者优化可以注意这一点 ## kmodel V3 数据结构 头 输出层信息 各层的头 各个层数据内容 kpu_kmodel_header_t kpu_model_output_t * output_count kpu_model_layer_header_t * layers_length layers_body 这里有个注意点, kpu_kmodel_header_t 没有8字节对齐, 所以在第一层的数据实际是保存在8字节对齐处, 比如前面所有header 长度为 228 字节, 那么 第一层数据中, 头 kpu_model_conv_layer_argument_t 占用24个字节, 228+24 不是8的整数倍, 所以层数据保存在 228+24+4 处, 所以在 kpu_model_conv_layer_argument_t 中用了 layer_offset 这个来表示层数据相对于模型起始地址的偏移 ```c typedef struct { uint32_t version; // 固定 0x00000003, 0x03在低地址 uint32_t flags; // 最低位 为1, 表示8bit模式 uint32_t arch; uint32_t layers_length; uint32_t max_start_address; uint32_t main_mem_usage; uint32_t output_count; } kpu_kmodel_header_t; typedef struct { uint32_t address; uint32_t size; } kpu_model_output_t; typedef struct { uint32_t type; uint32_t body_size; } kpu_model_layer_header_t; ``` ## kmodel V4 数据结构 头 输入 输入形状 输出 常量 各层的头 各个层数据内容 struct modelv4_header memory_range\\*hdr.inputs runtime_shape_t\\*hdr.inputs memory_range\\*hdr.outputs hdr.constants hdr.nodes \\* struct node_header nodes content ```c struct modelv4_header { uint32_t identifier; // 固定为 KMDL, L在低地址 uint32_t version; // 固定为 0x00000004, 0x04 在低位 uint32_t flags; uint32_t target; // CPU: 0, K210: 1 uint32_t constants; // 多少个 uint_t 类型的常量 uint32_t main_mem; // 主内存, 用于AI, 运行时会先把输入的数据拷贝到这里 uint32_t nodes; uint32_t inputs; // input size uint32_t outputs; // output size uint32_t reserved0; }; struct node_header { uint32_t opcode; uint32_t size; }; struct memory_range { memory_type_t memory_type; datatype_t datatype; uint32_t start; uint32_t size; }; // 16 Bytes typedef enum _datatype { dt_float32, dt_uint8 } datatype_t; typedef enum _memory_type { mem_const, mem_main, mem_k210_kpu } memory_type_t; using runtime_shape_t std::array<int, 4>; ```"},"/news/index.html":{"title":"动态","content":" title: 动态 keywords: teedoc, 博客生成, 静态博客 desc: teedoc 静态博客页面生成 show_source: false date: false <div id \"blog_list\"></div>"}}